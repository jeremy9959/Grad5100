[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grad 5100: Fundamentals of Data Science",
    "section": "",
    "text": "Grad 5100 is a foundational course in the MS in Data Science Program. It is designed to provide the essential background in programming, statistics, linear algebra, and multivariate calculus that the core and elective courses in the program rely on. The course will run intensively during the first few weeks of the semester and then drop back to a regular weekly schedule.\n\n\n\nWe will rely on the following materials.\n\nThe anaconda machine learning environment for python and associated libraries\nThe R language, Rstudio IDE, and associated libraries\nThe VScode IDE\n\nThere is no formal textbook for the course. Some useful references include the following, all of which are either open source or available through the UConn Library.\n\nProgramming Bootcamp (python) These are notes from a programming bootcamp at Caltech. It is very well done and comprehensive and covers more than we will do in this course.\nProgramming Bootcamp (R) These are notes developed at UConn by Chiranjit Dutta, one of Professor Ravishanker’s students. For a more usable zip file of the Rmd code and the data files, use this link.\nAn Introduction to Statistical Learning by James, et. al. Note that the original version of this book uses the R language, but a new edition available in Summer 2023 uses Python.\nR for Data Science by Wickham and Grolemund.\nPython for Data Science, 3E by Wes McKinney.\nPractical Statistics for Data Scientists by Bruce, Bruce, and Gedeck. Note that this is available for free to UConn students through the UConn library’s subscription to the O’Reilly Learning Platform.\nStatistical Practice for Data Science by Bar, Ravishankar, and Asha (draft).\nMathematics for Machine Learning (draft) by Teitelbaum.\nFluent Python by Ramalho. Available to UConn students through the UConn Library’s subscription to the O’Reilly Learning Platform.\n\nMore advanced technical references include:\n\nThe Elements of Statistical Learning by Hastie, et. al.\nPattern Recognition and Machine Learning by Bishop\n\n\n\n\nWe will use the campuswire Q&A site for class discussions and question asking/answering. Campuswire is like a private version of stackoverflow. Make sure to register for the site.\n\n\n\nCourse grades will be based on:\n\nbiweekly homework assignments (60 %)\na final exam (40 %)\n\n\n\n\nThe instructor reserves the right to modify or adapt this syllabus to account for disruption due to COVID-19 or other unexpected circumstances.\n\n\n\nStudents with disabilities should work with the Center for Students with Disabilities to request academic accommodations. The CSD is located in Wilbur Cross, Room 204 and can be reached at (860)-486-2020 or at csd@uconn.edu.\nStudents are bound by the university’s policies on academic misconduct. Academic misconduct is dishonest or unethical behavior that includes but is not limited to misrepresenting mastery in an academic area (e.g. cheating), failing to properly credit information, research, or ideas to their rightful originators or representing such information, research, or ideas as your own (e.g. plagiarism).\nStudents, faculty, and staff are bound by the university’s policy against discrimination, harassment, and related interpersonal violence.\n\n\n\n\n\n\n\nSetting up a data science working environment\nProbability and Statistics: the normal distribution\nWorking with Data in R and Python\nLinear Algebra: vectors, matrices, the dot product\nPartial derivatives and the gradient; matrix calculus\nSlicing and dicing data in R and Python\nStatistical Models\nHypothesis Testing\nData Structures and Object Oriented Programming\nVisualization tools in R and Python\nVersion Control\nDatabases\nAdditional topics as time permits"
  },
  {
    "objectID": "chapters/00-OrientationProject/orientation-project.html",
    "href": "chapters/00-OrientationProject/orientation-project.html",
    "title": "Orientation Project",
    "section": "",
    "text": "GitHub is a huge repository of open source software projects managed by the version control software git. GitHub and git are designed to allow many people working independently to contribute to a software project, keeping track of different versions and the contributions of different people\nLater we will use GitHub to actually manage software but our goal today is to take advantage of the ability to create a personal web page on GitHub."
  },
  {
    "objectID": "chapters/00-OrientationProject/orientation-project.html#steps",
    "href": "chapters/00-OrientationProject/orientation-project.html#steps",
    "title": "Orientation Project",
    "section": "Steps",
    "text": "Steps\n\nCreate a GitHub account with your selected username\nCreate a new repository named username.github.io. Include a basic README.md file.\n\n\n\nTurn on github pages for this repository from the settings link. This is probably done already. Check the published site at https://username.github.io\n\n\n\nCreate a file _config.yml so you can choose a theme. Here we use the architect theme to start with.\n\n\n\nWait a bit and then look at the results.\n\n\n\nLook at the theme possibilities and pick one you like by modifying the _config.yaml file. Notice that it takes a while to deploy the new theme.\n\n\n\nAdd more content! Add more info to the _config.yml file using the theme documentation!"
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html",
    "href": "chapters/01-SettingUp/setting-up.html",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Download from https://www.anaconda.com\n\nAnaconda includes:\n\npython\njupyter: notebook working environment\npython libraries: ML, visualization, I/O and others\nconda package manager: for dealing with multiple versions of libraries\nanaconda navigator: a GUI gateway to anaconda tools\nlots of other stuff\n\n\n\n\n\nVerify JupyterLab\n\nFrom a command line\n$ jupyter lab \nor use anaconda navigator to launch jupyterlab.\n\n\nVerify python version\n\nFrom a command line\n$ python --version\nor inside a jupyter notebook cell:\nimport sys\n\nprint(sys.version)\n\n\n\n\nSome notes on how to run Jupyter on the HPC cluster\n\n\n\n\n\nR is an open source language for statistical computations.\nRstudio is a working environment for the R language.\nR and Rstudio need to be installed separately.\nR is available at https://cran.r-project.org\nRstudio is available at https://posit.co/download/rstudio-desktop\n\n\n\n\nFor R, From a command line:\n$ R \nFor Rstudio, use the icon/shortcut or from a command line:\n$ rstudio \n\n\n\n\nvscode is a very powerful “IDE” (integrated development environment).\nit can integrate jupyter notebooks and r workbooks, though it takes some setting up\nvscode is integrated with GitHub copilot, a version of ChatGPT-3 that helps write code.\nvscode is available at http://code.visualstudio.com for windows, linux, and macOS.\n\n\n\n\nVSCode (visual studio code) is a freely distributed code editor/IDE distributed by microsoft.\nIt is extremely capable and well-suited for software development in python and other languages.\nIt is perhaps not as optimized for R as Rstudio but it does work.\nYou can access github copilot a version of chatGPT optimized for code, inside vscode in a straightforward way.\n\n\n\nThe software is available here.\nYou need a github account to use github copilot, and you need to sign in to that account from inside vscode. GitHub copilot is free to students, but you need to sign up for the student developer pack..\n\n\n\n\n\nOpening folders (as projects)\nOpening files\nInstall Extensions:\n\npython\nR\nmany others\n\nThe command palette\n\n\n\n\n\njupyter notebooks inside vscode with github copilot\nInteractive python with code cells (# %%)\nThe terminal\n\n\n\n\n\nCreate a project directory\nSubdirectories\n\ndata for data files\ndocs for notes and documentation\nothers?\n\nCreate a README.md file\n\n\n\n\nFor the directories:\n\nthe finder or File Manager\nthe command line\n\nFor the README file:\n\na text editor such as nano or notepad\njupyter or Rstudio (as we will see soon)\nvscode"
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html",
    "href": "chapters/01-SettingUp/Cluster.html",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "",
    "text": "On your local machine: Login to the login node:\nYou need to install anaconda on your account on the cluster. To do this you can use wget to download the installer and then run it and follow the installation prompts as usual. You only need to do this part once!\nNow check if python and jupyter lab work.\nIf jupyter lab won’t run because of a libc++.so.6.o error, you can run\nMake a note of the node where your interactive process is running. This is in the prompt. It will be something like cn560.\nMake a note of the token provided by the jupyter lab process and the port where the server is running.\nWith luck, you’re running jupyter on a node in the cluster!"
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html#moving-a-file-to-the-cluster",
    "href": "chapters/01-SettingUp/Cluster.html#moving-a-file-to-the-cluster",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "Moving a file to the cluster",
    "text": "Moving a file to the cluster\nIf you can login to the cluster successfully using ssh then you can transfer a file to the cluster from your laptop using rsync. From a shell on your local machine:\nrsync filename <netID>@hpc2.storrs.hpc.uconn.edu"
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html#getting-a-file-from-the-cluster",
    "href": "chapters/01-SettingUp/Cluster.html#getting-a-file-from-the-cluster",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "Getting a file from the cluster",
    "text": "Getting a file from the cluster\nTo transfer a file from the cluster to your local machine, run the following command from a shell on your local machine.\nrsync <netID>@hpc2.storrs.hpc.uconn.edu:filename ."
  },
  {
    "objectID": "chapters/02-JupyterBasics/jupyter-walkthrough.html",
    "href": "chapters/02-JupyterBasics/jupyter-walkthrough.html",
    "title": "Jupyter Lab and Python Walkthrough",
    "section": "",
    "text": "Use the ‘text editor’ feature in Jupyter Lab to create your README.md file.\nRENAME YOUR NOTEBOOK FILE IMMEDIATELY to something relevant\nCTRL-ENTER executes a cell.\n\n\n\nThis is a markdown cell:\n\nHeadings are #, ##, etc.\nBold is marked **make me bold** like this.\nItalics are marked *make me italic* like this.\nMath can be typeset with if you know it: \\[f(x)=e^{-x}\\cos(x)\\]\nBulleted lists are marked with -.\n\n\n# code cells\n## Code cells contain python code that gets executed.\n# indicates a comment that is ignored.\nprint(\"Hello World!\")\n\nHello World!\n\n\nIn this walkthrough we will look at the following elements of Python in a jupyter notebook.\nThe print statement\n\nprint(\"hello world!\")\n\nhello world!\n\n\nVariables, variable names, and assignment/datatypes\n\ncount = 5  # an integer\nname = \"Jeremy Teitelbaum\"  # a string\nparagraph = \"\"\"This is how you enter a multiline string\nin python. It is enclosed in triple quotes.\"\"\"\npi = 3.14159  # a float\nepsilon = 1.0e-6  # a float\nstudents = [\"Jeremy\", \"Phillip\", \"Sara\", \"Molly\"]  # a list\nHotDog = True\n\n\nprint(students)\n\n['Jeremy', 'Phillip', 'Sara', 'Molly']\n\n\nCompare print for multiline strings with the string value. (\\n means newline)\n\nprint(paragraph)\n\nThis is how you enter a multiline string\nin python. It is enclosed in triple quotes.\n\n\n\nparagraph\n\n'This is how you enter a multiline string\\nin python. It is enclosed in triple quotes.'\n\n\nArithmetic operations\n\nprint(count)\ncount = count + 1\nprint(count)\n\n5\n6\n\n\n\n1 / pi\n\n0.31831015504887655\n\n\n\nprint(2**3)  # exponent\nprint(1 / 2)  # division (converts integer to float)\nprint(1 / (1 / 2))  # 2 becomes 2.0\n\n8\n0.5\n2.0\n\n\n\nquotient = 5 // 3  # integer division\nremainder = 5 % 3  # remainder\nprint(quotient, remainder)\n\n1 2\n\n\nOperations on strings and lists\n\n\"Jeremy\" + \" Teitelbaum\"\n\n'Jeremy Teitelbaum'\n\n\n\n[\"a\", \"b\", \"c\"] + [\"d\"]\n\n['a', 'b', 'c', 'd']\n\n\n\nlen(\"Jeremy\")\n\n6\n\n\n\nlen([\"Jeremy\", \"Teitelbaum\"])\n\n2\n\n\n\nfirstName = \"Jeremy\"\nlastName = \"Teitelbaum\"\nfullName = firstName + \" \" + lastName\n\nSome fancier printing\n\nprint(f\"The first name is {firstName}\")\nprint(f\"The last name is {lastName}\")\nprint(f\"The full name is {firstName} {lastName}\")\nprint(firstName, lastName, sep=\",\")\nprint(firstName, lastName, sep=\":\")\n\nThe first name is Jeremy\nThe last name is Teitelbaum\nThe full name is Jeremy Teitelbaum\nJeremy,Teitelbaum\nJeremy:Teitelbaum\n\n\nSlicing\nIn python, we always count from zero!!!\n\nfirstName[0]\n\n'J'\n\n\n\nlastName[1]\n\n'e'\n\n\n\n# [a:b] means from a to b-1 inclusive\n\nprint(firstName[0:3])\nprint(firstName[3:])\nprint(firstName[3:5])\n\nJer\nemy\nem\n\n\n\n# negative indices count from the end\nprint(firstName[-1])  # the last element\nprint(firstName[-3:-1])  # elements -3 and -2, but not -1\n\ny\nem\n\n\n\n# [a:b:c] means from a to b-1 in steps of c\n# missing numbers mean (beginnging):(end)\nprint(firstName[:5:2])\nprint(firstName[::2])\nprint(firstName[::-1])  # reverse the string\nprint(firstName[3::-1])  # 3,2,1,0\nprint(firstName[3:0:-1])  # 3,2,1\n\nJrm\nJrm\nymereJ\nereJ\nere\n\n\nSlices work the same on list elements\n\nprint(students[0])\nprint(students[-1])\nevery_other_student = students[::2]\nprint(every_other_student)\n\nJeremy\nMolly\n['Jeremy', 'Sara']\n\n\nLibraries\n\nimport math\n\n\nmath.log(23)\n\n3.1354942159291497\n\n\n\nmath.pi\n\n3.141592653589793\n\n\n\nmath.cos(math.pi / 2)  # should be zero\n\n6.123233995736766e-17\n\n\n\nmath.cos(math.pi / 2) == 0\n\nFalse\n\n\n\nabs(math.cos(math.pi / 2)) < 1e-6\n\nTrue\n\n\n\nmath.pi == pi\n\nFalse\n\n\n\nimport numpy as np\n\n\nprint(np.random.randint(0, 10))\n\n5\n\n\n\nprint(np.__version__)\n\n1.21.5\n\n\n\nfrom numpy.random import randint\n\n\nrandint(1, 10)\n\n4\n\n\n\n\n\nA numpy array is like a list, but:\n- it's itended for use with numbers\n- it's designed for fast arithmetic and numerical operations\n- it can be multi-dimensional -- like a table or matrix -- although we won't use that here.\n\nx = np.array([1, 2, 3, 4, 5, 6])\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nYou access arrays like lists, and can use slices; indices start at zero.\n\nx[2:4]\n\narray([3, 4])\n\n\nWhen you apply an operation to an array, it gets applied to every element of the array.\n\nprint(f\"Square of x is {x**2}\")\nprint(f\"1/x is {1/x}\")\nprint(f\"cos(x) is {np.cos(x)}\")\n\nSquare of x is [ 1  4  9 16 25 36]\n1/x is [1.         0.5        0.33333333 0.25       0.2        0.16666667]\ncos(x) is [ 0.54030231 -0.41614684 -0.9899925  -0.65364362  0.28366219  0.96017029]\n\n\nSome special arrays.\n\nx = np.zeros(10)  # 10 zeros\ny = np.ones(20)  # 20 ones\nz = np.linspace(0, 10, 100)  # 100 equally spaced numbers from 0 to 10 **inclusive**\nw = np.array(list(range(-10, 10, 2)))\n\n\nprint(w)\n\n[-10  -8  -6  -4  -2   0   2   4   6   8]\n\n\n\nprint(z)\n\n[ 0.          0.1010101   0.2020202   0.3030303   0.4040404   0.50505051\n  0.60606061  0.70707071  0.80808081  0.90909091  1.01010101  1.11111111\n  1.21212121  1.31313131  1.41414141  1.51515152  1.61616162  1.71717172\n  1.81818182  1.91919192  2.02020202  2.12121212  2.22222222  2.32323232\n  2.42424242  2.52525253  2.62626263  2.72727273  2.82828283  2.92929293\n  3.03030303  3.13131313  3.23232323  3.33333333  3.43434343  3.53535354\n  3.63636364  3.73737374  3.83838384  3.93939394  4.04040404  4.14141414\n  4.24242424  4.34343434  4.44444444  4.54545455  4.64646465  4.74747475\n  4.84848485  4.94949495  5.05050505  5.15151515  5.25252525  5.35353535\n  5.45454545  5.55555556  5.65656566  5.75757576  5.85858586  5.95959596\n  6.06060606  6.16161616  6.26262626  6.36363636  6.46464646  6.56565657\n  6.66666667  6.76767677  6.86868687  6.96969697  7.07070707  7.17171717\n  7.27272727  7.37373737  7.47474747  7.57575758  7.67676768  7.77777778\n  7.87878788  7.97979798  8.08080808  8.18181818  8.28282828  8.38383838\n  8.48484848  8.58585859  8.68686869  8.78787879  8.88888889  8.98989899\n  9.09090909  9.19191919  9.29292929  9.39393939  9.49494949  9.5959596\n  9.6969697   9.7979798   9.8989899  10.        ]\n\n\n\n## Plotting with matplotlib\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot(z, z**2)\n\n\n\n\n\nz = np.linspace(-10, 10, 100)\nplt.axes()\nplt.plot(z, np.cos(z), color=\"red\")\nplt.title(\"A cosine curve\")\nplt.grid()\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\nplt.xticks(list(range(-10, 11)))\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\nText(0, 0.5, 'y')"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html",
    "href": "chapters/03-RBasics/r-walkthrough.html",
    "title": "R Notebook Walkthrough",
    "section": "",
    "text": "Start out with a code cell saying “Hello World”\nThe cat command is actually probably more useful than print:"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#variables-types-and-assignment",
    "href": "chapters/03-RBasics/r-walkthrough.html#variables-types-and-assignment",
    "title": "R Notebook Walkthrough",
    "section": "Variables, Types, and Assignment",
    "text": "Variables, Types, and Assignment\nIn R, the assignment operator is <-, not =. This takes some getting used to.\n\ncount <- 5\nname <- \"Jeremy Teitelbaum\" # string types are called chr for character\nparagraph <- \"Far across the misty mountains cold,\nto dungeons deep and caverns cold,\nwe must away,\nere break of day\nto seek our long forgotten gold.\"\npi <- 3.14159 # R doesn't use integer types unless you force it to, numbers are \"num\" # nolint: line_length_linter.\nepsilon <- 1e-6\ncount <- 5L # this forces an integer\nstudents <- c(\"Jeremy\", \"Phillip\", \"Sara\", \"Molly\")\nhot_dog <- TRUE # note all caps unlike Python; false is FALSE\n\nIn R, you can give names to the elements of a vector.\n\nprint(\"hello\")\n\n[1] \"hello\"\n\n\n\nnames(students) <- c(\"President\", \"Vice President\", \"Treasurer\", \"Secretary\")\nprint(names(students))\n\n[1] \"President\"      \"Vice President\" \"Treasurer\"      \"Secretary\"     \n\nprint(students[\"President\"])\n\nPresident \n \"Jeremy\" \n\nprint(students)\n\n     President Vice President      Treasurer      Secretary \n      \"Jeremy\"      \"Phillip\"         \"Sara\"        \"Molly\" \n\n\nThe cat command is a print command that “concatenates” its arguments; it needs an explicit newline.\n\nprint(students)\n\n     President Vice President      Treasurer      Secretary \n      \"Jeremy\"      \"Phillip\"         \"Sara\"        \"Molly\" \n\nprint(count)\n\n[1] 5\n\ncat(\"Students:\", students, \"\\n\")\n\nStudents: Jeremy Phillip Sara Molly \n\nprint(epsilon)\n\n[1] 1e-06\n\ncat(\"The value of epsilon is:\", epsilon, \"\\n\")\n\nThe value of epsilon is: 1e-06 \n\nprint(paragraph)\n\n[1] \"Far across the misty mountains cold,\\nto dungeons deep and caverns cold,\\nwe must away,\\nere break of day\\nto seek our long forgotten gold.\"\n\ncat(paragraph)\n\nFar across the misty mountains cold,\nto dungeons deep and caverns cold,\nwe must away,\nere break of day\nto seek our long forgotten gold.\n\n\nThe [1] at the beginning of each of these things reflects the fact that in R everything is a vector. So it is telling you that the first thing there is element 1 of the vector.\nThe c() command makes a vector of its arguments. It forces everything to be of the same type.\n\nstr_list <- c(\"Jeremy\", 25, 1.34, FALSE) # everything becomes a string\nint_list <- c(1, 2, 3, 4, 5)\nfloat_list <- c(1, 2, 3.5, 4)"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#arithmetic",
    "href": "chapters/03-RBasics/r-walkthrough.html#arithmetic",
    "title": "R Notebook Walkthrough",
    "section": "Arithmetic",
    "text": "Arithmetic\nR does all arithmetic on vectors/lists. It one is shorter than the other, it repeats the shorter one, but the length of the longer has to be a multiple of the shorter.\n\na <- 1\nb <- 2\na + b\n\n[1] 3\n\n\n\na <- c(1, 2, 3, 4, 5)\nb <- 4\na + b\n\n[1] 5 6 7 8 9\n\n\n\na <- c(1, 2, 3, 4, 5, 6)\nb <- c(10, 11)\na + b\n\n[1] 11 13 13 15 15 17\n\n\n\na <- c(1, 2, 3, 4, 5)\nb <- c(1, 2)\na + b\n\nWarning in a + b: longer object length is not a multiple of shorter object\nlength\n\n\n[1] 2 4 4 6 6\n\n\n\na / 5\n\n[1] 0.2 0.4 0.6 0.8 1.0\n\n\n\n# integer division (// in python)\na <- 5L\nb <- 3\na %/% b\n\n[1] 1\n\n\n\n# remainder (% in python)\na <- 5\nb <- 3\na %% b\n\n[1] 2\n\n\n\na <- c(1, 2, 3, 4, 5)\na^2\n\n[1]  1  4  9 16 25\n\n\n\nprint(a^2 == a)\n\n[1]  TRUE FALSE FALSE FALSE FALSE\n\nprint(a^2 > a)\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE\n\nprint(a^2 == 4)\n\n[1] FALSE  TRUE FALSE FALSE FALSE"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#operations-on-strings-and-lists",
    "href": "chapters/03-RBasics/r-walkthrough.html#operations-on-strings-and-lists",
    "title": "R Notebook Walkthrough",
    "section": "Operations on strings and lists",
    "text": "Operations on strings and lists\n\nfirst_name <- \"Jeremy\"\nlast_name <- \"Teitelbaum\"\nnchar(first_name)\n\n[1] 6\n\n\n\npaste(first_name, last_name) # spaces by default\n\n[1] \"Jeremy Teitelbaum\"\n\n\n\npaste(first_name, last_name, sep = \"\") # no space\n\n[1] \"JeremyTeitelbaum\"\n\n\n\npaste(c(1, 2, 3), \"Jeremy\") # remember functions work across vectors\n\n[1] \"1 Jeremy\" \"2 Jeremy\" \"3 Jeremy\""
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#substrings",
    "href": "chapters/03-RBasics/r-walkthrough.html#substrings",
    "title": "R Notebook Walkthrough",
    "section": "Substrings",
    "text": "Substrings\nIn R, you always count from 1 (big difference from python)\n\nfirst_name[1] # another difference from Python\n\n[1] \"Jeremy\"\n\n\n\na <- substr(\"Jeremy\", 1, 1)\nb <- substr(\"Jeremy\", 1, 3)\ncat(a, b, paste(a, b, sep = \"\"))\n\nJ Jer JJer"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#slicing-lists",
    "href": "chapters/03-RBasics/r-walkthrough.html#slicing-lists",
    "title": "R Notebook Walkthrough",
    "section": "Slicing lists",
    "text": "Slicing lists\n\nnums <- 0:10 # generates a sequence from 0 to 10 INCLUSIVE (compare python)\nprint(nums)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(nums[c(1, 3)]) # you can pass a list of indices to a subscript\n\n[1] 0 2\n\n\n\nsqrs <- nums^2\nsqrs[seq(1, 10, 2)]\n\n[1]  0  4 16 36 64\n\n\nIn R, negative numbers in seq mean “omit” so this means omit entries 2 through 5. You can’t mix positive and negative numbers\n\nrev <- nums[seq(-2, -5)]\nprint(rev)\n\n[1]  0  5  6  7  8  9 10\n\n\n\nrev(nums) # reverses the list\n\n [1] 10  9  8  7  6  5  4  3  2  1  0"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#libraries-and-packages",
    "href": "chapters/03-RBasics/r-walkthrough.html#libraries-and-packages",
    "title": "R Notebook Walkthrough",
    "section": "Libraries and packages",
    "text": "Libraries and packages\nUse the Rstudio package manager to add libraries to your installation, but to use them you need to use the library function. The tidyverse library is something we will use a lot.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#plotting",
    "href": "chapters/03-RBasics/r-walkthrough.html#plotting",
    "title": "R Notebook Walkthrough",
    "section": "Plotting",
    "text": "Plotting\n\nlibrary(ggplot2)\n\n\nx <- seq(-10, 10, .1)\ny <- x**2\ndata <- tibble(\"x\" = x, \"y\" = y)\n\n\nggplot(data = data, aes(x = x)) +\n    geom_point(aes(y = y), color = \"red\") +\n    ggtitle(\"A Parabola\") +\n    scale_x_continuous(breaks = seq(-10, 10, 1)) +\n    scale_y_continuous(breaks = seq(0, 100, 20))\n\n\n\n\n\nx <- seq(-10, 10, .1)\ny <- cos(x)\ndata <- tibble(\"x\" = x, \"y\" = y)\nggplot(data = data, aes(x = x)) +\n    geom_line(aes(y = y), color = \"darkgreen\") +\n    ggtitle(\"A Cosine Curve\") +\n    scale_x_continuous(breaks = seq(-10, 10, 1)) +\n    scale_y_continuous(breaks = seq(-1, 1, 5))"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-theory",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-theory",
    "title": "Statistical Basics",
    "section": "Probability Theory",
    "text": "Probability Theory\nProbability theory is based on:\n\nAn underlying collection \\(S\\) of all possible outcomes (a population or sample space) of an experiment.\nA rule \\(P\\) that assigns a number between zero and one to each subset of the sample space satisfying certain rules."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sample-space",
    "href": "chapters/04-StatBasics/stat-basics.html#sample-space",
    "title": "Statistical Basics",
    "section": "Sample Space",
    "text": "Sample Space\nFor example:\n\nFor a flip of a single coin, the possible outcomes are Heads and Tails and the sample space has two elements. For multiple flips, the outcomes are sequences of Heads and Tails.\nFor a measurement of temperature, we might model the possible outcomes, or the sample space, as all real numbers, recognizing that only some of them are actually possible results of the experiment."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#simple-events",
    "href": "chapters/04-StatBasics/stat-basics.html#simple-events",
    "title": "Statistical Basics",
    "section": "Simple Events",
    "text": "Simple Events\nThe elements of the sample space or population are the outcomes or simple events or sample points.\n\nFor a flip of a coin, the possible outcomes are Heads or Tails. For multiple flips, the possible outcomes are particular sequences of Heads or Tails.\nFor a measurement of temperature, a simple event would be a particular number obtained at a particular time."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#events",
    "href": "chapters/04-StatBasics/stat-basics.html#events",
    "title": "Statistical Basics",
    "section": "Events",
    "text": "Events\nSubsets of the population make up events or outcomes.\n\nAmong the population made up of sequences of 10 coin flips, the subset consisting of sequences containing at least 3 heads is an event.\nAmong the measurements of temperature, a measurement lying between say 22 and 25 degrees celsius would be an event."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-measure",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-measure",
    "title": "Statistical Basics",
    "section": "Probability Measure",
    "text": "Probability Measure\nThe last element of probability theory is the function P that assigns a number between 0 and 1 to every event such that\n\n\\(P(\\emptyset)=0\\)\n\\(P(S)=1\\).\nIf \\(A\\cap B=\\emptyset\\) then \\(P(A\\cup B)=P(A)+P(B)\\). This is also required to hold for infinite collections of disjoint sets but we won’t worry much about the foundations of probability."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#random-variables",
    "title": "Statistical Basics",
    "section": "Random Variables",
    "text": "Random Variables\nA random variable is a rule that assigns a number to an event.\n\nWe can assign the value 1 to heads and 0 to tails. This is a bernoulli random variable.\nOur sample space can be sets of 10 coin flips. The number of heads is a random variable.\nThe measurement of temperature yields a number.\n\nIf we pick a person at random, we can assign the value 1 if they wear glasses and 0 if not."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#discrete-vs-continuous-random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#discrete-vs-continuous-random-variables",
    "title": "Statistical Basics",
    "section": "Discrete vs Continuous Random Variables",
    "text": "Discrete vs Continuous Random Variables\nA discrete random variables takes “separate” values depending on the event. A continuous random variable takes values in a range.\n\nBernoulli random variable is discrete (0/1)\nNumber of heads in 10 flips is discrete (takes values 0,…,10)\nTemperature is continuous (in principle can get any reading)\nMass of a penguin is continuous\nSpecies of penguin is discrete"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#events-and-random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#events-and-random-variables",
    "title": "Statistical Basics",
    "section": "Events and Random Variables",
    "text": "Events and Random Variables\nSpecifying a value, or a range of values, for a random variable defines an event."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#bernoulli-example",
    "href": "chapters/04-StatBasics/stat-basics.html#bernoulli-example",
    "title": "Statistical Basics",
    "section": "Bernoulli example",
    "text": "Bernoulli example\n\nSample space is \\(\\{H,T\\}\\)\n\\(P(H)=p\\)\n\\(X\\) is the random variable with \\(X(H)=1\\) and \\(X(T)=0\\)\n\nThen:\n\n\\(X=1\\) is the same as the event \\(H\\)\n\\(P(X=1)\\)=p"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#independence",
    "href": "chapters/04-StatBasics/stat-basics.html#independence",
    "title": "Statistical Basics",
    "section": "Independence",
    "text": "Independence\nTwo events are independent if the chance of both occurring is the product of the chances of them occurring separately.\n\\[\nP(X\\cap Y)=P(X)P(Y)\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#binomial-example",
    "href": "chapters/04-StatBasics/stat-basics.html#binomial-example",
    "title": "Statistical Basics",
    "section": "Binomial Example",
    "text": "Binomial Example\nA binomial random variable (with parameters \\(n\\) and \\(p\\)) is the sum of \\(n\\) bernoulli random variables with probability \\(p\\). It corresponds to flipping a coin (with \\(P(H)=p\\)) \\(n\\) times and counting up the heads.\nThe probability of getting \\(k\\) heads is \\[\nP(k)=\\binom{n}{k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#binomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#binomial-distribution",
    "title": "Statistical Basics",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#continuous-example",
    "href": "chapters/04-StatBasics/stat-basics.html#continuous-example",
    "title": "Statistical Basics",
    "section": "Continuous example",
    "text": "Continuous example\n\nSample space is the possible temperatures at a particular point in space and time.\nRandom variable \\(T\\) is a measure of temperature.\n\\(P(21<T<22)\\) is the probability that the temperature is between 21 and 22 degrees."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-density-functions",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-density-functions",
    "title": "Statistical Basics",
    "section": "Probability density functions",
    "text": "Probability density functions\nIn the continuous case, probability is measured by a probability density function \\(P(x)\\). The classic example is the normal (bell-shaped) curve."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#density-functions",
    "href": "chapters/04-StatBasics/stat-basics.html#density-functions",
    "title": "Statistical Basics",
    "section": "Density Functions",
    "text": "Density Functions\nIf \\(P(x)\\) is the density function, then:\n\nthe probability that \\(x\\) lies between \\(a\\) and \\(b\\) is the area under density function between \\(a\\) and \\(b\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#area-gives-probability",
    "href": "chapters/04-StatBasics/stat-basics.html#area-gives-probability",
    "title": "Statistical Basics",
    "section": "Area gives probability",
    "text": "Area gives probability\n\n\n\n\nThe shaded area gives probability 0.87 for temp between 21.7 and 22.3."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#standard-normal",
    "href": "chapters/04-StatBasics/stat-basics.html#standard-normal",
    "title": "Statistical Basics",
    "section": "Standard Normal",
    "text": "Standard Normal\nA normal curve is defined by two parameters:\n\nthe mean \\(\\mu\\), which sets the location\nthe standard deviation \\(\\sigma\\) or its square, the variance \\(\\sigma^2\\), which sets the scale."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#z-score",
    "href": "chapters/04-StatBasics/stat-basics.html#z-score",
    "title": "Statistical Basics",
    "section": "Z-score",
    "text": "Z-score\nIf \\(x\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then \\[\nz = \\frac{x-\\mu}{\\sigma}\n\\] is a normal random variable with mean \\(0\\) and variance \\(1\\). This is called a \\(z\\)-score or a standard normal variable."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution",
    "title": "Statistical Basics",
    "section": "Cumulative Distribution",
    "text": "Cumulative Distribution\nThe cumulative distribution is a function \\(f(x)\\) such that \\(f(x)\\) is the the percentage of samples that are less than \\(x\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution-1",
    "href": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution-1",
    "title": "Statistical Basics",
    "section": "Cumulative Distribution",
    "text": "Cumulative Distribution\n\nSo the median of the samples occurs where the \\(y\\)-axis is \\(.5\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#quantiles",
    "href": "chapters/04-StatBasics/stat-basics.html#quantiles",
    "title": "Statistical Basics",
    "section": "Quantiles",
    "text": "Quantiles\n\nIf \\(q\\) is between \\(0\\) and \\(1\\), then the \\(q^{th}\\) quantile \\(Q\\) of a random variable \\(x\\) is the value of \\(x\\) such that the fraction of the population with \\(x<Q\\) is \\(q\\).\nThe median of \\(x\\) is the \\(.5\\) quantile for \\(x\\) because half of the population has values less than the median.\nOne can read quantiles from the cumulative distribution."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distributions-in-r",
    "href": "chapters/04-StatBasics/stat-basics.html#distributions-in-r",
    "title": "Statistical Basics",
    "section": "Distributions in R",
    "text": "Distributions in R\nThere are many distributions in R. We’ve talked about the binomial (discrete) and normal (continuous).\n\nrnorm (rbinom) draws samples from the distribution\ndnorm (dbinom) gives the value of the probability density function\npnorm (pbinom) gives the value of the cumulative density function\nqnorm (qbinom) gives the quantiles, that is, qnorm(p) gives the value of the parameter so that the probability of getting a result less than that parameter is p."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#examples-in-r",
    "href": "chapters/04-StatBasics/stat-basics.html#examples-in-r",
    "title": "Statistical Basics",
    "section": "Examples in R",
    "text": "Examples in R\n\nsamples <- rnorm(10, mean = 0, sd = 1)\n\ndensityfn <- dnorm(1, mean = 0, sd = 1)\ncdf <- pnorm(1, mean = 0, sd = 1)\nquant <- qnorm(.05, mean = 0, sd = 1)\ncat(\"samples: \", samples, \"\\n\")\n\nsamples:  1.624309 0.7831292 -0.04017203 -0.2440161 0.2947779 -1.585369 -0.5791326 -0.954867 -0.347164 0.4989488 \n\ncat(\"Density=\", densityfn, \" CDF value=\", cdf, \" Quantile=\", quant)\n\nDensity= 0.2419707  CDF value= 0.8413447  Quantile= -1.644854"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distributions-in-python",
    "href": "chapters/04-StatBasics/stat-basics.html#distributions-in-python",
    "title": "Statistical Basics",
    "section": "Distributions in Python",
    "text": "Distributions in Python\nIn python the distributions are available in the scipy.stats library. Assuming import scipy.stats as sps:\n\nsps.norm.rvs draws from the distribution\nsps.norm.pdf is the density\nsps.norm.cdf is the cumulative distribution\nsps.norm.ppf are the quantiles"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#examples-in-python",
    "href": "chapters/04-StatBasics/stat-basics.html#examples-in-python",
    "title": "Statistical Basics",
    "section": "Examples in Python",
    "text": "Examples in Python\n\nimport scipy.stats as sps\n\nsamples = sps.norm.rvs(0, 1, size=10)\n\ndensityfn = sps.norm.pdf(1, 0, 1)\ncdf = sps.norm.cdf(1, 0, 1)\nquant = sps.norm.ppf(0.05, 0, 1)\nprint(\n    (\"samples = [ \" + \"{:.3f} \" * len(samples)).format(*samples) + \"]\",\n    \"Density={:.3f} CDF value={:.3f} Quantile={:.3f}\".format(densityfn, cdf, quant),\n)\n\nsamples = [ 0.189 -1.137 -0.386 0.320 -0.714 -0.727 -0.479 1.746 -0.880 -0.330 ] Density=0.242 CDF value=0.841 Quantile=-1.645"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics",
    "title": "Statistical Basics",
    "section": "Order Statistics",
    "text": "Order Statistics\nThe sample median and the sample quantiles (such as the 25th percentile or 75th percentile) are examples of order statistics.\nThe smallest element, the second smallest element, and so on are other examples of order statistics."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics-example",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics-example",
    "title": "Statistical Basics",
    "section": "Order Statistics example",
    "text": "Order Statistics example\nWe take 100 samples from a normal distribution and compute the median, minimum, and maximum. Then we do that 10000 times and produce a histogram."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics-histogram",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics-histogram",
    "title": "Statistical Basics",
    "section": "Order Statistics Histogram",
    "text": "Order Statistics Histogram"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#the-multinomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#the-multinomial-distribution",
    "title": "Statistical Basics",
    "section": "The multinomial distribution",
    "text": "The multinomial distribution\nThe multinomial distribution arises when you have \\(n\\) outcomes for your experiment, say \\(x_1,\\ldots, x_n\\); and the probability of getting \\(x_i\\) is \\(p_i\\). Here we have to have \\[\n\\sum p_{i}=1.\n\\]\nThis generalizes the bernoulli distribution."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean",
    "href": "chapters/04-StatBasics/stat-basics.html#mean",
    "title": "Statistical Basics",
    "section": "Mean",
    "text": "Mean\nThe mean of a random variable is perhaps the most important statistic associated with a probability space.\nThe mean is the “average value” of the random variable.\nThe mean of \\(x\\) is denoted \\(\\overline{x}\\) .\nExpectation or expected value is another name for the mean, and so the mean is also denoted \\(E(x)\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-discrete-case",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-discrete-case",
    "title": "Statistical Basics",
    "section": "Mean – discrete case",
    "text": "Mean – discrete case\nIn the discrete case:\n\\[\n\\overline{x}=\\sum_{a\\in X} x(a)p(a)\n\\]\nIn other words, the mean of \\(\\overline{x}\\) is the sum of \\(x\\) at each event, weighted by the probability of that event."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-a-bernoulli-random-variable",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-a-bernoulli-random-variable",
    "title": "Statistical Basics",
    "section": "Mean of a bernoulli random variable",
    "text": "Mean of a bernoulli random variable\nIf \\(x\\) is bernoulli, with \\(p(x=1)=p\\), then the mean of \\(x\\) is \\[\np(1)+(1-p)(0)=p.\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-a-binomial-random-variable",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-a-binomial-random-variable",
    "title": "Statistical Basics",
    "section": "Mean of a binomial random variable",
    "text": "Mean of a binomial random variable\nIf \\(x\\) is binomial, corresponding to the sum of \\(N\\) bernoulli random variables with probability \\(p\\), then \\[\n\\overline{x} = \\sum_{0\\le i\\le N} i\\binom{N}{i}p^{i}(1-p)^{N-i}=Np\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-continuous-case",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-continuous-case",
    "title": "Statistical Basics",
    "section": "Mean – continuous case",
    "text": "Mean – continuous case\nThe mean of a continuous random variable is given by an integral:\n\\[\n\\overline{x} = \\int_{X} xp(x) dx\n\\]\nwhere \\(p(x)\\) is the probability density. This is the limiting case of the formula in the discrete case."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-standard-normal",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-standard-normal",
    "title": "Statistical Basics",
    "section": "Mean of standard normal",
    "text": "Mean of standard normal\nThe mean of the standard normal is zero."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-and-standard-deviation",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-and-standard-deviation",
    "title": "Statistical Basics",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\nThe variance of a random variable measures how it is distributed around its mean value.\nThe variance is the average value of the difference between \\(x\\) and its mean.\n\\[\n\\sigma^2=E((x-\\overline{x})^2)\n\\]\nIn the case of a discrete random variable with outcomes values \\(x\\) having probability \\(p(x)\\), the variance is \\[\n\\sum_{x} (x-\\overline{x})^2p(x)\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-alternative-formula",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-alternative-formula",
    "title": "Statistical Basics",
    "section": "Variance alternative formula",
    "text": "Variance alternative formula\nThis is the same as\n\\[\n\\sigma^2 = \\overline{x^2}-(\\overline{x})^2\n\\]\nThe standard deviation is the square root of the variance."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-of-bernoulli",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-of-bernoulli",
    "title": "Statistical Basics",
    "section": "Variance of Bernoulli",
    "text": "Variance of Bernoulli\nIn the Bernoulli case, the variance is \\[\n(1-p)^2p+p^2(1-p)=p(1-p).\n\\]\nNotice that the maximum variance happens when \\(p=1/2\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-of-binomial",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-of-binomial",
    "title": "Statistical Basics",
    "section": "Variance of Binomial",
    "text": "Variance of Binomial\nA binomial random variable with probability \\(p\\) and \\(n\\) trials is a sum of \\(n\\) bernoulli random variables with probability \\(p\\). Using the formula you get \\[\n\\sigma^2 = \\sum_{i=0}^{n}(i-np)^2\\binom{n}{i}p^{i}(1-p)^{n-i}\n\\]\nThis turns out to be \\[\n\\sigma^2 = np(1-p).\n\\]\nNote: there are easier ways to get this formula. If two random variables are independent, then the variance of their sum is the sum of their variances."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling",
    "title": "Statistical Basics",
    "section": "Sampling",
    "text": "Sampling\nIn practice we study random variables through samples. A sample of a random variable is a choice of values distributed according to the associated probability. So for example a sample of a Bernoulli random variable is a coin flip where \\(P(H)=p\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling-1",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling-1",
    "title": "Statistical Basics",
    "section": "Sampling",
    "text": "Sampling\nIf we draw \\(N\\) sample values \\(x_i\\) ofa random variable, then the mean and variance of those sampled values, computed by\n\\[\n\\overline{x} = \\frac{1}{N}\\sum x_{i}\n\\]\nand \\[\n\\overline{x} = \\frac{1}{N-1}\\sum (x_{i}-\\overline{x})^2\n\\]"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sample-mean-and-variance",
    "href": "chapters/04-StatBasics/stat-basics.html#sample-mean-and-variance",
    "title": "Statistical Basics",
    "section": "Sample Mean and Variance",
    "text": "Sample Mean and Variance\nThe formulae above are called the sample mean and variance; they are estimates of the mean and variance of the underlying random variable.\nThe law of large numbers says that, as \\(N\\to\\infty\\), these estimates converge to the true values.\nIn general these values are also random (they depend on the particular choices drawn from the distribution) and follow their own probabilility distribution."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distribution-of-sample-mean-and-variance",
    "href": "chapters/04-StatBasics/stat-basics.html#distribution-of-sample-mean-and-variance",
    "title": "Statistical Basics",
    "section": "Distribution of sample mean and variance",
    "text": "Distribution of sample mean and variance\nSo for example, if you sample a Bernoulli random variable \\(10\\) times, the mean is \\[\n\\frac{k}{N}\n\\] where \\(k\\) is the number of heads.\nThis mean follows a binomial distribution."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling-distribution",
    "title": "Statistical Basics",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution\n\nBy looking at sample means (or other sample statistics) we can try to uncover information about the underlying probability distribution."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#hypothesis-testing",
    "href": "chapters/04-StatBasics/stat-basics.html#hypothesis-testing",
    "title": "Statistical Basics",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\nA statistical hypothesis is a claim about a particular population. A hypothesis test is a method to determine which of two contradictory hypotheses is supported by the data.\nUnderlying idea: a lot of surprising things happen by chance. If you do an experiment and observe an effect, that might be the result of pure chance. Can you quantify that?"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#an-example",
    "href": "chapters/04-StatBasics/stat-basics.html#an-example",
    "title": "Statistical Basics",
    "section": "An example",
    "text": "An example\nSuppose we have a coin and we’d like to do some testing to determine if we have reason to suspect that the coin is biased. Put another way, you’d like to know if this coin behaves differently from a reference, standard coin that is fair.\nNote this is more common than you might think. It might arise in the following circumstance in “real life.” You have two web pages, your current one and a proposed new one. You’d like to know if seeing the proposed one increases the chance of a viewer clicking through to something. This is called A/B testing and it amounts to comparing the probability of click-through in the reference case to the proposed case."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#null-and-alternative-hypotheses",
    "href": "chapters/04-StatBasics/stat-basics.html#null-and-alternative-hypotheses",
    "title": "Statistical Basics",
    "section": "Null (and alternative) hypotheses",
    "text": "Null (and alternative) hypotheses\nThe Null hypothesis is the hypotheses that our coin is fair, or that our two web pages yield the same results, or more generally that the observations we make are accounted for only by chance and not by some underlying effect. So our null hypothesis for our coin is “P=.5”.\nAn alternative hypothesis is a statement that contradicts the null hypothesis. For example, “P>.5” or “P<.5” or “P is different from .5.”"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#test-statistic",
    "href": "chapters/04-StatBasics/stat-basics.html#test-statistic",
    "title": "Statistical Basics",
    "section": "Test statistic",
    "text": "Test statistic\nA test statistic is a measurement of the data used to draw conclusions about the sample."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#back-to-our-example",
    "href": "chapters/04-StatBasics/stat-basics.html#back-to-our-example",
    "title": "Statistical Basics",
    "section": "Back to our example",
    "text": "Back to our example\nFor our test statistic, we are going to use the fraction of times we get a head in N flips.\nIn the A/B testing situation, our test statistic would be the fraction of times a person “clicked through” when given the proposed web site.\nIntuitively, if the fraction of heads differs significantly from the expected fraction of heads (.5) then we take that as strong evidence for the unfairness of our coin (or the increased value of our proposed web page).\nHow can we quantify this?"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-and-significance",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-and-significance",
    "title": "Statistical Basics",
    "section": "Rejection region and “significance”",
    "text": "Rejection region and “significance”\nTo make things concrete, suppose the coin is fair (in other words, the null hypothesis is true) we flip the coin \\(10\\) times. If the coin is far, we expect to get roughly 5 heads.\nThere’s a long tradition of saying something unlikely is “significant” if the chance of it occurring, assuming the null hypothesis, is less than .05 or one in twenty.\nThe chance of getting \\(0\\), \\(1\\), \\(9\\), or \\(10\\) heads is \\(.02\\). If we allow \\(2\\) or \\(8\\) heads in addition, the chance is about \\(11%\\), so if we set our significance level at \\(.05\\) we reject the null hypothesis if our experiment yields \\(0\\), \\(1\\), \\(9\\), or \\(10\\) heads.\nThis is the “rejection region.”"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-plot-code",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-plot-code",
    "title": "Statistical Basics",
    "section": "Rejection Region (plot code)",
    "text": "Rejection Region (plot code)\n\nlibrary(ggplot2)\n# two-sided\nrejection2 <- function(n,d=10) {\n    results <- data.frame(\n            x=seq(0,n),\n            y=dbinom(seq(0,n),n,.5),\n            keep=sapply(seq(0,n),\n                function(x) \n                    (x<qbinom(.025,n,.5)) | (x>qbinom(.975,n,.5))))\n    ggplot(\n        data=results,aes(x=x,y=y,fill=keep))+ \n        geom_bar(stat=\"identity\")+\n        scale_x_continuous(breaks=seq(0,n,d))+\n        ggtitle(\"Two sided rejection region at alpha=.05\")\n    \n}"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#more-code",
    "href": "chapters/04-StatBasics/stat-basics.html#more-code",
    "title": "Statistical Basics",
    "section": "More code",
    "text": "More code\n\nrejection1 <-function(n,d=10) {\n    results <- data.frame(\n        x=seq(0,n),\n        y=dbinom(seq(0,n),n,.5),\n        keep=sapply(seq(0,n),function(x) (x>qbinom(.95,n,.5))))\n    ggplot(data=results,aes(x=x,y=y,fill=keep))+\n    geom_bar(stat=\"identity\")+\n    scale_x_continuous(breaks=seq(0,n,d))+\n    ggtitle(\"One sided rejection region at alpha=.05\")\n}"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-plotted",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-plotted",
    "title": "Statistical Basics",
    "section": "Rejection Region (plotted)",
    "text": "Rejection Region (plotted)"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-test",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-test",
    "title": "Statistical Basics",
    "section": "One-sided test",
    "text": "One-sided test\nSuppose you want evidence that your coin is more likely to get heads.\n-Your null hypothesis is that your coin has \\(p=.5\\). Your alternative hypothesis is \\(p>.5\\).\n\nThe probability of getting 0,1,2 heads is \\(.054\\), which is a bit larger than \\(.05\\). So the one-sided test would reach significance only at 0 or 1 heads same as the two-sided test.\nBut suppose we did 50 flips? Then the one- and two-sided limits are slightly different on the right."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region",
    "title": "Statistical Basics",
    "section": "One-sided rejection region",
    "text": "One-sided rejection region"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region-1",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region-1",
    "title": "Statistical Basics",
    "section": "One-sided rejection region",
    "text": "One-sided rejection region"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#normal-approximation",
    "href": "chapters/04-StatBasics/stat-basics.html#normal-approximation",
    "title": "Statistical Basics",
    "section": "Normal approximation",
    "text": "Normal approximation\nFor large \\(n\\), the binomial distribution distribution with probability \\(p\\) becomes a version of the normal distribution with mean \\(Np\\) and standard deviation \\(\\sqrt{Np(1-p)}\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#normal-and-binomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#normal-and-binomial-distribution",
    "title": "Statistical Basics",
    "section": "Normal and binomial distribution",
    "text": "Normal and binomial distribution\n\nSo one can use the normal distribution to determine the rejection region if \\(n\\) is large."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#errors",
    "href": "chapters/04-StatBasics/stat-basics.html#errors",
    "title": "Statistical Basics",
    "section": "Errors",
    "text": "Errors\nTwo things can go wrong:\n\nType I error: You reject the null hypothesis, but the null hypothesis is true. The probability of a Type I error is something you choose when you set the significance level. This is usually called \\(\\alpha\\).\nType II error: You accept the null hypothesis when it is false. In this case, you’ve missed an actual effect. This probability of this is called \\(\\beta\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#tradeoff-between-error-types",
    "href": "chapters/04-StatBasics/stat-basics.html#tradeoff-between-error-types",
    "title": "Statistical Basics",
    "section": "Tradeoff between error types",
    "text": "Tradeoff between error types\nOther things equal, if you make \\(\\alpha\\) smaller (thus reducing the chance of a Type I error) you make \\(\\beta\\) bigger (increasing the chance of a type II error)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#statistical-power",
    "href": "chapters/04-StatBasics/stat-basics.html#statistical-power",
    "title": "Statistical Basics",
    "section": "Statistical Power",
    "text": "Statistical Power\nInformally, statistical power measures the ability of an experiment to detect a real effect. If a study has high power, then you are very unlikely to make a Type II error.\nFor example, return to the coin flipping problem (or the A/B testing problem)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power",
    "href": "chapters/04-StatBasics/stat-basics.html#power",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nSuppose we flip our coin \\(20\\) times and our null hypothesis is that \\(p=.5\\) If our significance level is \\(.05\\), we will reject the null hypothesis and conclude that the coin is not fair (and biased towards heads) provided we get \\(15\\) or more heads."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-computations",
    "href": "chapters/04-StatBasics/stat-basics.html#power-computations",
    "title": "Statistical Basics",
    "section": "Power Computations",
    "text": "Power Computations\n\n# look at the probability density for this case\nprobs <- dbinom(seq(0, 20), 20, .5)\n# The qbinom function tells us the threshold\nrejection <- qbinom(.95, 20, .5)\n# We check this by comparing the probability of $15-20$ vs $14-20$ heads:\nsum(probs[16:21]) # remember probs[i] is the chance of i-1 heads\n\n[1] 0.02069473\n\nsum(probs[15:21])\n\n[1] 0.05765915\n\n# The chance of $15-20$ heads is greater than $.05$."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-1",
    "href": "chapters/04-StatBasics/stat-basics.html#power-1",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nNow suppose the coin is not fair and \\(p=.6\\). What is the chance that we accept the null hypothesis and conclude, falsely, that the coin is fair? It is the chance that we get \\(14\\) or fewer heads when \\(p=.6\\).\n\nprobs6 <- dbinom(seq(0, 20), 20, .6)\nsum(probs6[1:15])\n\n[1] 0.874401\n\n\nThis is \\(87\\) percent! In other words, our experiment is very unlikely to detect the unfairness of the coin if the unfairness is only the difference between \\(p=.6\\) and \\(p=.5\\)"
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-2",
    "href": "chapters/04-StatBasics/stat-basics.html#power-2",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nBut if the coin is very unfair, with, say \\(p=.8\\), then we find:\n\nprobs8 <- dbinom(seq(0, 20), 20, .8)\nsum(probs8[1:15])\n\n[1] 0.1957922\n\n\nWe have only a 20% chance of a Type II error so there’s an 80% chance we’ll detect the difference.\nNow suppose we use \\(100\\) flips.\n\nrejection <- qbinom(.95, 100, .5)\nprobs6 <- dbinom(seq(0, 100), 100, .6)\nsum(probs6[1:rejection])\n\n[1] 0.3032601\n\n\nNow we have a 70% chance of detecting the difference unfairness of \\(p=.6\\)."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#more-on-ab-example",
    "href": "chapters/04-StatBasics/stat-basics.html#more-on-ab-example",
    "title": "Statistical Basics",
    "section": "More on AB example",
    "text": "More on AB example\nNull hypothesis: the two ads are the same, and of the 9400 who see an ad, 2108 click through. This is a probabiility of 22.4%.\nThe .95 quantile for the binomial distribution with n=4600 and p=.224 is 1077. Thus the 1133 click through rate is significantly higher. Similarly the 975 out of 4800 is significantly lower.\nSo ad B is better than ad A at the .05 significance level. In fact the odds of getting a number as high as 1133 is more like 1 in 10^4 so the evidence for ad b is overwhelming."
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#simulation",
    "href": "chapters/04-StatBasics/stat-basics.html#simulation",
    "title": "Statistical Basics",
    "section": "Simulation",
    "text": "Simulation\nBy simulation:\n\nsimulated <- rbinom(10000, 4600, .224)\nsum(simulated >= 1133)\n\n[1] 4"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html",
    "title": "Working with data in python/pandas",
    "section": "",
    "text": "import sys\nimport pandas as pd\nimport numpy as np\nimport re\n\nprint(f\"pandas version {pd.__version__}\")\nprint(f\"numpy version {np.__version__}\")\nprint(\"\\n\".join(f\"Python {sys.version}\".split(\"|\")))\n\npandas version 1.5.3\nnumpy version 1.21.5\nPython 3.9.16 (main, Mar  8 2023, 14:00:05) \n[GCC 11.2.0]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#a-comment-on-file-formats",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#a-comment-on-file-formats",
    "title": "Working with data in python/pandas",
    "section": "A comment on file formats",
    "text": "A comment on file formats\nThe most common simple format for tabular data is comma separated or tab separated (csv or tsv).\nNewer formats such as arrow and parquet are more efficient in storage and faster to load.\nPandas 2.0 can handle these newer formats."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#reading-a-dataframe",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#reading-a-dataframe",
    "title": "Working with data in python/pandas",
    "section": "Reading a dataframe",
    "text": "Reading a dataframe\n\n# read from a csv file\npenguins = pd.read_csv(\"data/penguins-raw.csv\")\n# read from a url\n# url = \"https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv\"\n# penguins = pd.read_csv(url)\n# read from an excel file\n# penguins = pd.read_excel('file.xlsx')\nrows, cols = penguins.shape\nprint(f\"Rows: {rows}, Columns: {cols}\")\nprint(f\"Columns:\", \"\\n\".join(penguins.columns))\n\nRows: 344, Columns: 17\nColumns: studyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#series",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#series",
    "title": "Working with data in python/pandas",
    "section": "Series",
    "text": "Series\nEach column of a dataframe is a series accessed by name.\n\npenguins[\"Culmen Length (mm)\"]\n\n0      39.1\n1      39.5\n2      40.3\n3       NaN\n4      36.7\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: Culmen Length (mm), Length: 344, dtype: float64\n\n\nNote the last row: - Name - Length - dtype\nTypes are “inferred” by the read_csv function."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#another-example",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#another-example",
    "title": "Working with data in python/pandas",
    "section": "Another example",
    "text": "Another example\n\npenguins['Date Egg']\n\n0      2007-11-11\n1      2007-11-11\n2      2007-11-16\n3      2007-11-16\n4      2007-11-16\n          ...    \n339    2009-11-19\n340    2009-11-21\n341    2009-11-21\n342    2009-11-21\n343    2009-11-21\nName: Date Egg, Length: 344, dtype: object\n\n\nHere the type is “object” which is the generic python object. But these are clearly supposed to be dates. We’ll fix that later."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#alternative-syntax",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#alternative-syntax",
    "title": "Working with data in python/pandas",
    "section": "Alternative syntax",
    "text": "Alternative syntax\n\n# if the column name is simple, you can use a simpler syntax.\npenguins.Sex\n\n0        MALE\n1      FEMALE\n2      FEMALE\n3         NaN\n4      FEMALE\n        ...  \n339      MALE\n340    FEMALE\n341      MALE\n342      MALE\n343    FEMALE\nName: Sex, Length: 344, dtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#value-counts",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#value-counts",
    "title": "Working with data in python/pandas",
    "section": "Value Counts",
    "text": "Value Counts\nThe value_counts method returns a summary series.\n\npenguins['Island'].value_counts()\n\nBiscoe       168\nDream        124\nTorgersen     52\nName: Island, dtype: int64\n\n\n\npenguins['Species'].value_counts()\n\nAdelie Penguin (Pygoscelis adeliae)          152\nGentoo penguin (Pygoscelis papua)            124\nChinstrap penguin (Pygoscelis antarctica)     68\nName: Species, dtype: int64"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#selecting-a-subset-of-columns",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#selecting-a-subset-of-columns",
    "title": "Working with data in python/pandas",
    "section": "Selecting a subset of columns",
    "text": "Selecting a subset of columns\n\nsimpler = penguins[['Species', 'Body Mass (g)', 'Flipper Length (mm)']]\nsimpler.head()\n\n\n\n\n\n  \n    \n      \n      Species\n      Body Mass (g)\n      Flipper Length (mm)\n    \n  \n  \n    \n      0\n      Adelie Penguin (Pygoscelis adeliae)\n      3750.0\n      181.0\n    \n    \n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      3800.0\n      186.0\n    \n    \n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      3250.0\n      195.0\n    \n    \n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      NaN\n      NaN\n    \n    \n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      3450.0\n      193.0"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#index",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#index",
    "title": "Working with data in python/pandas",
    "section": "Index",
    "text": "Index\nA dataframe has an index, which can be just the numbers from 0 to N as in this case.\n\npenguins.index\n\nRangeIndex(start=0, stop=344, step=1)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#columns-and-rows",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#columns-and-rows",
    "title": "Working with data in python/pandas",
    "section": "Columns and Rows",
    "text": "Columns and Rows\nloc allows you to access individual elements.\n\n# The 23rd row\npenguins.loc[23,:]\n\nstudyName                                          PAL0708\nSample Number                                           24\nSpecies                Adelie Penguin (Pygoscelis adeliae)\nRegion                                              Anvers\nIsland                                              Biscoe\nStage                                   Adult, 1 Egg Stage\nIndividual ID                                        N12A2\nClutch Completion                                      Yes\nDate Egg                                        2007-11-12\nCulmen Length (mm)                                    38.2\nCulmen Depth (mm)                                     18.1\nFlipper Length (mm)                                  185.0\nBody Mass (g)                                       3950.0\nSex                                                   MALE\nDelta 15 N (o/oo)                                  8.43423\nDelta 13 C (o/oo)                                -25.22664\nComments                                               NaN\nName: 23, dtype: object\n\n\n\npenguins.loc[23,'Culmen Length (mm)']\n\n38.2\n\n\n\npenguins.loc[23:28,['Sex','Date Egg']]\n\n\n\n\n\n  \n    \n      \n      Sex\n      Date Egg\n    \n  \n  \n    \n      23\n      MALE\n      2007-11-12\n    \n    \n      24\n      MALE\n      2007-11-10\n    \n    \n      25\n      FEMALE\n      2007-11-10\n    \n    \n      26\n      MALE\n      2007-11-12\n    \n    \n      27\n      FEMALE\n      2007-11-12\n    \n    \n      28\n      FEMALE\n      2007-11-10"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#filtering",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#filtering",
    "title": "Working with data in python/pandas",
    "section": "Filtering",
    "text": "Filtering\nFiltering is done by using a boolean series as an index.\n\npenguins['Sex']=='FEMALE'\n\n0      False\n1       True\n2       True\n3      False\n4       True\n       ...  \n339    False\n340     True\n341    False\n342    False\n343     True\nName: Sex, Length: 344, dtype: bool\n\n\n\nfemales = penguins[penguins['Sex']=='FEMALE']\nfemales.head()\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Species\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Comments\n    \n  \n  \n    \n      1\n      PAL0708\n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A2\n      Yes\n      2007-11-11\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      8.94956\n      -24.69454\n      NaN\n    \n    \n      2\n      PAL0708\n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A1\n      Yes\n      2007-11-16\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      8.36821\n      -25.33302\n      NaN\n    \n    \n      4\n      PAL0708\n      5\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A1\n      Yes\n      2007-11-16\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      8.76651\n      -25.32426\n      NaN\n    \n    \n      6\n      PAL0708\n      7\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N4A1\n      No\n      2007-11-15\n      38.9\n      17.8\n      181.0\n      3625.0\n      FEMALE\n      9.18718\n      -25.21799\n      Nest never observed with full clutch.\n    \n    \n      12\n      PAL0708\n      13\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N7A1\n      Yes\n      2007-11-15\n      41.1\n      17.6\n      182.0\n      3200.0\n      FEMALE\n      NaN\n      NaN\n      Not enough blood for isotopes.\n    \n  \n\n\n\n\nAn alternative syntax is to use query. The quoting rules here can be tricky. The query is a string, and column names are set off by backticks. Using two different types of quotes allows the query to include a string.\n\nfemales = penguins.query(\"`Sex`=='FEMALE'\")\nfemales.head()\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Species\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Comments\n    \n  \n  \n    \n      1\n      PAL0708\n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A2\n      Yes\n      2007-11-11\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      8.94956\n      -24.69454\n      NaN\n    \n    \n      2\n      PAL0708\n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A1\n      Yes\n      2007-11-16\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      8.36821\n      -25.33302\n      NaN\n    \n    \n      4\n      PAL0708\n      5\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A1\n      Yes\n      2007-11-16\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      8.76651\n      -25.32426\n      NaN\n    \n    \n      6\n      PAL0708\n      7\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N4A1\n      No\n      2007-11-15\n      38.9\n      17.8\n      181.0\n      3625.0\n      FEMALE\n      9.18718\n      -25.21799\n      Nest never observed with full clutch.\n    \n    \n      12\n      PAL0708\n      13\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N7A1\n      Yes\n      2007-11-15\n      41.1\n      17.6\n      182.0\n      3200.0\n      FEMALE\n      NaN\n      NaN\n      Not enough blood for isotopes."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#fancier-filtering",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#fancier-filtering",
    "title": "Working with data in python/pandas",
    "section": "Fancier filtering",
    "text": "Fancier filtering\n\npenguins[penguins[\"Flipper Length (mm)\"]>penguins[\"Body Mass (g)\"]/20]\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Species\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Comments\n    \n  \n  \n    \n      2\n      PAL0708\n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A1\n      Yes\n      2007-11-16\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      8.36821\n      -25.33302\n      NaN\n    \n    \n      4\n      PAL0708\n      5\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A1\n      Yes\n      2007-11-16\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      8.76651\n      -25.32426\n      NaN\n    \n    \n      5\n      PAL0708\n      6\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A2\n      Yes\n      2007-11-16\n      39.3\n      20.6\n      190.0\n      3650.0\n      MALE\n      8.66496\n      -25.29805\n      NaN\n    \n    \n      8\n      PAL0708\n      9\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N5A1\n      Yes\n      2007-11-09\n      34.1\n      18.1\n      193.0\n      3475.0\n      NaN\n      NaN\n      NaN\n      No blood sample obtained.\n    \n    \n      10\n      PAL0708\n      11\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N6A1\n      Yes\n      2007-11-09\n      37.8\n      17.1\n      186.0\n      3300.0\n      NaN\n      8.63243\n      -25.21315\n      No blood sample obtained for sexing.\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      339\n      PAL0910\n      64\n      Chinstrap penguin (Pygoscelis antarctica)\n      Anvers\n      Dream\n      Adult, 1 Egg Stage\n      N98A2\n      Yes\n      2009-11-19\n      55.8\n      19.8\n      207.0\n      4000.0\n      MALE\n      9.70465\n      -24.53494\n      NaN\n    \n    \n      340\n      PAL0910\n      65\n      Chinstrap penguin (Pygoscelis antarctica)\n      Anvers\n      Dream\n      Adult, 1 Egg Stage\n      N99A1\n      No\n      2009-11-21\n      43.5\n      18.1\n      202.0\n      3400.0\n      FEMALE\n      9.37608\n      -24.40753\n      Nest never observed with full clutch.\n    \n    \n      341\n      PAL0910\n      66\n      Chinstrap penguin (Pygoscelis antarctica)\n      Anvers\n      Dream\n      Adult, 1 Egg Stage\n      N99A2\n      No\n      2009-11-21\n      49.6\n      18.2\n      193.0\n      3775.0\n      MALE\n      9.46180\n      -24.70615\n      Nest never observed with full clutch.\n    \n    \n      342\n      PAL0910\n      67\n      Chinstrap penguin (Pygoscelis antarctica)\n      Anvers\n      Dream\n      Adult, 1 Egg Stage\n      N100A1\n      Yes\n      2009-11-21\n      50.8\n      19.0\n      210.0\n      4100.0\n      MALE\n      9.98044\n      -24.68741\n      NaN\n    \n    \n      343\n      PAL0910\n      68\n      Chinstrap penguin (Pygoscelis antarctica)\n      Anvers\n      Dream\n      Adult, 1 Egg Stage\n      N100A2\n      Yes\n      2009-11-21\n      50.2\n      18.7\n      198.0\n      3775.0\n      FEMALE\n      9.39305\n      -24.25255\n      NaN\n    \n  \n\n147 rows × 17 columns"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#missing-values",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#missing-values",
    "title": "Working with data in python/pandas",
    "section": "Missing values",
    "text": "Missing values\nDealing with missing values is a central problem in data science. One way to identify how many misssing values are out there is as follows:\n\n## Uses the fact that logical True counts as one, False as zero\n## sum() method sums by columns\npenguins.isna().sum()\n\nstudyName                0\nSample Number            0\nSpecies                  0\nRegion                   0\nIsland                   0\nStage                    0\nIndividual ID            0\nClutch Completion        0\nDate Egg                 0\nCulmen Length (mm)       2\nCulmen Depth (mm)        2\nFlipper Length (mm)      2\nBody Mass (g)            2\nSex                     11\nDelta 15 N (o/oo)       14\nDelta 13 C (o/oo)       13\nComments               290\ndtype: int64\n\n\nNearly all of the comments are empty. What are they?\n\ncomments = penguins['Comments'].value_counts()\ncomments\n\nNest never observed with full clutch.                                   34\nNot enough blood for isotopes.                                           7\nSexing primers did not amplify.                                          4\nNo blood sample obtained.                                                2\nNo blood sample obtained for sexing.                                     2\nAdult not sampled.                                                       1\nNest never observed with full clutch. Not enough blood for isotopes.     1\nSexing primers did not amplify. Not enough blood for isotopes.           1\nAdult not sampled. Nest never observed with full clutch.                 1\nNo delta15N data received from lab.                                      1\nName: Comments, dtype: int64\n\n\nLet’s save the comments separately and look at the rest.\n\n# drop normally drops rows, but with axis=1 it drops columns\npenguins = penguins.drop('Comments',axis=1)\n\nVarious options: - drop rows with missing values - impute the missing values somehow"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#drop-rows-with-missing-values",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#drop-rows-with-missing-values",
    "title": "Working with data in python/pandas",
    "section": "Drop rows with missing values",
    "text": "Drop rows with missing values\n\n# This makes a boolean where a row is True provided at least one of its entries are NA\nna_rows = (penguins.isna().any(axis=1))\nprint(f\"{na_rows.sum()} rows have NA somewhere outside of comments\")\n\n20 rows have NA somewhere outside of comments\n\n\n\n# here we keep rows only if no NA's.  Can also use notna().\npenguins_nona = penguins.loc[~na_rows,:]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#imputation",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#imputation",
    "title": "Working with data in python/pandas",
    "section": "Imputation",
    "text": "Imputation\nWe saw above that culmen length has 2 missing values. We can use fillna to replace the missing values with something (like the mean or median or zero).\n\n# using equality w/o copy creates another reference.\npenguins_imputed = penguins.copy()\nculmen_mean = penguins_imputed['Culmen Length (mm)'].mean() # how does this handle NA values?\nprint(f\"Culmen length mean is {culmen_mean}\")\npenguins_imputed['Culmen Length (mm)'] = penguins_imputed['Culmen Length (mm)'].fillna(culmen_mean)\n\nCulmen length mean is 43.9219298245614\n\n\nThere are many other imputation methods. For example, if the data is ordered, you can fill missing data with linear interpolation. (See the interpolate method)."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#data-types",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#data-types",
    "title": "Working with data in python/pandas",
    "section": "Data types",
    "text": "Data types\nAs we saw above, the types of the columns are inferred when the data is read. But it’s not always correct. For example, the “Date Egg” column is supposed to be a date but it’s shown as a generic python object.\nUsing the correct type can greatly improve performance as generic Python arguments are inefficient.\nIn pandas 1.0 strings are always treated as objects but in pandas 2.0 there is a StringDtype.\nThe most common types are: - object - float64 - datetime (datetime64[ns]) - int64 - bool\nOne may also find categorical types.\n\npenguins.dtypes\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\ndtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#setting-datatypes",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#setting-datatypes",
    "title": "Working with data in python/pandas",
    "section": "Setting datatypes",
    "text": "Setting datatypes\nHere’s an example where we manually make sex a categorical type.\n\npenguins = penguins.astype({'Sex':'category'})\npenguins['Sex']\n\n0        MALE\n1      FEMALE\n2      FEMALE\n3         NaN\n4      FEMALE\n        ...  \n339      MALE\n340    FEMALE\n341      MALE\n342      MALE\n343    FEMALE\nName: Sex, Length: 344, dtype: category\nCategories (2, object): ['FEMALE', 'MALE']\n\n\nOne can also pass a dictionary setting the types of columns as an argument when you read them from the csv file."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#creating-new-columns",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#creating-new-columns",
    "title": "Working with data in python/pandas",
    "section": "Creating new columns",
    "text": "Creating new columns\nSimplifying the species name.\n\ndef first_word(x):\n    return x.split()[0]\npenguins['SimpleSpecies'] = penguins['Species'].map(first_word)\n\nRewriting the body mass in kilograms.\n\npenguins['Body Mass (kg)'] = penguins['Body Mass (g)']/1000"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#sorting",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#sorting",
    "title": "Working with data in python/pandas",
    "section": "Sorting",
    "text": "Sorting\n\npenguins_small = penguins[['Species','Island','Body Mass (g)']]\npenguins_small.sort_values('Body Mass (g)')\n# ascending = False for descending order\n# na_position = 'first' or 'last' (default is 'last')\n# can also provide a key which is a function of prototype Series -> Series\n# inplace = True doesn't return a new dataframe, sorts the given one in place\n\n\n\n\n\n  \n    \n      \n      Species\n      Island\n      Body Mass (g)\n    \n  \n  \n    \n      314\n      Chinstrap penguin (Pygoscelis antarctica)\n      Dream\n      2700.0\n    \n    \n      64\n      Adelie Penguin (Pygoscelis adeliae)\n      Biscoe\n      2850.0\n    \n    \n      58\n      Adelie Penguin (Pygoscelis adeliae)\n      Biscoe\n      2850.0\n    \n    \n      116\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      2900.0\n    \n    \n      98\n      Adelie Penguin (Pygoscelis adeliae)\n      Dream\n      2900.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      269\n      Gentoo penguin (Pygoscelis papua)\n      Biscoe\n      6000.0\n    \n    \n      185\n      Gentoo penguin (Pygoscelis papua)\n      Biscoe\n      6050.0\n    \n    \n      169\n      Gentoo penguin (Pygoscelis papua)\n      Biscoe\n      6300.0\n    \n    \n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      NaN\n    \n    \n      271\n      Gentoo penguin (Pygoscelis papua)\n      Biscoe\n      NaN\n    \n  \n\n344 rows × 3 columns"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#grouping",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#grouping",
    "title": "Working with data in python/pandas",
    "section": "Grouping",
    "text": "Grouping\nGrouping is a powerful tool. Let’s first group our penguins by species. The result is a “grouped” object which needs to pass through a summarize operation to be useful.\n\npenguins_by_species = penguins.groupby('Species')\npenguins_by_species\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f29842ccd00>"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#summarizing",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#summarizing",
    "title": "Working with data in python/pandas",
    "section": "Summarizing",
    "text": "Summarizing\n\n# describe computes basic descriptive statistics\npenguins_by_species['Body Mass (g)'].describe()\n\n\n\n\n\n  \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      Species\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Adelie Penguin (Pygoscelis adeliae)\n      151.0\n      3700.662252\n      458.566126\n      2850.0\n      3350.0\n      3700.0\n      4000.0\n      4775.0\n    \n    \n      Chinstrap penguin (Pygoscelis antarctica)\n      68.0\n      3733.088235\n      384.335081\n      2700.0\n      3487.5\n      3700.0\n      3950.0\n      4800.0\n    \n    \n      Gentoo penguin (Pygoscelis papua)\n      123.0\n      5076.016260\n      504.116237\n      3950.0\n      4700.0\n      5000.0\n      5500.0\n      6300.0\n    \n  \n\n\n\n\n\n# this fails because some columns aren't numeric\npenguins_by_species.mean(numeric_only=True)\n\n\n\n\n\n  \n    \n      \n      Sample Number\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Body Mass (kg)\n    \n    \n      Species\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Adelie Penguin (Pygoscelis adeliae)\n      76.5\n      38.791391\n      18.346358\n      189.953642\n      3700.662252\n      8.859733\n      -25.804194\n      3.700662\n    \n    \n      Chinstrap penguin (Pygoscelis antarctica)\n      34.5\n      48.833824\n      18.420588\n      195.823529\n      3733.088235\n      9.356155\n      -24.546542\n      3.733088\n    \n    \n      Gentoo penguin (Pygoscelis papua)\n      62.5\n      47.504878\n      14.982114\n      217.186992\n      5076.016260\n      8.245338\n      -26.185298\n      5.076016\n    \n  \n\n\n\n\n\npenguins_by_species.count()\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      SimpleSpecies\n      Body Mass (kg)\n    \n    \n      Species\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Adelie Penguin (Pygoscelis adeliae)\n      152\n      152\n      152\n      152\n      152\n      152\n      152\n      152\n      151\n      151\n      151\n      151\n      146\n      141\n      141\n      152\n      151\n    \n    \n      Chinstrap penguin (Pygoscelis antarctica)\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      68\n      67\n      68\n      68\n      68\n    \n    \n      Gentoo penguin (Pygoscelis papua)\n      124\n      124\n      124\n      124\n      124\n      124\n      124\n      124\n      123\n      123\n      123\n      123\n      119\n      122\n      122\n      124\n      123"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#multiindex",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#multiindex",
    "title": "Working with data in python/pandas",
    "section": "MultiIndex",
    "text": "MultiIndex\n\npenguins_by_sex_and_species = penguins.groupby(['Sex','Species'])\npenguins_by_sex_and_species['Body Mass (g)'].describe().round()\n\n\n\n\n\n  \n    \n      \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      Sex\n      Species\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      FEMALE\n      Adelie Penguin (Pygoscelis adeliae)\n      73.0\n      3369.0\n      269.0\n      2850.0\n      3175.0\n      3400.0\n      3550.0\n      3900.0\n    \n    \n      Chinstrap penguin (Pygoscelis antarctica)\n      34.0\n      3527.0\n      285.0\n      2700.0\n      3362.0\n      3550.0\n      3694.0\n      4150.0\n    \n    \n      Gentoo penguin (Pygoscelis papua)\n      58.0\n      4680.0\n      282.0\n      3950.0\n      4462.0\n      4700.0\n      4875.0\n      5200.0\n    \n    \n      MALE\n      Adelie Penguin (Pygoscelis adeliae)\n      73.0\n      4043.0\n      347.0\n      3325.0\n      3800.0\n      4000.0\n      4300.0\n      4775.0\n    \n    \n      Chinstrap penguin (Pygoscelis antarctica)\n      34.0\n      3939.0\n      362.0\n      3250.0\n      3731.0\n      3950.0\n      4100.0\n      4800.0\n    \n    \n      Gentoo penguin (Pygoscelis papua)\n      61.0\n      5485.0\n      313.0\n      4750.0\n      5300.0\n      5500.0\n      5700.0\n      6300.0\n    \n  \n\n\n\n\n\n# pivot tables\npenguins_by_sex_and_species['Body Mass (g)'].mean().reset_index().pivot(index='Sex',columns='Species',values='Body Mass (g)')\n\n\n\n\n\n  \n    \n      Species\n      Adelie Penguin (Pygoscelis adeliae)\n      Chinstrap penguin (Pygoscelis antarctica)\n      Gentoo penguin (Pygoscelis papua)\n    \n    \n      Sex\n      \n      \n      \n    \n  \n  \n    \n      FEMALE\n      3368.835616\n      3527.205882\n      4679.741379\n    \n    \n      MALE\n      4043.493151\n      3938.970588\n      5484.836066"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#pandas-plotting",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#pandas-plotting",
    "title": "Working with data in python/pandas",
    "section": "Pandas plotting",
    "text": "Pandas plotting\nSome simple plots are available directly from pandas.\n\npenguins[penguins['Species'].str.startswith(\"Adel\")].groupby(['Sex'])['Body Mass (g)'].hist(bins=30,legend=True)\n\nSex\nFEMALE    Axes(0.125,0.11;0.775x0.77)\nMALE      Axes(0.125,0.11;0.775x0.77)\nName: Body Mass (g), dtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#excel-files",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#excel-files",
    "title": "Working with data in python/pandas",
    "section": "Excel files",
    "text": "Excel files\nWe can read an excel file. This particular one is complicated for various reasons, including the fact that the column heads are in the third row, not at the top. Also there are a bunch of footnotes starting in row 510 that we don’t want. So we don’t read them in.\n\ncrime2019 = pd.read_excel(\"data/Violent Crime-by state-2019-table-5.xls\",header=3,nrows=510)\ncrime2019\n\n\n\n\n\n  \n    \n      \n      State\n      Area\n      Unnamed: 2\n      Population\n      Violent \\ncrime1\n      Murder and \\nnonnegligent \\nmanslaughter\n      Rape2\n      Robbery\n      Aggravated \\nassault\n      Property \\ncrime\n      Burglary\n      Larceny-theft\n      Motor \\nvehicle \\ntheft\n    \n  \n  \n    \n      0\n      ALABAMA\n      Metropolitan Statistical Area\n      NaN\n      3728978\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n      Area actually reporting\n      0.766\n      12880\n      182.0\n      1141.0\n      1706.0\n      9851\n      65789\n      12388.0\n      47299.0\n      6102.0\n    \n    \n      2\n      NaN\n      NaN\n      Estimated total\n      1\n      19951\n      300.0\n      1542.0\n      3432.0\n      14677\n      104658\n      20728.0\n      73857.0\n      10073.0\n    \n    \n      3\n      NaN\n      Cities outside metropolitan areas\n      NaN\n      528518\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n      Area actually reporting\n      0.893\n      3327\n      36.0\n      297.0\n      266.0\n      2728\n      17915\n      3140.0\n      13382.0\n      1393.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      505\n      NaN\n      Nonmetropolitan counties\n      NaN\n      160615\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      506\n      NaN\n      NaN\n      Area actually reporting\n      0.921\n      194\n      0.0\n      39.0\n      0.0\n      155\n      973\n      170.0\n      716.0\n      87.0\n    \n    \n      507\n      NaN\n      NaN\n      Estimated total\n      1\n      213\n      0.0\n      42.0\n      0.0\n      171\n      1065\n      188.0\n      781.0\n      96.0\n    \n    \n      508\n      NaN\n      State Total\n      NaN\n      578759\n      1258\n      13.0\n      324.0\n      67.0\n      854\n      9093\n      1396.0\n      6984.0\n      713.0\n    \n    \n      509\n      NaN\n      NaN\n      Rate per 100,000 inhabitants\n      NaN\n      217.4\n      2.2\n      56.0\n      11.6\n      147.6\n      1571.1\n      241.2\n      1206.7\n      123.2\n    \n  \n\n510 rows × 13 columns\n\n\n\nThe column names have newlines in them and we’d like to get rid of those.\n\ncrime2019.columns = [x.replace(\" \\n\",\"_\") for x in crime2019.columns]\ncrime2019\n\n\n\n\n\n  \n    \n      \n      State\n      Area\n      Unnamed: 2\n      Population\n      Violent_crime1\n      Murder and_nonnegligent_manslaughter\n      Rape2\n      Robbery\n      Aggravated_assault\n      Property_crime\n      Burglary\n      Larceny-theft\n      Motor_vehicle_theft\n    \n  \n  \n    \n      0\n      ALABAMA\n      Metropolitan Statistical Area\n      NaN\n      3728978\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n      Area actually reporting\n      0.766\n      12880\n      182.0\n      1141.0\n      1706.0\n      9851\n      65789\n      12388.0\n      47299.0\n      6102.0\n    \n    \n      2\n      NaN\n      NaN\n      Estimated total\n      1\n      19951\n      300.0\n      1542.0\n      3432.0\n      14677\n      104658\n      20728.0\n      73857.0\n      10073.0\n    \n    \n      3\n      NaN\n      Cities outside metropolitan areas\n      NaN\n      528518\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n      Area actually reporting\n      0.893\n      3327\n      36.0\n      297.0\n      266.0\n      2728\n      17915\n      3140.0\n      13382.0\n      1393.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      505\n      NaN\n      Nonmetropolitan counties\n      NaN\n      160615\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      506\n      NaN\n      NaN\n      Area actually reporting\n      0.921\n      194\n      0.0\n      39.0\n      0.0\n      155\n      973\n      170.0\n      716.0\n      87.0\n    \n    \n      507\n      NaN\n      NaN\n      Estimated total\n      1\n      213\n      0.0\n      42.0\n      0.0\n      171\n      1065\n      188.0\n      781.0\n      96.0\n    \n    \n      508\n      NaN\n      State Total\n      NaN\n      578759\n      1258\n      13.0\n      324.0\n      67.0\n      854\n      9093\n      1396.0\n      6984.0\n      713.0\n    \n    \n      509\n      NaN\n      NaN\n      Rate per 100,000 inhabitants\n      NaN\n      217.4\n      2.2\n      56.0\n      11.6\n      147.6\n      1571.1\n      241.2\n      1206.7\n      123.2\n    \n  \n\n510 rows × 13 columns\n\n\n\nLet’s look at the states.\n\nstates = crime2019[\"State\"].dropna().values\nstates\n\narray(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA',\n       'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA3',\n       'FLORIDA', 'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA',\n       'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND',\n       'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI4',\n       'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE',\n       'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA',\n       'NORTH DAKOTA', 'OHIO4', 'OKLAHOMA', 'OREGON4', 'PENNSYLVANIA',\n       'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',\n       'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON',\n       'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'], dtype=object)\n\n\nSome have footnotes at the end. We don’t want them.\n\nstates = [re.sub(\"[0-9$]\",\"\",x) for x in states]\nstates\n\n['ALABAMA',\n 'ALASKA',\n 'ARIZONA',\n 'ARKANSAS',\n 'CALIFORNIA',\n 'COLORADO',\n 'CONNECTICUT',\n 'DELAWARE',\n 'DISTRICT OF COLUMBIA',\n 'FLORIDA',\n 'GEORGIA',\n 'HAWAII',\n 'IDAHO',\n 'ILLINOIS',\n 'INDIANA',\n 'IOWA',\n 'KANSAS',\n 'KENTUCKY',\n 'LOUISIANA',\n 'MAINE',\n 'MARYLAND',\n 'MASSACHUSETTS',\n 'MICHIGAN',\n 'MINNESOTA',\n 'MISSISSIPPI',\n 'MISSOURI',\n 'MONTANA',\n 'NEBRASKA',\n 'NEVADA',\n 'NEW HAMPSHIRE',\n 'NEW JERSEY',\n 'NEW MEXICO',\n 'NEW YORK',\n 'NORTH CAROLINA',\n 'NORTH DAKOTA',\n 'OHIO',\n 'OKLAHOMA',\n 'OREGON',\n 'PENNSYLVANIA',\n 'PUERTO RICO',\n 'RHODE ISLAND',\n 'SOUTH CAROLINA',\n 'SOUTH DAKOTA',\n 'TENNESSEE',\n 'TEXAS',\n 'UTAH',\n 'VERMONT',\n 'VIRGINIA',\n 'WASHINGTON',\n 'WEST VIRGINIA',\n 'WISCONSIN',\n 'WYOMING']\n\n\n] We don’t want to include DC or Puerto Rico.\n\nstates = [x for x in states if x!='DISTRICT OF COLUMBIA' and x!='PUERTO RICO']\nstates\n\n['ALABAMA',\n 'ALASKA',\n 'ARIZONA',\n 'ARKANSAS',\n 'CALIFORNIA',\n 'COLORADO',\n 'CONNECTICUT',\n 'DELAWARE',\n 'FLORIDA',\n 'GEORGIA',\n 'HAWAII',\n 'IDAHO',\n 'ILLINOIS',\n 'INDIANA',\n 'IOWA',\n 'KANSAS',\n 'KENTUCKY',\n 'LOUISIANA',\n 'MAINE',\n 'MARYLAND',\n 'MASSACHUSETTS',\n 'MICHIGAN',\n 'MINNESOTA',\n 'MISSISSIPPI',\n 'MISSOURI',\n 'MONTANA',\n 'NEBRASKA',\n 'NEVADA',\n 'NEW HAMPSHIRE',\n 'NEW JERSEY',\n 'NEW MEXICO',\n 'NEW YORK',\n 'NORTH CAROLINA',\n 'NORTH DAKOTA',\n 'OHIO',\n 'OKLAHOMA',\n 'OREGON',\n 'PENNSYLVANIA',\n 'RHODE ISLAND',\n 'SOUTH CAROLINA',\n 'SOUTH DAKOTA',\n 'TENNESSEE',\n 'TEXAS',\n 'UTAH',\n 'VERMONT',\n 'VIRGINIA',\n 'WASHINGTON',\n 'WEST VIRGINIA',\n 'WISCONSIN',\n 'WYOMING']\n\n\nFinally, we want to pull out the violent crime numbers for the total area of the state. Notice that Puerto Rico and DC use “Total”, not “State Total”, for Area and so they will be excluded.\n\nvcrime2019 = crime2019[crime2019['Area'] == 'State Total']['Violent_crime1'].values\nvcrime2019\n\narray([25046, 6343, 33141, 17643, 174331, 21938, 6546, 4115, 81270, 36170,\n       4042, 4000, 51561, 24966, 8410, 11968, 9701, 25537, 1548, 27456,\n       22578, 43686, 13332, 8272, 30380, 4328, 5821, 15210, 2074, 18375,\n       17450, 69764, 38995, 2169, 34269, 17086, 11995, 39228, 2342, 26323,\n       3530, 40647, 121474, 7553, 1262, 17753, 22377, 5674, 17070, 1258],\n      dtype=object)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html",
    "href": "chapters/05-WorkingWithData/pythonAndR.html",
    "title": "Data Structures and Functions in R and Python",
    "section": "",
    "text": "Both R and Python have data structures like excel spreadsheets that are the basic way to organize tabular data.\nIn R, these tools are packaged together in a family of libraries called the tidyverse.\nIn Python they are packaged in two closely related libraries, numpy (which handles numerical linear algebra) and pandas which handles tabular data.\nIn Python, these tabular data structures are called dataframes; in R they are called tibbles (there are dataframes in R as well but the tidyverse package mainly uses tibbles.)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#features",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#features",
    "title": "Data Structures and Functions in R and Python",
    "section": "Features",
    "text": "Features\nThe basic operations that both R and Python offer are\n\nmapping a function to a column of data and creating a new column\nselecting a particular column\nfiltering to select rows where column entries meet a condition\ngrouping rows by keys\nsummarizing data by computing sums, counts, averages, variances, and so on."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#visualization",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#visualization",
    "title": "Data Structures and Functions in R and Python",
    "section": "Visualization",
    "text": "Visualization\nIn addition, both R and Python have plotting libraries that rely on dataframes/tibbles as input and libraries that apply ML algorithms to tabular data stored in dataframes/tibbles."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#walkthroughs",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#walkthroughs",
    "title": "Data Structures and Functions in R and Python",
    "section": "Walkthroughs",
    "text": "Walkthroughs\n\nR/basics of R programming\nR/tidyverse walkthrough\nPython/basics of python programming\nPython/pandas walkthrough\n\nTo download the materials including the data so you can work with them locally, follow this link."
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html",
    "href": "chapters/05-WorkingWithData/python_programming.html",
    "title": "Basics of Programming in Python",
    "section": "",
    "text": "Key ingredients of programming language:\n\ndata types and data structures\nfunctions\ncontrol flow (iteration and logical branches)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#key-data-types-in-python",
    "href": "chapters/05-WorkingWithData/python_programming.html#key-data-types-in-python",
    "title": "Basics of Programming in Python",
    "section": "Key data types in python",
    "text": "Key data types in python\n\nnumbers (integers and floating point)\nstrings\nlists\nnumpy arrays (*)\ndictionaries\npandas dataframes (*)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#basic-examples",
    "href": "chapters/05-WorkingWithData/python_programming.html#basic-examples",
    "title": "Basics of Programming in Python",
    "section": "Basic examples",
    "text": "Basic examples\nFrom before, remember:\n\nn = 56  # integer\nm = 1234.48  # floating point\nL = [1, 2, 3, 4]  # list\nname = \"Jeremy\"  # string\n\nThe typeof operator tells you what something is.\n\nprint(\"type of n is {}, type of name is {}\".format(type(n), type(name)))\n\ntype of n is <class 'int'>, type of name is <class 'str'>"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#working-with-lists-and-strings",
    "href": "chapters/05-WorkingWithData/python_programming.html#working-with-lists-and-strings",
    "title": "Basics of Programming in Python",
    "section": "Working with Lists and Strings",
    "text": "Working with Lists and Strings\nSplit a string to a list.\n\nL = list(\"My name is Jeremy\")\nprint(L)\n\n['M', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'J', 'e', 'r', 'e', 'm', 'y']\n\n\nJoin a list to a string.\n\nprint(''.join([\"A\",\"B\",\"C\"]))\nprint('_'.join([\"A\",\"B\",\"C\"]))\n\nABC\nA_B_C"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#dictionaries",
    "href": "chapters/05-WorkingWithData/python_programming.html#dictionaries",
    "title": "Basics of Programming in Python",
    "section": "Dictionaries",
    "text": "Dictionaries\nA dictionary (or a HashMap, or an associative array) is like an array with arbitrary subscripts.\n\nD = {\"first_name\": \"Jeremy\", \"last_name\": \"Teitelbaum\"}\nD[\"middle_name\"] = \"Thau\"\nprint(D[\"first_name\"])\nD[\"Title\"] = \"Emperor\"\nprint(D)\n# D[\"Subtitle\"]\n\nJeremy\n{'first_name': 'Jeremy', 'last_name': 'Teitelbaum', 'middle_name': 'Thau', 'Title': 'Emperor'}"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#arrays",
    "href": "chapters/05-WorkingWithData/python_programming.html#arrays",
    "title": "Basics of Programming in Python",
    "section": "Arrays",
    "text": "Arrays\n\nimport numpy as np\n\nx=np.array([1,2,3,4])\nx=np.linspace(-5,5,10)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#booleans",
    "href": "chapters/05-WorkingWithData/python_programming.html#booleans",
    "title": "Basics of Programming in Python",
    "section": "Booleans",
    "text": "Booleans\n\nT = True\nF = False\nprint(T or F) # or\nprint(T and F) # and \n3 == 5 # equality\n3 > 5 # \n3 < 5 #\nx = (3 <= 5) #\nprint(x)\ny = (3 != 5) #\nprint(y)\n\nTrue\nFalse\nTrue\nTrue"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#functions",
    "href": "chapters/05-WorkingWithData/python_programming.html#functions",
    "title": "Basics of Programming in Python",
    "section": "Functions",
    "text": "Functions\n\nimport scipy.stats as sps\n\ndef my_function(n,mu,s):\n    x = sps.norm.rvs(mu,s,size=n)\n    return x\n\nImportant concepts: - arguments - scope - return values"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#scope",
    "href": "chapters/05-WorkingWithData/python_programming.html#scope",
    "title": "Basics of Programming in Python",
    "section": "Scope",
    "text": "Scope\nBasic rule of scope: Variables created inside functions are completely separate from those outside the function, changing them has no effect.\nException: some operations (such as list append) modify an element in place and in these cases you may end up modifying something.\n\ndef f(a,b):\n    x=a+b\n    return x\n\n\nx=3\nprint(\"before executing f, x={}\".format(x))\nprint(f(2,5))\nprint(\"after executing f, x={}\".format(x))\n\nbefore executing f, x=3\n7\nafter executing f, x=3\n\n\n\ndef f(x):\n    x=x+[\"d\"]\n    return x\n\nL=[\"a\",\"b\",\"c\"]\nprint(\"L before is {}\".format(L))\nprint(\"result of f(L) is {}\".format(f(L)))\nprint(\"L after is {}\".format(L))\n\nL before is ['a', 'b', 'c']\nresult of f(L) is ['a', 'b', 'c', 'd']\nL after is ['a', 'b', 'c']\n\n\n\ndef f(x):\n    x.append(\"d\") #\n    return x\n\n# Warning\nx = [\"a\",\"b\",\"c\"]\nprint(f(x))\nprint(x)\n\n['a', 'b', 'c', 'd']\n['a', 'b', 'c', 'd']\n\n\n\nx = 55\n\ndef f(n):\n    n = n+x\n    return n\n\nf(24)\n\n79"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#iteration",
    "href": "chapters/05-WorkingWithData/python_programming.html#iteration",
    "title": "Basics of Programming in Python",
    "section": "Iteration",
    "text": "Iteration\n\nfor x in range(10):\n    print(x,end=',')\nprint('\\n---')\n\nfor x in [\"a\",\"b\",\"c\"]:\n    print(x,end=',')\n\n# Also available: while\n\n0,1,2,3,4,5,6,7,8,9,\n---\na,b,c,"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#logic",
    "href": "chapters/05-WorkingWithData/python_programming.html#logic",
    "title": "Basics of Programming in Python",
    "section": "Logic",
    "text": "Logic\n\nif 3<5:\n    print(\"ha\")\nelse:\n    print(\"ba\")\n\nha\n\n\n\nif 3+5==8 and 3-5==-2:\n    print(\"Yeah!\")\nelse:\n    print(\"Nah!\")\n\nYeah!\n\n\n\nif 3+5 in [1,2,3,4,5,6,7]:\n    print(\"Yeah\")\nelse:\n    print(\"nah!\")\n\nnah!"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#list-comprehensions",
    "href": "chapters/05-WorkingWithData/python_programming.html#list-comprehensions",
    "title": "Basics of Programming in Python",
    "section": "List Comprehensions",
    "text": "List Comprehensions\nThis is one of the most useful things about python.\n\nL = [\"hello\",\"Hello\",\"HELLO\",\"jeremy\",\"jereMy\"]\nN = [f(x) for x in L]\nM = [f(x) for x in L if x[0]==\"H\"]\nprint(N,M)\n\n['helloc', 'Helloc', 'HELLOc', 'jeremyc', 'jereMyc'] ['Helloc', 'HELLOc']\n\n\nAnother example.\n\ns=\"Jeremy Teitelbaum\"\nL=[x for x in list(s) if x not in [\" \"]]\nprint(L)\n\n['J', 'e', 'r', 'e', 'm', 'y', 'T', 'e', 'i', 't', 'e', 'l', 'b', 'a', 'u', 'm']\n\n\nCompare:\n\nS=\"\"\nfor x in \"Jeremy Teitelbaum\":\n    if x not in [\" \"]:\n        S+=x"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#a-few-other-tricks",
    "href": "chapters/05-WorkingWithData/python_programming.html#a-few-other-tricks",
    "title": "Basics of Programming in Python",
    "section": "A few other tricks",
    "text": "A few other tricks\n\ndefault arguments\ndocstrings\n\n\ndef f(x=0,y=1):\n    return x+y\n\nprint(f())\nprint(f(1))\nprint(f(3,4))\n\n1\n2\n7\n\n\n\ndef first_letter_cap(s):\n    \"Returns s but first letter of string is upper case\"\n    return s[0].upper()+s[1:]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#some-examples",
    "href": "chapters/05-WorkingWithData/python_programming.html#some-examples",
    "title": "Basics of Programming in Python",
    "section": "Some examples",
    "text": "Some examples\nTake a string and make its first character upper case and the rest lower.\n\ndef f(s):\n    l = s[0].upper()+s[1:].lower()\n    return l\n\nprint(f(\"hello\"),f(\"Hello\"),f(\"HELLO\"))\n\nHello Hello Hello\n\n\nNow do this for each element of a list.\n\ndef h(L):\n    N=[]\n    for x in L:\n        N = N + [f(x)]\n    return N\n\nh([\"hello\",\"HELLO\",\"jeremy\",\"JEREMY\",\"jerEmy\"])\n\n['Hello', 'Hello', 'Jeremy', 'Jeremy', 'Jeremy']"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#problems",
    "href": "chapters/05-WorkingWithData/python_programming.html#problems",
    "title": "Basics of Programming in Python",
    "section": "Problems",
    "text": "Problems\n\nWrite a function which takes a string and standardizes it by:\n\nremoves all characters which are not letters, numbers, or spaces\nmakes all the letters lower case\nreplacing all spaces by underscore ’_’\n\n\nHint: convert the string to a vector of letters.\n\nThe penguins_raw.csv file can get loaded into a pandas dataframe, which is a fancy type of tabular layout. It has named columns that you can extract with .columns\n\n\nimport pandas as pd\npenguins_raw = pd.read_csv(\"data/penguins-raw.csv\")\npenguins_raw.columns\n\nIndex(['studyName', 'Sample Number', 'Species', 'Region', 'Island', 'Stage',\n       'Individual ID', 'Clutch Completion', 'Date Egg', 'Culmen Length (mm)',\n       'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex',\n       'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)', 'Comments'],\n      dtype='object')\n\n\nYou can assign to penguins_raw.columns to change the column names. Use your function from part 1 to standardize and simplify the column names.\n\nYou can access a column of the dataframe using ., so for example penguins_raw.Species should give you the column species. Replace this column with just the first word of the species name (Gentoo, Adelie, Chinstrap). To do this, you have to use the map method. If f is a function that picks out the first word of a string, then penguins_raw.species.map(f) returns the result of applying f to every element of penguins_raw.species.\nLet \\(n\\) be a positive real number and let \\(x_0\\) be 1. The iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\n\nconverges to the square root of \\(n\\). (This is Newton’s Method). Write an R function which computes the square root using this iteration. You should continue to iterate until \\(x_{k+1}\\) is within \\(10^{-6}\\) of \\(x_{k}\\).\n\n# def f(n):\n# \n# ...\n\nSuppose you want to save the successive values you computed during the iteration for plotting purposes. How could you do that (and return them)?\nSuppose you want the tolerance (here \\(10^{6}\\)) to be a parameter?\nSuppose you want to set a maximum number of iterations, in case something goes wrong, to prevent an infinite loop?"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_penguins.html",
    "href": "chapters/05-WorkingWithData/r_penguins.html",
    "title": "Working with data in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\ncat(paste(R.version$version.string, \"\\n\"))\n\nR version 4.3.1 (2023-06-16) \n\n\n\n\n\n\npenguins <- read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\ncat(\"Rows:\", nrow(penguins), \", Columns:\", ncol(penguins), \"\\n\")\n\nRows: 344 , Columns: 17 \n\n\n\n\n\n\ncat(\"Columns:\\n\")\n\nColumns:\n\nprint(colnames(penguins))\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n\n\n\n\nsimpler <- penguins |> select(`Species`, `Body Mass (g)`, `Flipper Length (mm)`)\nhead(simpler)\n\n# A tibble: 6 × 3\n  Species                             `Body Mass (g)` `Flipper Length (mm)`\n  <chr>                                         <dbl>                 <dbl>\n1 Adelie Penguin (Pygoscelis adeliae)            3750                   181\n2 Adelie Penguin (Pygoscelis adeliae)            3800                   186\n3 Adelie Penguin (Pygoscelis adeliae)            3250                   195\n4 Adelie Penguin (Pygoscelis adeliae)              NA                    NA\n5 Adelie Penguin (Pygoscelis adeliae)            3450                   193\n6 Adelie Penguin (Pygoscelis adeliae)            3650                   190\n\n\n\n\n\n\nprint(rownames(penguins))\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\" \"151\" \"152\" \"153\" \"154\" \"155\" \"156\"\n[157] \"157\" \"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\"\n[169] \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\"\n[181] \"181\" \"182\" \"183\" \"184\" \"185\" \"186\" \"187\" \"188\" \"189\" \"190\" \"191\" \"192\"\n[193] \"193\" \"194\" \"195\" \"196\" \"197\" \"198\" \"199\" \"200\" \"201\" \"202\" \"203\" \"204\"\n[205] \"205\" \"206\" \"207\" \"208\" \"209\" \"210\" \"211\" \"212\" \"213\" \"214\" \"215\" \"216\"\n[217] \"217\" \"218\" \"219\" \"220\" \"221\" \"222\" \"223\" \"224\" \"225\" \"226\" \"227\" \"228\"\n[229] \"229\" \"230\" \"231\" \"232\" \"233\" \"234\" \"235\" \"236\" \"237\" \"238\" \"239\" \"240\"\n[241] \"241\" \"242\" \"243\" \"244\" \"245\" \"246\" \"247\" \"248\" \"249\" \"250\" \"251\" \"252\"\n[253] \"253\" \"254\" \"255\" \"256\" \"257\" \"258\" \"259\" \"260\" \"261\" \"262\" \"263\" \"264\"\n[265] \"265\" \"266\" \"267\" \"268\" \"269\" \"270\" \"271\" \"272\" \"273\" \"274\" \"275\" \"276\"\n[277] \"277\" \"278\" \"279\" \"280\" \"281\" \"282\" \"283\" \"284\" \"285\" \"286\" \"287\" \"288\"\n[289] \"289\" \"290\" \"291\" \"292\" \"293\" \"294\" \"295\" \"296\" \"297\" \"298\" \"299\" \"300\"\n[301] \"301\" \"302\" \"303\" \"304\" \"305\" \"306\" \"307\" \"308\" \"309\" \"310\" \"311\" \"312\"\n[313] \"313\" \"314\" \"315\" \"316\" \"317\" \"318\" \"319\" \"320\" \"321\" \"322\" \"323\" \"324\"\n[325] \"325\" \"326\" \"327\" \"328\" \"329\" \"330\" \"331\" \"332\" \"333\" \"334\" \"335\" \"336\"\n[337] \"337\" \"338\" \"339\" \"340\" \"341\" \"342\" \"343\" \"344\"\n\n\n\n\n\n\npenguins[23, ]\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  <chr>               <dbl> <chr>            <chr>  <chr>  <chr> <chr>          \n1 PAL0708                23 Adelie Penguin … Anvers Biscoe Adul… N12A1          \n# ℹ 10 more variables: `Clutch Completion` <chr>, `Date Egg` <date>,\n#   `Culmen Length (mm)` <dbl>, `Culmen Depth (mm)` <dbl>,\n#   `Flipper Length (mm)` <dbl>, `Body Mass (g)` <dbl>, Sex <chr>,\n#   `Delta 15 N (o/oo)` <dbl>, `Delta 13 C (o/oo)` <dbl>, Comments <chr>\n\n\n\n\n\n\npenguins[23, \"Culmen Length (mm)\"]\n\n# A tibble: 1 × 1\n  `Culmen Length (mm)`\n                 <dbl>\n1                 35.9\n\n\n\n\n\n\npenguins[23:28, c(\"Sex\", \"Date Egg\")]\n\n# A tibble: 6 × 2\n  Sex    `Date Egg`\n  <chr>  <date>    \n1 FEMALE 2007-11-12\n2 MALE   2007-11-12\n3 MALE   2007-11-10\n4 FEMALE 2007-11-10\n5 MALE   2007-11-12\n6 FEMALE 2007-11-12\n\n\n\n\n\n\npenguins |> count(Island)\n\n# A tibble: 3 × 2\n  Island        n\n  <chr>     <int>\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n\n\n\n\n\npenguins |> count(Species)\n\n# A tibble: 3 × 2\n  Species                                       n\n  <chr>                                     <int>\n1 Adelie Penguin (Pygoscelis adeliae)         152\n2 Chinstrap penguin (Pygoscelis antarctica)    68\n3 Gentoo penguin (Pygoscelis papua)           124\n\n\n\n\n\n\nfemales <- penguins |> filter(Sex == \"FEMALE\")\nhead(females)\n\n# A tibble: 6 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  <chr>               <dbl> <chr>            <chr>  <chr>  <chr> <chr>          \n1 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n2 PAL0708                 3 Adelie Penguin … Anvers Torge… Adul… N2A1           \n3 PAL0708                 5 Adelie Penguin … Anvers Torge… Adul… N3A1           \n4 PAL0708                 7 Adelie Penguin … Anvers Torge… Adul… N4A1           \n5 PAL0708                13 Adelie Penguin … Anvers Torge… Adul… N7A1           \n6 PAL0708                16 Adelie Penguin … Anvers Torge… Adul… N8A2           \n# ℹ 10 more variables: `Clutch Completion` <chr>, `Date Egg` <date>,\n#   `Culmen Length (mm)` <dbl>, `Culmen Depth (mm)` <dbl>,\n#   `Flipper Length (mm)` <dbl>, `Body Mass (g)` <dbl>, Sex <chr>,\n#   `Delta 15 N (o/oo)` <dbl>, `Delta 13 C (o/oo)` <dbl>, Comments <chr>\n\n\n\n\n\n\npenguins |> filter(`Flipper Length (mm)` > `Body Mass (g)` / 20)\n\n# A tibble: 147 × 17\n   studyName `Sample Number` Species         Region Island Stage `Individual ID`\n   <chr>               <dbl> <chr>           <chr>  <chr>  <chr> <chr>          \n 1 PAL0708                 3 Adelie Penguin… Anvers Torge… Adul… N2A1           \n 2 PAL0708                 5 Adelie Penguin… Anvers Torge… Adul… N3A1           \n 3 PAL0708                 6 Adelie Penguin… Anvers Torge… Adul… N3A2           \n 4 PAL0708                 9 Adelie Penguin… Anvers Torge… Adul… N5A1           \n 5 PAL0708                11 Adelie Penguin… Anvers Torge… Adul… N6A1           \n 6 PAL0708                13 Adelie Penguin… Anvers Torge… Adul… N7A1           \n 7 PAL0708                14 Adelie Penguin… Anvers Torge… Adul… N7A2           \n 8 PAL0708                17 Adelie Penguin… Anvers Torge… Adul… N9A1           \n 9 PAL0708                19 Adelie Penguin… Anvers Torge… Adul… N10A1          \n10 PAL0708                21 Adelie Penguin… Anvers Biscoe Adul… N11A1          \n# ℹ 137 more rows\n# ℹ 10 more variables: `Clutch Completion` <chr>, `Date Egg` <date>,\n#   `Culmen Length (mm)` <dbl>, `Culmen Depth (mm)` <dbl>,\n#   `Flipper Length (mm)` <dbl>, `Body Mass (g)` <dbl>, Sex <chr>,\n#   `Delta 15 N (o/oo)` <dbl>, `Delta 13 C (o/oo)` <dbl>, Comments <chr>\n\n\n\n\n\n\ncolSums(is.na(penguins))\n\n          studyName       Sample Number             Species              Region \n                  0                   0                   0                   0 \n             Island               Stage       Individual ID   Clutch Completion \n                  0                   0                   0                   0 \n           Date Egg  Culmen Length (mm)   Culmen Depth (mm) Flipper Length (mm) \n                  0                   2                   2                   2 \n      Body Mass (g)                 Sex   Delta 15 N (o/oo)   Delta 13 C (o/oo) \n                  2                  11                  14                  13 \n           Comments \n                290 \n\n\n\n\n\n\npenguins <- penguins |> select(-Comments)\n\n\n\n\n\npenguins_nona <- penguins |> drop_na()\ndim(penguins_nona)\n\n[1] 324  16\n\n\n\n\n\n\npenguins_imputed <- penguins |>\n    mutate(`Culmen Length (mm)` = if_else(is.na(`Culmen Length (mm)`), mean(`Culmen Length (mm)`, na.rm = TRUE), `Culmen Length (mm)`))\n\n\n\n\n\npenguins <- penguins |> mutate(Sex = as.factor(Sex))\n\n\n\n\n\nggplot(data = penguins, aes(x = Sex)) +\n    geom_bar()\n\n\n\n\n\n\n\n\npenguins <- penguins |> mutate(SimpleSpecies = word(Species, 1))\n\n\n\n\n\npenguins <- penguins |> mutate(`Body Mass (kg)` = `Body Mass (g)` / 1000)\n\n\n\n\n\npenguins_small <- penguins |> select(Species, Island, `Body Mass (g)`)\npenguins_small |> arrange(`Body Mass (g)`)\n\n# A tibble: 344 × 3\n   Species                                   Island    `Body Mass (g)`\n   <chr>                                     <chr>               <dbl>\n 1 Chinstrap penguin (Pygoscelis antarctica) Dream                2700\n 2 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 3 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 4 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2900\n 5 Adelie Penguin (Pygoscelis adeliae)       Dream                2900\n 6 Adelie Penguin (Pygoscelis adeliae)       Torgersen            2900\n 7 Chinstrap penguin (Pygoscelis antarctica) Dream                2900\n 8 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2925\n 9 Adelie Penguin (Pygoscelis adeliae)       Dream                2975\n10 Adelie Penguin (Pygoscelis adeliae)       Dream                3000\n# ℹ 334 more rows\n\n\n\n\n\n\npenguins_by_species <- penguins |> group_by(Species)\n#### summarize the \"Body Mass (g)\" column for each group\n\n\npenguins_by_species |> drop_na()|> summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n# A tibble: 3 × 4\n  Species                                    mean    sd     n\n  <chr>                                     <dbl> <dbl> <int>\n1 Adelie Penguin (Pygoscelis adeliae)       3703.  460.   139\n2 Chinstrap penguin (Pygoscelis antarctica) 3730.  386.    67\n3 Gentoo penguin (Pygoscelis papua)         5091.  503.   118\n\n\n\n\n\n\npenguins_by_sex_and_species <- penguins |> group_by(Sex, Species)\n\n\n\n\n\npenguins_by_sex_and_species |> summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 8 × 5\n# Groups:   Sex [3]\n  Sex    Species                                    mean    sd     n\n  <fct>  <chr>                                     <dbl> <dbl> <int>\n1 FEMALE Adelie Penguin (Pygoscelis adeliae)       3369.  269.    73\n2 FEMALE Chinstrap penguin (Pygoscelis antarctica) 3527.  285.    34\n3 FEMALE Gentoo penguin (Pygoscelis papua)         4680.  282.    58\n4 MALE   Adelie Penguin (Pygoscelis adeliae)       4043.  347.    73\n5 MALE   Chinstrap penguin (Pygoscelis antarctica) 3939.  362.    34\n6 MALE   Gentoo penguin (Pygoscelis papua)         5485.  313.    61\n7 <NA>   Adelie Penguin (Pygoscelis adeliae)         NA    NA      6\n8 <NA>   Gentoo penguin (Pygoscelis papua)           NA    NA      5\n\n\n\n\n\n\npenguins_by_sex_and_species |>\n    summarize(mean = mean(`Body Mass (g)`)) |>\n    pivot_wider(names_from = Species, values_from = mean)\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 3 × 4\n# Groups:   Sex [3]\n  Sex    Adelie Penguin (Pygosce…¹ Chinstrap penguin (P…² Gentoo penguin (Pygo…³\n  <fct>                      <dbl>                  <dbl>                  <dbl>\n1 FEMALE                     3369.                  3527.                  4680.\n2 MALE                       4043.                  3939.                  5485.\n3 <NA>                         NA                     NA                     NA \n# ℹ abbreviated names: ¹​`Adelie Penguin (Pygoscelis adeliae)`,\n#   ²​`Chinstrap penguin (Pygoscelis antarctica)`,\n#   ³​`Gentoo penguin (Pygoscelis papua)`\n\n\n\n\n\n\npenguins |>\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |>\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\npenguins |>\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |>\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\nOne can also work with excel files. You need the readxl library.\n\nlibrary(\"readxl\")\n\nAs an example, we use an excel spreadsheet violent crime data from the FBI."
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html",
    "href": "chapters/05-WorkingWithData/r_programming.html",
    "title": "Basics of Programming in R",
    "section": "",
    "text": "The assignment operator in R is <-\nThere is no built-in “dictionary” datatype.\nThe basic datatype in R is the vector, which contains objects of the same type.\n\nVectors are indexed from 1.\n\n\n# n\nx <- c(\"Hello\", 1)\nclass(x)\n\n[1] \"character\"\n\n\nNotice that x is now all characters, and in fact if you now compute 2*x[2] you will get an error.\n\nRanges are inclusive\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nTRUE and FALSE instead of True and False\nindentation does not matter and you can use ; to string multiple statements together.\n\n\nx <- 1\ny <- 1\nz <- 1\n\n\nlength gives the length of a vector, nchar gives the number of characters of a string.\n\n\nlength(\"Hello\")\n\n[1] 1\n\n\n\nlength(c(\"Hello\", \"GoodBye\"))\n\n[1] 2\n\n\n\nnchar(\"Hello\")\n\n[1] 5\n\n\n\nnchar(c(\"Hello\", \"GoodBye\"))\n\n[1] 5 7\n\n\n\nYou need to use substr to extract substrings, not subscripts.\n\n\ns <- \"Hello\"\ns[1]\n\n[1] \"Hello\"\n\n\n\nConvert a vector to a string\n\n\ns <- paste(c(\"A\", \"B\", \"C\"), collapse = \"\")\nt <- paste(c(\"A\", \"B\", \"C\"), c(\"D\", \"E\", \"F\"), sep = \",\", collapse = \" \")\nprint(s)\n\n[1] \"ABC\"\n\nprint(t)\n\n[1] \"A,D B,E C,F\"\n\n\n\ns <- \"This is a string of letters\"\nt <- substr(rep(s, nchar(s) / 2), seq(1, nchar(s), 2), seq(1, nchar(s), 2))\npaste(t, collapse = \"\")\n\n[1] \"Ti sasrn flte\""
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#lists",
    "href": "chapters/05-WorkingWithData/r_programming.html#lists",
    "title": "Basics of Programming in R",
    "section": "Lists",
    "text": "Lists\nA list can contain objects of different types.\n\nlst <- list(\"a\", 1.5)\n\nIn particular, a list can contain vectors and can have named entries.\n\nlst <- list(first = c(1, 2, 3), second = c(4, 5, 6))\nprint(lst)\n\n$first\n[1] 1 2 3\n\n$second\n[1] 4 5 6\n\n\nThe presence of [[]] indicates a list.\n\nprint(lst[[1]])\n\n[1] 1 2 3\n\nprint(lst$first)\n\n[1] 1 2 3\n\n\n\nclass(lst[1])\n\n[1] \"list\"\n\nclass(lst[[1]])\n\n[1] \"numeric\"\n\n\n\nSplit a string to a list\n\n\na <- strsplit(\"This is a string\", split = \" \")\nb <- strsplit(\"this is a string split into letters\", split = \"\")\nprint(a)\n\n[[1]]\n[1] \"This\"   \"is\"     \"a\"      \"string\"\n\nprint(b)\n\n[[1]]\n [1] \"t\" \"h\" \"i\" \"s\" \" \" \"i\" \"s\" \" \" \"a\" \" \" \"s\" \"t\" \"r\" \"i\" \"n\" \"g\" \" \" \"s\" \"p\"\n[20] \"l\" \"i\" \"t\" \" \" \"i\" \"n\" \"t\" \"o\" \" \" \"l\" \"e\" \"t\" \"t\" \"e\" \"r\" \"s\"\n\n\n\nExtract every other letter"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#functions",
    "href": "chapters/05-WorkingWithData/r_programming.html#functions",
    "title": "Basics of Programming in R",
    "section": "Functions",
    "text": "Functions\nFunctions are constructed like this:\n\nf <- function(n) {\n    n**2\n}\nf(5)\n\n[1] 25\n\n\nThe last evaluated expression is the value of the function but it is better style to actually use the return statement.\n\nf <- function(n) {\n    return(n**2)\n}\nf(10)\n\n[1] 100\n\n\nFunctions are automatically “vectorized.”\n\nf(1:10)\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nR automatically “recyles” when things fit.\n\n1:3 + 1:6\n\n[1] 2 4 6 5 7 9\n\n\nThe principle of scope is essentially the same as discussed in the python programming notes."
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#iteration-in-r",
    "href": "chapters/05-WorkingWithData/r_programming.html#iteration-in-r",
    "title": "Basics of Programming in R",
    "section": "Iteration in R",
    "text": "Iteration in R\n\ny <- 0\nfor (x in c(1, 2, 3, 10)) {\n    print(x)\n    y <- y + x\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 10\n\ncat(\"y=\", y)\n\ny= 16\n\n\n\ny<-0\nwhile(y<10) {\n    cat(\"y = \",y,\" \",sep=\"\")\n    y <- y+1\n}\n\ny = 0 y = 1 y = 2 y = 3 y = 4 y = 5 y = 6 y = 7 y = 8 y = 9 \n\n\nOften iteration in R is unnecessary. Suppose you want to compute the sum of the squares of the first n integers.\n\nf <- function(n) {\n    s <- 0\n    for (i in seq(1, n)) {\n        s <- s + i^2\n    }\n    return(s)\n}\nf(10)\n\n[1] 385\n\n\n\nf <- function(n) {\n    return(sum(seq(1, n)^2))\n}\nf(10)\n\n[1] 385"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#logical-statements",
    "href": "chapters/05-WorkingWithData/r_programming.html#logical-statements",
    "title": "Basics of Programming in R",
    "section": "Logical statements",
    "text": "Logical statements\n\nif(substr(\"Hesterday\",1,1)==\"H\") {\n    print(\"Yes\")\n} else {\n    print(\"No\")\n}\n\n[1] \"Yes\"\n\n\n\nless_than_one <- function(x) {\nif (any(x<1)) {\n    print(\"Yes\")\n} \nelse {\n    print(\"No\")\n}\n}\n\nAgain you can avoid iteration.\n\nx <- rnorm(20)\nx[x < 1]\n\n [1] -0.13346948 -1.51869672 -2.07774164 -1.26363146 -0.77787713 -0.04647544\n [7]  0.48731270 -0.64566439  0.55046269  0.38183078 -0.12686373 -0.48916487\n[13] -0.48677926 -1.10597842 -0.12989496 -1.38434980 -0.84124205  0.61809283"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#example",
    "href": "chapters/05-WorkingWithData/r_programming.html#example",
    "title": "Basics of Programming in R",
    "section": "Example",
    "text": "Example\nTake a string and make its first character upper case and the rest lower.\n\nf<-function(s) {\n    a<-paste(toupper(substr(s,1,1)),substr(s,2,nchar(s)),sep=\"\")\n    return(a)\n}\n\nYou can assign to substrings.\n\nf<-function(s) {\n    substr(s,1,1)<-toupper(substr(s,1,1))\n    return(s)\n}"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#problems",
    "href": "chapters/05-WorkingWithData/r_programming.html#problems",
    "title": "Basics of Programming in R",
    "section": "Problems",
    "text": "Problems\n\nWrite a function which takes a string and standardizes it by:\n\nremoves all characters which are not letters, numbers, or spaces\nmakes all the letters lower case\nreplacing all spaces by underscore ’_’\n\n\nHint: convert the string to a vector of letters\n\nThe object penguins_raw is a “tibble”, which is a fancy type of tabular layout. It has named columns that you can extract with $.\n\n\nlibrary(palmerpenguins)\n# view(penguins_raw)\ncolnames(penguins_raw)\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nBy assigning to colnames you can change the column names. (In other words, colnames(penguins_raw)<-c(...) replaces the column names from the given vector. Use your function from part(1) to simplify the column names of this tibble.\n\nYou can access a column of the tibble using $, so for example penguins_raw$species should give you the vector of species. Replace this column with just the first word of the species name (Gentoo, Adelie, Chinstrap).\nLet \\(n\\) be a positive real number and let \\(x_0\\) be 1. The iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\n\nconverges to the square root of \\(n\\). (This is Newton’s Method). Write an R function which computes the square root using this iteration. You should continue to iterate until \\(x_{k+1}\\) is within \\(10^{-6}\\) of \\(x_{k}\\).\n\n#f<-function(n) {\n\n#}\n\nSuppose you want to save the successive values you computed during the iteration for plotting purposes. How could you do that (and return them)?\nSuppose you want the tolerance (here \\(10^{6}\\)) to be a parameter?\nSuppose you want to set a maximum number of iterations, in case something goes wrong, to prevent an infinite loop?"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html",
    "title": "Essential Linear Algebra",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Arrow\n\n\ndef make_plot(xmin, ymin, xmax, ymax):\n    fig, ax = plt.subplots()\n    ax.set_xlim(xmin, xmax)\n    ax.set_ylim(ymin, ymax)\n    ax.set_xticks(np.arange(xmin, xmax, 1))\n    ax.set_yticks(np.arange(ymin, ymax, 1))\n    ax.set_aspect(\"equal\")\n    ax.grid(visible=True)\n    return fig, ax\n\n\ndef draw_arrow(x0, y0, x1, y1, axes, color=\"blue\", alpha=1):\n    axes.add_patch(Arrow(x0, y0, x1 - x0, y1 - y0, width=0.3, color=color, alpha=alpha))\n    return axes"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#r-and-python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#r-and-python",
    "title": "Essential Linear Algebra",
    "section": "R and Python",
    "text": "R and Python\nFor a look at linear algebra basics in R and Python, see:\n\nPython Linear Algebra\nR Linear Algebra"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#vectors-and-scalars",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#vectors-and-scalars",
    "title": "Essential Linear Algebra",
    "section": "Vectors and Scalars",
    "text": "Vectors and Scalars\n\\(\\mathbf{R}^{n}\\) is the set of vectors (ordered tuples) of real numbers of length \\(n\\). A scalar is a real number.\n\nVectors are added componentwise.\nA vector can be multiplied by a scalar."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#addition",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#addition",
    "title": "Essential Linear Algebra",
    "section": "Addition",
    "text": "Addition\n\nfig, ax = make_plot(0, 0, 12, 12)\nax.set_title(\"Vector Addition\")\nax = draw_arrow(0, 0, 3, 5, ax)\nax = draw_arrow(0, 0, 1, 4, ax)\nax = draw_arrow(1, 4, 4, 9, ax)\nax = draw_arrow(3, 5, 4, 9, ax)\nplt.show()"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#scalar-multiplication",
    "title": "Essential Linear Algebra",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\nfig, ax = make_plot(0, 0, 12, 12)\nax.set_title(\"Scalar Multiplication\")\nax = draw_arrow(0, 0, 3, 5, ax)\nax = draw_arrow(0, 0, 6, 10, ax, color=\"red\", alpha=0.5)"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#geometric-interpretation-in-2-and-3-dimensions",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#geometric-interpretation-in-2-and-3-dimensions",
    "title": "Essential Linear Algebra",
    "section": "Geometric Interpretation in 2 and 3 dimensions",
    "text": "Geometric Interpretation in 2 and 3 dimensions"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#feature-space",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#feature-space",
    "title": "Essential Linear Algebra",
    "section": "Feature Space",
    "text": "Feature Space\nEach ‘dimension’ in feature space corresponds to a ‘feature’ or measurement of the data. Here we are assuming for now that the features are continuous and measured by real numbers.\nLet’s choose some numerical features of the penguins dataset.\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\ndata = (\n    data[\n        [\n            \"Culmen Length (mm)\",\n            \"Culmen Depth (mm)\",\n            \"Flipper Length (mm)\",\n            \"Body Mass (g)\",\n        ]\n    ]\n    .dropna()\n    .values\n)\n\nEach penguin is represented by a vector in \\(\\mathbf{R}^{4}\\). So for example penguin number 34 is represented as follows.\n\ndata[34, :]\n\narray([  39.2,   21.1,  196. , 4150. ])\n\n\nThis abstraction of penguins into vectors is sometimes called “an embedding”."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#features",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#features",
    "title": "Essential Linear Algebra",
    "section": "Features",
    "text": "Features\nWe can also look at a single feature for all of the penguins. For example, ‘Culmen Length (mm)’ is a feature and there is a vector in \\(\\mathbf{R}^{342}\\) consisting of all of the Culmen Lengths for all of the penguins.\nIn the tidy convention, we summarize our data in an array or matrix where each row corresponds to a sample and each column to a feature. So our penguin data has \\(342\\) rows (corresponding to the 342 penguins with no missing data) and 4 columns corresponding to four features."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#image-embeddings",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#image-embeddings",
    "title": "Essential Linear Algebra",
    "section": "Image Embeddings",
    "text": "Image Embeddings\nEach sample in the MNIST database is a \\(28x28\\) gray scale image, represented by a \\(28\\times 28\\) array of integers between 0 and 255.\n\nwith open(\"data/train-images.idx3-ubyte\", \"rb\") as f:\n    f.read(16)\n    buf = f.read(28 * 28)\n    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n    data = data.reshape(1, 28, 28)\nfor x in range(28):\n    for y in range(28):\n        print(\"{:>4}\".format(int(data[0, x, y])), end=\"\")\n    print(\"\\n\")\n\nimage = np.asarray(data[0].squeeze())\nplt.imshow(image)\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0\n\n   0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0\n\n   0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0\n\n   0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n\n\n<matplotlib.image.AxesImage at 0x7f9244058910>\n\n\n\n\n\nHere we can view each image as a vector in a 784 dimensional (=28*28) space.\nA collection of 100 images would be represented by an array with 100 rows and 784 columns\nA 28x28 image in color has 28283 numbers to account for the RGB channels."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#one-hot-embedding",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#one-hot-embedding",
    "title": "Essential Linear Algebra",
    "section": "One Hot Embedding",
    "text": "One Hot Embedding\nNormally categorical variables don’t embed direcly into \\(\\mathbf{R}^{n}\\) but one can use “one-hot” embedding.\nSuppose our categorical vector has 4 levels: red, green, blue, orange.\nThe “one-hot” embedding uses four features, and each color corresponds to a vector with a one in the column corresponding to the color and zeros elsewhere.\n\n\n\nred\ngreen\nblue\norange\n\n\n\n\n1\n0\n0\n0\n\n\n0\n1\n0\n0\n\n\n0\n0\n1\n0\n\n\n0\n0\n0\n1\n\n\n\nSo to use one-hot encoding of our feature data, we’d add four columns to our data matrix."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#word-embeddings",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#word-embeddings",
    "title": "Essential Linear Algebra",
    "section": "Word embeddings",
    "text": "Word embeddings\nWord2vec is a technique developed by scientists at google that embeds a vocabulary into \\(\\mathbf{R}^{n}\\). Each of 3 million words has a 300 dimensional vector representing it.\nSee this google page."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#the-curse-of-dimensionality",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#the-curse-of-dimensionality",
    "title": "Essential Linear Algebra",
    "section": "The Curse of Dimensionality",
    "text": "The Curse of Dimensionality\nOur intuition misleads us when we think about high dimensional space. There is just vastly more “space” in high dimensional space then we expect.\nOne way to see this is to compare the unit sphere in \\(\\mathbf{R}^{n}\\) and the unit cube in \\(\\mathbf{R}^{n}\\).\nIn the plane, the unit cube has volume 4 and the unit circle has volume 3.14. So the unit circle fills up most of the cube. Given vectors with coordinates \\((x,y)\\) between \\(-1\\) and \\(1\\), about 75 percent are within distance one of the origin.\n\nrng = np.random.default_rng()\ndef hypercube(n,d):\n    data = rng.uniform(-1,1,size=(n,d))\n    r = np.linalg.norm(data,axis=1)\n    hist, edges = np.histogram(r,bins=20,density=True)\n    fig = plt.figure()\n    axes = fig.subplots()\n    axes.bar(x=edges[:-1], height=hist,align='edge',width=edges[1]-edges[0],edgecolor='white')\n    axes.set_title(\"Distance to zero for {} points\\n in the hypercube in {} dimensions\".format(n,d))\nhypercube(10000,2)\n\n\n\n\nIn 20 dimensions, the situation is quite different. The hypercube has volume 2^{20} (this volume grows exponentially with the dimension) while the sphere has volume \\[\n\\frac{\\pi^{10}}{10!}=.025\n\\]\nIf you compare the distribution you see that most of the points are very far from the origin; basically none are within the unit sphere.\n\nhypercube(10000,20)\n\n\n\n\nThis means that even huge numbers of points in relatively high dimensions are very sparsely distributed."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-combinations",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-combinations",
    "title": "Essential Linear Algebra",
    "section": "Linear combinations",
    "text": "Linear combinations\nIf \\(v_1,\\ldots, v_k\\) are vectors in \\(\\mathbf{R}^{n}\\) then a weighted sum of the \\(v_{i}\\) is called a linear combination.\n\\[\nw = \\sum b_{i}v_{i}\n\\]\nSuppose our data is the performance of students on 2 homeworks, 1 midterm, and one final, all scored on a 100 points scale, with each homework worth 10% of the total, the midterm worth 25% and the final worth 55%. If there are 20 students our data is a \\(20 x 4\\) array with each row having the grades of a single student and each column having all the scores for a particular assignment.\nLet \\(v_1, v_2, v_3, v_4\\) be the four columns. Then the final score is the linear combination \\[\ns=.1v_1+.1v_2+.25v_3+.55v_4\n\\]\nThe vector \\(s\\), the score, is a linear combination of the features."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-dependence-and-linear-independence",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-dependence-and-linear-independence",
    "title": "Essential Linear Algebra",
    "section": "Linear Dependence and Linear Independence",
    "text": "Linear Dependence and Linear Independence\nIn the example above, the final score is a linear combination of the features. We say that the final score is dependent on the features. More generally, a collection of vectors is linearly dependent if there are constants, not all zero, so that\n\\[\nb_1v_1+...+b_kv_k=0.\n\\]\nIf they’re dependent, it means one of them can be written in terms of the other.\nIf they aren’t dependent, they are independent. This means that the only way you can get \\[\nb_1v_1+...+b_kv_k=0\n\\] is if all the constants are zero.\nNone of the vectors can be written in terms of the others.\nMathematically, dependence is an exact relationship."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-relations-in-python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-relations-in-python",
    "title": "Essential Linear Algebra",
    "section": "Linear relations in python",
    "text": "Linear relations in python\n\nvectors = [np.random.uniform(size=8) for i in range(5)]  # 10 random vectors\nscalars = [np.random.normal() for i in range(5)]  # 10 random scalars\nprods = [scalars[i] * vectors[i] for i in range(5)]  # products\nresult = sum(prods)  # sum of products\nprint(result)\n\n[-2.05819278 -2.67603538 -1.96513374 -2.26124284 -2.21024428 -1.42506644\n -2.85392633 -3.00973004]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#approximate-linear-dependence",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#approximate-linear-dependence",
    "title": "Essential Linear Algebra",
    "section": "Approximate linear dependence",
    "text": "Approximate linear dependence\nSometimes two features are “almost” linearly related.\nIn an old dataset about car models, with 398 types of cars and 9 features, two features are “miles per gallon” and “engine displacement”. If we look at mpg and displacement relative to their means by subtracting their averages values, we see that\nHere, miles per gallon (relative to its mean value) is roughly linearly dependent on displacement (relative to its mean). \\[\n\\mathrm{mpg}-\\overline{\\mathrm{mpg}} = -.0603(\\mathrm{disp}-\\overline{\\mathrm{disp}})\n\\]\nSo we don’t learn much new from ‘mpg’ that isn’t already in ‘displacement’.\n\nimport statsmodels.api as sm\n\nmpg = pd.read_csv(\"data/auto-mpg.csv\")\nx = mpg[\"displacement\"].values\nx = x - np.mean(x)\ny = mpg[\"mpg\"].values\ny = y - np.mean(y)\nx1 = sm.add_constant(x)\nmodel = sm.OLS(y, x1).fit()\nx0 = np.linspace(-100, 300, 10)\nx1 = sm.add_constant(x0)\npredictions = model.predict(x1)\nplt.scatter(x, y)\nplt.plot(x0, predictions, color=\"red\")\nplt.title(\"Miles per Gallon vs Engine Displacement\")\nplt.xlabel(\"Displacement\")\n\nText(0.5, 0, 'Displacement')\n\n\n\n\n\nLinear Regression (studied later) tries to capture this."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#span",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#span",
    "title": "Essential Linear Algebra",
    "section": "Span",
    "text": "Span\nThe span of a collection of vectors is the set of all linear combinations of those vectors."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#basis-and-dimension",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#basis-and-dimension",
    "title": "Essential Linear Algebra",
    "section": "Basis and dimension",
    "text": "Basis and dimension\nA basis is a linearly independent, spanning set. The number of elements in a basis is always the same; it is called the dimension of the vector space.\nThe dimension of \\(\\mathbf{R}^{n}\\) is \\(n\\) (the standard vectors are independent and span)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#distances-and-the-euclidean-norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#distances-and-the-euclidean-norm",
    "title": "Essential Linear Algebra",
    "section": "Distances and the euclidean norm",
    "text": "Distances and the euclidean norm\nThe norm of a vector \\(v=(a_1,\\ldots, a_n)\\) is \\[\n\\|v\\| = (\\sum a_{i}^2)^{1/2}\n\\]\nIt is the “length” of the vector.\nThe Euclidean distance between two points \\(v\\) and \\(w\\) is \\[\n\\|v-w\\|\n\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#mean-squared-error-in-vector-form",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#mean-squared-error-in-vector-form",
    "title": "Essential Linear Algebra",
    "section": "Mean Squared Error in vector form",
    "text": "Mean Squared Error in vector form\nRemember our example the “almost” dependence of mpg and displacement.\n\nmpg0 = mpg[\"mpg\"] - np.mean(mpg[\"mpg\"])\ndisp0 = mpg[\"displacement\"] - np.mean(mpg[\"displacement\"])\npredicted = -0.0603 * disp0\nplt.scatter(disp0, mpg0)\nplt.scatter(disp0, predicted)\nplt.title(\"MSE={:.2f}\".format(np.linalg.norm(mpg0 - predicted) / mpg0.shape[0]))\n\nText(0.5, 1.0, 'MSE=0.23')\n\n\n\n\n\nThe mean squared error is the squared distance between a true and predicted value, divided by the number of values."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#the-dot-product",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#the-dot-product",
    "title": "Essential Linear Algebra",
    "section": "The dot product",
    "text": "The dot product\nSuppose we have two vectors: \\[\\begin{aligned}\nv_1 & =[a_1,a_2,\\dots, a_n] \\\\\nv_2 &= [b_1,b_2,\\ldots, b_n]\n\\end{aligned}\n\\]\nThe “dot product” or “inner product” of these two vectors is: \\[\nv_1\\cdot v_2 = \\sum_{i=1}^{n} a_i b_i.\n\\]\nImportant: The dot product *converts two vectors into a scalar!"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#properties-of-the-dot-product",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#properties-of-the-dot-product",
    "title": "Essential Linear Algebra",
    "section": "Properties of the dot product",
    "text": "Properties of the dot product\n\n\\(v_1\\cdot v_1 = \\|v_1\\|^2\\)\n\\((av_1+bv_2)\\cdot v_3 = a(v_1\\cdot v_2) + b(v_2\\cdot v_2)\\)\n\\(v_1\\cdot v_2 = v_2 \\cdot v_1\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#angles-and-cauchy-schwartz",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#angles-and-cauchy-schwartz",
    "title": "Essential Linear Algebra",
    "section": "Angles and Cauchy-Schwartz",
    "text": "Angles and Cauchy-Schwartz\nThe law of cosines: \\[\\|v_1\\|^2+\\|v_2\\|^2 - 2\\|v_1\\|\\|v_2\\|\\cos(\\theta) =\\|v_1-v_2\\|^2\\]\nmeans that\n\\[\nv_1\\cdot v_2 = \\|v_1\\|\\|v_2\\|\\cos(\\theta)\n\\tag{1}\\]\nIn particular:\n\\[|v_1\\cdot v_2|\\le \\|v_1\\|\\|v_2\\|\n\\tag{2}\\]\nThis says \\[\n|\\sum_{i=1}^{n} a_{i}b_{i}|^2\\le (\\sum_{i=1}^{n} a_{i}^2)(\\sum_{i=1}^{n} b_{i}^2)\n\\]\nEquation 2 is called the “Cauchy-Schwartz inequality.”"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#python",
    "title": "Essential Linear Algebra",
    "section": "Python",
    "text": "Python\n\nListing 1: Dot product computation\n# python\nv = np.array([1,2,3,4,5])\nw = np.array([2,4,6,8,10])\nprint('Entry by entry product = {}'.format(v*w)) # <1>\nprint('Dot product = {}'.format(np.dot(v,w))) # <2>\n\nNote: In R, the symbol for dot product is %*%.\nIn Listing 1 we show how to compute the dot product in python."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#orthogonality",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#orthogonality",
    "title": "Essential Linear Algebra",
    "section": "Orthogonality",
    "text": "Orthogonality\nIf \\(v_1\\cdot v_2=0\\) then either one of \\(v_1\\) or \\(v_2\\) is zero, or the angle between then is 90 degrees.\nIn this case we saw the vectors are orthogonal."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#unit-vectors-and-projection",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#unit-vectors-and-projection",
    "title": "Essential Linear Algebra",
    "section": "Unit vectors and projection",
    "text": "Unit vectors and projection\nA vector \\(u\\) is a unit vector if \\(u\\cdot u=1\\).\nThe quantity \\(v\\cdot u\\) measures the projection of \\(v\\) into the direction given by \\(u\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#variance-correlation-and-cosine-similarity",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#variance-correlation-and-cosine-similarity",
    "title": "Essential Linear Algebra",
    "section": "Variance, Correlation and cosine similarity",
    "text": "Variance, Correlation and cosine similarity\nIf \\(v\\) is a feature vector, let \\(\\overline{v}=\\frac{1}{n}\\sum_{i=1}^{n} v_{i}\\).\nNotice that \\(\\overline{v}=\\frac{v\\cdot E}{n}\\) where \\(E\\) is the vector with \\(1\\) in each entry.\n\\[\n\\|(v-\\overline{v}E)\\|=\\sigma^{2}\n\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#covariance",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#covariance",
    "title": "Essential Linear Algebra",
    "section": "Covariance",
    "text": "Covariance\nIf \\(v\\) and \\(w\\) are two vectors, their covariance is \\[\n\\sigma_{vw} = \\frac{(v-\\overline{v}E)\\cdot (w-\\overline{w}E)}{n}\n\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#correlation",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#correlation",
    "title": "Essential Linear Algebra",
    "section": "Correlation",
    "text": "Correlation\nThe correlation coefficient of \\(v\\) and \\(w\\) is \\[\nr_{vw} = \\frac{\\sigma_{vw}}{\\sigma_{v}\\sigma_{w}}=\\frac{|(v-\\overline{v}E)\\cdot(w-\\overline{w}E)|}{\\|v-\\overline{v}E)\\|\\|w-\\overline{w}E\\|}=\\cos\\theta\n\\]\nIt measures the cosine of the angle between \\(v-\\overline{v}E\\) and \\(w-\\overline{w}E\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#cosine-similarity",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#cosine-similarity",
    "title": "Essential Linear Algebra",
    "section": "Cosine similarity",
    "text": "Cosine similarity\nIn general,\n\\[\n\\cos(\\theta) = \\frac{v\\cdot w}{\\|v\\|\\|w\\|}\n\\] measures the angle between two feature vectors and is a measure of “similarity” between \\(0\\) and \\(1\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#hyperplanes",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#hyperplanes",
    "title": "Essential Linear Algebra",
    "section": "Hyperplanes",
    "text": "Hyperplanes\nA (linear) hyperplane is a subspace of dimension \\(n-1\\) in a vector space of dimension \\(n\\). It is given by an equation of the form\n\\[\n\\sum a_{i}x_{i}=0.\n\\]\nGeometrically this can be written \\(v\\cdot x=0\\) where \\(v=[a_1,\\ldots, a_n]\\) and \\(x=[x_1,\\ldots, x_n]\\). The vector \\(v\\) is called the normal vector to the hyperplane.\nAn (affine) hyperplane is given by an equation of the form \\[\nv\\cdot x = b\n\\] for some constant \\(b\\)\n\nx = np.linspace(-5, 5, 10)\ny = 2 / 3 * x\nplt.plot(x, y)\nplt.grid(True)\nplt.gca().set_aspect(\"equal\")\n\nplt.plot([0, -2], [0, 3])\nplt.plot([-2, -2], [3, 2])\nplt.plot([-2, -1], [3, 2.6])\nplt.title(\"Hyperplane 2x-3y=0 with normal vector [-2,3]\")\n\nText(0.5, 1.0, 'Hyperplane 2x-3y=0 with normal vector [-2,3]')"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#affine-hyperplanes",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#affine-hyperplanes",
    "title": "Essential Linear Algebra",
    "section": "Affine hyperplanes",
    "text": "Affine hyperplanes\nFor fixed \\(v\\) and varying \\(b\\), the hyperplanes \\(v\\cdot x=b\\) form a parallel family."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#distance-from-a-point-to-a-hyperplane",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#distance-from-a-point-to-a-hyperplane",
    "title": "Essential Linear Algebra",
    "section": "Distance from a point to a hyperplane",
    "text": "Distance from a point to a hyperplane\nThe distance from a point \\(w\\) to the hyperplane \\(v\\cdot x = b\\) is \\[\nD = \\frac{w\\cdot v-b}{\\|v\\|}.\n\\]\nThis is the projection of the line from \\(w\\) to a point \\(x\\) on the hyperplane against the unit normal \\(\\frac{v}{\\|v\\|}\\).\n\\[\n(w-x)\\cdot\\frac{v}{\\|v\\|} =\\frac{(w\\cdot v -x\\cdot v)}{\\|v\\|} = \\frac{(w\\cdot v - b)}{\\|v\\|}\n\\]\n\nx = np.linspace(-4, 4, 10)\ny = 2 / 3 * x\nplt.plot(x, y)\nplt.grid(True)\nplt.gca().set_aspect(\"equal\")\nplt.title(\"Dist. from point to hyperplane\")\nplt.plot([0, -2 / np.sqrt(13)], [0, 3 / np.sqrt(13)], color=\"red\", linewidth=3)\nplt.plot([0, -2], [0, 3])\nplt.plot([-3, -2], [-2, 3])\nplt.text(-2.4, 3, r\"w\")\nplt.text(-3, -2.3, r\"x\")\nplt.text(-3.6, 0, r\"$\\|w-x\\|$\")\nplt.text(-1.9, 2.2, r\"$\\theta$\")\nplt.text(-0.5, 1.4, r\"$\\|w-x\\|\\cos(\\theta)$\")\n\nText(-0.5, 1.4, '$\\\\|w-x\\\\|\\\\cos(\\\\theta)$')"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrices",
    "title": "Essential Linear Algebra",
    "section": "Matrices",
    "text": "Matrices\nAn \\(n\\times m\\) matrix is an array of real numbers with \\(n\\) rows, \\(m\\) columns, and a total of \\(nm\\) entries."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector",
    "title": "Essential Linear Algebra",
    "section": "Matrix times Vector",
    "text": "Matrix times Vector\nIf \\(M\\) is an \\(n\\times m\\) matrix and \\(v\\) is an \\(m\\times 1\\) vector (a column vector) then \\(Mv\\) is the \\(n\\times 1\\) column vector whose entries are \\[\nM[i,:]\\cdot v\n\\] where \\(i\\) runs from 1 to \\(n\\). Here \\(M[i,:]\\) is the \\(i^{th}\\) row of \\(M\\).\nIf \\(v\\) is a \\(1\\times n\\) row vector then \\(vM\\) is the \\(1\\times m\\) row vector whose entries are \\(v\\cdot M[:,i]\\) as \\(i\\) runs from 1 to \\(m\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector-is-linear",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector-is-linear",
    "title": "Essential Linear Algebra",
    "section": "Matrix times vector is linear",
    "text": "Matrix times vector is linear\n\\[M(v+w) = Mv+Mw\\] \\[M(aw) = aMw\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-standard-vector-gives-rowcolumn",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-standard-vector-gives-rowcolumn",
    "title": "Essential Linear Algebra",
    "section": "Matrix times standard vector gives row/column",
    "text": "Matrix times standard vector gives row/column\nIf \\(v\\) is a column vector with a a \\(1\\) in position \\(i\\) and zeros elsewhere, then \\(Mv\\) is the \\(i^{th}\\) column of \\(M\\).\nIf \\(v\\) is a row vector with a \\(1\\) in position \\(i\\) and zeros elsewhere, then \\(vM\\) is the \\(i^{th}\\) row of \\(M\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#mvvm-gives-linear-combination-of-columnsrows",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#mvvm-gives-linear-combination-of-columnsrows",
    "title": "Essential Linear Algebra",
    "section": "\\(Mv\\)/\\(vM\\) gives linear combination of columns/rows",
    "text": "\\(Mv\\)/\\(vM\\) gives linear combination of columns/rows\n\\(Mv\\) is a linear combination of the columns of \\(M\\) weighted by the entries of \\(v\\).\n\\(vM\\) is a linear combination of the rows of \\(M\\) weighted by the entries of \\(v\\)."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-matrix",
    "title": "Essential Linear Algebra",
    "section": "Matrix times matrix",
    "text": "Matrix times matrix\nAn \\(n\\times m\\) matrix times an \\(m\\times k\\) matrix yields an \\(n\\times k\\) matrix.\nYou can view \\(MN\\) as \\(Mv\\) where \\(v\\) runs through the columns of \\(N\\). Each column has \\(n\\) rows.\n\\[\nMN=\\left[\n    \\begin{matrix}\n     M[0,:]N & M[1,:]N &\\cdots&M[m,:]N\\\\\n    \\end{matrix}\n    \\right]\n\\]\nOR you can view \\(MN\\) as \\(wN\\) where \\(w\\) runs through the rows of \\(M\\).\n\\[\nMN = \\left[\\begin{matrix} MN[:,0] \\\\ MN[:,1] \\\\\\vdots\\\\MN[:,k]\\end{matrix}\\right]\n\\]\nOR\nyou can view \\(MN\\) where the \\(i,j\\) entry of \\(MN\\) is the dot product of the \\(i^{th}\\) row of \\(M\\) with the \\(j^{th}\\) column of \\(N\\) (each of which has \\(m\\) entries).\n\\[(MN)_{ij} = M[i,:]\\cdot N[;,j]\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#python-1",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#python-1",
    "title": "Essential Linear Algebra",
    "section": "Python",
    "text": "Python\nThe ‘@’ sign gives matrix multiplication in python. In R, it’s %*%.\n\nM = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\nv = np.array([[-1], [0], [1]])\nprint(M)\nprint(v)\nprint(M @ v)\nprint(\"Compare -M[:,0]+M[:,2] with M@v\\n both are {}\".format(-M[:, 0] + M[:, 2]))\n\n[[1 2 3]\n [2 3 4]\n [3 4 5]]\n[[-1]\n [ 0]\n [ 1]]\n[[2]\n [2]\n [2]]\nCompare -M[:,0]+M[:,2] with M@v\n both are [2 2 2]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#where-does-matrix-multiplication-come-from",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#where-does-matrix-multiplication-come-from",
    "title": "Essential Linear Algebra",
    "section": "Where does matrix multiplication come from?",
    "text": "Where does matrix multiplication come from?\nIf \\(v\\) is in \\(\\mathbf{R}^{m}\\) as a column vector, and \\(M\\) is an \\(n\\times m\\) matrix, then \\(Mv\\in\\mathbf{R}^{n}\\). So the function \\(v\\to Mv\\) is a function from \\(\\mathbf{R}^{m}\\to \\mathbf{R}^{m}\\).\nNow if \\(N\\) is a \\(k\\times n\\) matrix, then \\(NMv\\) is in \\(\\mathbf{R}^{k}\\).\nIf we want \\(N(Mv)=(NM)v\\) to be true then this forces the definition of matrix multiplication.\nThe Matrix Product gives composition of functions"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#transpose-of-a-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#transpose-of-a-matrix",
    "title": "Essential Linear Algebra",
    "section": "Transpose of a matrix",
    "text": "Transpose of a matrix\nThe transpose \\(M^{T}\\) of a matrix is the matrix obtained from \\(M\\) by switching rows and columns.\nThe transpose switches the order of a product.\n\\[(MN)^{T}=N^{T}M^{T}\\]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#covariance-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#covariance-matrix",
    "title": "Essential Linear Algebra",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\nRemember that if \\(v\\) and \\(w\\) are feature vectors, then \\((v-\\overline{v})\\cdot (w-\\overline{w})\\) is the covariance of \\(v\\) and \\(w\\).\nSuppose \\(v_1,\\ldots, v_n\\) are features forming a data matrix \\(X\\).\nLet \\(X_{0}\\) be the matrix whose columns are \\(v_{i}-\\overline{v_{i}}\\).\nThen \\(\\frac{1}{N}X_{0}^{T}X_{0}\\) is \\(n\\times n\\) and called the covariance matrix.\nIf \\(Y_{0}\\) is obtained from \\(X_{0}\\) by dividing each column by its norm, then \\(Y_{0}^{T}Y_{0}\\) is the correlation matrix – ones on the diagonal, correlation coefficients off diagonal.\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\ndata = (\n    data[\n        [\n            \"Culmen Length (mm)\",\n            \"Culmen Depth (mm)\",\n            \"Flipper Length (mm)\",\n            \"Body Mass (g)\",\n        ]\n    ]\n    .dropna()\n    .values\n)\n# axis=0 means take the average of the columns (summarize over rows)\ndata.mean(axis=0)\n\n# \"center\" each column; scale column 3\ndata0 = data - data.mean(axis=0)\nprint(np.linalg.norm(data0, axis=0))\ndata0 = data0 / np.linalg.norm(data0, axis=0)\nD = data0.transpose() @ data0\nprint(D)\nplt.imshow(D, cmap=\"hot\", interpolation=\"nearest\")\nplt.title(\"covariance matrix heatmap\")\n\n[  100.81768459    36.46689639   259.66621062 14809.0410685 ]\n[[ 1.         -0.23505287  0.65618134  0.59510982]\n [-0.23505287  1.         -0.58385122 -0.47191562]\n [ 0.65618134 -0.58385122  1.          0.87120177]\n [ 0.59510982 -0.47191562  0.87120177  1.        ]]\n\n\nText(0.5, 1.0, 'covariance matrix heatmap')\n\n\n\n\n\n\nplt.scatter(x=data0[:, 2], y=data0[:, 3])\n\n<matplotlib.collections.PathCollection at 0x7f91f198a280>"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#rank-and-invertibility",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#rank-and-invertibility",
    "title": "Essential Linear Algebra",
    "section": "Rank and invertibility",
    "text": "Rank and invertibility\nThe column rank of a matrix is the dimension of the space spanned by its columns; this is the number of linearly independent columns.\nThe row rank is the number of linearly independent rows.\nTheorem: These two numbers are equal."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html",
    "title": "Fundamentals of Machine Learning",
    "section": "",
    "text": "The numpy library is the main tool for linear algebra in python.\n\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#creating-and-shaping-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#creating-and-shaping-arrays",
    "title": "Fundamentals of Machine Learning",
    "section": "Creating and shaping arrays",
    "text": "Creating and shaping arrays\n\nm = np.array([1, 2, 3, 4, 5, 6, 7, 8])\nprint(\"Array {} with shape {} (a row vector)\".format(m, m.shape))\nprint(\"Reshaped array to shape (2,4):\\n {}\".format(m.reshape((2, 4))))\nprint(\"Reshaped array to column vector:\\n {}\".format(m.reshape(8, 1)))\n\nArray [1 2 3 4 5 6 7 8] with shape (8,) (a row vector)\nReshaped array to shape (2,4):\n [[1 2 3 4]\n [5 6 7 8]]\nReshaped array to column vector:\n [[1]\n [2]\n [3]\n [4]\n [5]\n [6]\n [7]\n [8]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#some-special-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#some-special-arrays",
    "title": "Fundamentals of Machine Learning",
    "section": "Some special arrays",
    "text": "Some special arrays\n\none = np.ones(shape=(3, 4))\nprint(one)\nzero = np.zeros(shape=(3, 3))\nprint(zero)\nd = np.diag([1, 2, 3, 4])\nprint(d)\n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]]\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n[[1 0 0 0]\n [0 2 0 0]\n [0 0 3 0]\n [0 0 0 4]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#addition-and-scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#addition-and-scalar-multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Addition and scalar multiplication",
    "text": "Addition and scalar multiplication\n\nx = np.random.normal(size=(4,))\ny = np.random.normal(size=(4,))\nprint(x + y)\nu = np.random.normal(size=(2,))\ntry:\n    print(x + u)\nexcept:\n    print(\"Cant Mix These\")\n\n[-1.07860461 -2.01082556 -0.73317181 -0.27922611]\nCant Mix These"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#broadcasting",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#broadcasting",
    "title": "Fundamentals of Machine Learning",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nx = np.array([[1, 2], [3, 4]])\nprint(\"x={}\".format(x))\nprint(\"x-1={}\".format(x - 1))\nz = np.array([1, 2])\nprint(\"z={}\".format(z))\nprint(\"x-z={}\".format(x - z))\nz = np.array([[3], [4]])\nprint(\"z={}\".format(z))\nprint(\"x-z={}\".format(x - z))\n\nx=[[1 2]\n [3 4]]\nx-1=[[0 1]\n [2 3]]\nz=[1 2]\nx-z=[[0 0]\n [2 2]]\nz=[[3]\n [4]]\nx-z=[[-2 -1]\n [-1  0]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#element-by-element",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#element-by-element",
    "title": "Fundamentals of Machine Learning",
    "section": "Element by Element",
    "text": "Element by Element\n\nx = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\nprint(1 / x)\nprint(np.log(x))\n\n[[1.         0.5        0.33333333]\n [0.5        0.33333333 0.25      ]\n [0.25       0.2        0.16666667]]\n[[0.         0.69314718 1.09861229]\n [0.69314718 1.09861229 1.38629436]\n [1.38629436 1.60943791 1.79175947]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Multiplication",
    "text": "Multiplication\n\nx = np.random.normal(size=(3, 4))\nprint(x)\ny = np.random.normal(size=(4, 1))\nprint(y)\nprint(x @ y)\n\n[[ 0.04684751  0.78677568 -2.00441577  1.22379046]\n [-1.33771959  1.49536894  0.87015839  2.84501276]\n [ 0.23392267  1.95021894 -1.22110799  0.09849131]]\n[[-0.07852097]\n [ 0.2726073 ]\n [-0.38097843]\n [ 0.60552613]]\n[[1.71547855]\n [1.90390551]\n [1.03813094]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#transpose",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#transpose",
    "title": "Fundamentals of Machine Learning",
    "section": "Transpose",
    "text": "Transpose\n\nx = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\nprint(x)\nprint(x.transpose())\n\n[[1 2 3]\n [2 3 4]\n [3 4 5]]\n[[1 2 3]\n [2 3 4]\n [3 4 5]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#norm",
    "title": "Fundamentals of Machine Learning",
    "section": "Norm",
    "text": "Norm\n\nx = np.array([[1, 2], [3, 4]])\nprint(x)\ny = np.linalg.norm(x)\nprint(y)\ny = np.linalg.norm(x, axis=0)\nprint(\"axis=0 yields row norms: {}\".format(y))\ny = np.linalg.norm(x, axis=1)\nprint(\"axis=1 yields column norms: {}\".format(y))\n\n[[1 2]\n [3 4]]\n5.477225575051661\naxis=0 yields row norms: [3.16227766 4.47213595]\naxis=1 yields column norms: [2.23606798 5.        ]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#rank",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#rank",
    "title": "Fundamentals of Machine Learning",
    "section": "Rank",
    "text": "Rank\n\nx = np.array([[1,2],[3,4]])\nnp.linalg.matrix_rank(x)\n\n2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#dataframes-and-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#dataframes-and-matrices",
    "title": "Fundamentals of Machine Learning",
    "section": "Dataframes and matrices",
    "text": "Dataframes and matrices\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\nprint(data[[\"Body Mass (g)\"]])\nprint(data[[\"Body Mass (g)\"]].values)\n\n     Body Mass (g)\n0           3750.0\n1           3800.0\n2           3250.0\n3              NaN\n4           3450.0\n..             ...\n339         4000.0\n340         3400.0\n341         3775.0\n342         4100.0\n343         3775.0\n\n[344 rows x 1 columns]\n[[3750.]\n [3800.]\n [3250.]\n [  nan]\n [3450.]\n [3650.]\n [3625.]\n [4675.]\n [3475.]\n [4250.]\n [3300.]\n [3700.]\n [3200.]\n [3800.]\n [4400.]\n [3700.]\n [3450.]\n [4500.]\n [3325.]\n [4200.]\n [3400.]\n [3600.]\n [3800.]\n [3950.]\n [3800.]\n [3800.]\n [3550.]\n [3200.]\n [3150.]\n [3950.]\n [3250.]\n [3900.]\n [3300.]\n [3900.]\n [3325.]\n [4150.]\n [3950.]\n [3550.]\n [3300.]\n [4650.]\n [3150.]\n [3900.]\n [3100.]\n [4400.]\n [3000.]\n [4600.]\n [3425.]\n [2975.]\n [3450.]\n [4150.]\n [3500.]\n [4300.]\n [3450.]\n [4050.]\n [2900.]\n [3700.]\n [3550.]\n [3800.]\n [2850.]\n [3750.]\n [3150.]\n [4400.]\n [3600.]\n [4050.]\n [2850.]\n [3950.]\n [3350.]\n [4100.]\n [3050.]\n [4450.]\n [3600.]\n [3900.]\n [3550.]\n [4150.]\n [3700.]\n [4250.]\n [3700.]\n [3900.]\n [3550.]\n [4000.]\n [3200.]\n [4700.]\n [3800.]\n [4200.]\n [3350.]\n [3550.]\n [3800.]\n [3500.]\n [3950.]\n [3600.]\n [3550.]\n [4300.]\n [3400.]\n [4450.]\n [3300.]\n [4300.]\n [3700.]\n [4350.]\n [2900.]\n [4100.]\n [3725.]\n [4725.]\n [3075.]\n [4250.]\n [2925.]\n [3550.]\n [3750.]\n [3900.]\n [3175.]\n [4775.]\n [3825.]\n [4600.]\n [3200.]\n [4275.]\n [3900.]\n [4075.]\n [2900.]\n [3775.]\n [3350.]\n [3325.]\n [3150.]\n [3500.]\n [3450.]\n [3875.]\n [3050.]\n [4000.]\n [3275.]\n [4300.]\n [3050.]\n [4000.]\n [3325.]\n [3500.]\n [3500.]\n [4475.]\n [3425.]\n [3900.]\n [3175.]\n [3975.]\n [3400.]\n [4250.]\n [3400.]\n [3475.]\n [3050.]\n [3725.]\n [3000.]\n [3650.]\n [4250.]\n [3475.]\n [3450.]\n [3750.]\n [3700.]\n [4000.]\n [4500.]\n [5700.]\n [4450.]\n [5700.]\n [5400.]\n [4550.]\n [4800.]\n [5200.]\n [4400.]\n [5150.]\n [4650.]\n [5550.]\n [4650.]\n [5850.]\n [4200.]\n [5850.]\n [4150.]\n [6300.]\n [4800.]\n [5350.]\n [5700.]\n [5000.]\n [4400.]\n [5050.]\n [5000.]\n [5100.]\n [4100.]\n [5650.]\n [4600.]\n [5550.]\n [5250.]\n [4700.]\n [5050.]\n [6050.]\n [5150.]\n [5400.]\n [4950.]\n [5250.]\n [4350.]\n [5350.]\n [3950.]\n [5700.]\n [4300.]\n [4750.]\n [5550.]\n [4900.]\n [4200.]\n [5400.]\n [5100.]\n [5300.]\n [4850.]\n [5300.]\n [4400.]\n [5000.]\n [4900.]\n [5050.]\n [4300.]\n [5000.]\n [4450.]\n [5550.]\n [4200.]\n [5300.]\n [4400.]\n [5650.]\n [4700.]\n [5700.]\n [4650.]\n [5800.]\n [4700.]\n [5550.]\n [4750.]\n [5000.]\n [5100.]\n [5200.]\n [4700.]\n [5800.]\n [4600.]\n [6000.]\n [4750.]\n [5950.]\n [4625.]\n [5450.]\n [4725.]\n [5350.]\n [4750.]\n [5600.]\n [4600.]\n [5300.]\n [4875.]\n [5550.]\n [4950.]\n [5400.]\n [4750.]\n [5650.]\n [4850.]\n [5200.]\n [4925.]\n [4875.]\n [4625.]\n [5250.]\n [4850.]\n [5600.]\n [4975.]\n [5500.]\n [4725.]\n [5500.]\n [4700.]\n [5500.]\n [4575.]\n [5500.]\n [5000.]\n [5950.]\n [4650.]\n [5500.]\n [4375.]\n [5850.]\n [4875.]\n [6000.]\n [4925.]\n [  nan]\n [4850.]\n [5750.]\n [5200.]\n [5400.]\n [3500.]\n [3900.]\n [3650.]\n [3525.]\n [3725.]\n [3950.]\n [3250.]\n [3750.]\n [4150.]\n [3700.]\n [3800.]\n [3775.]\n [3700.]\n [4050.]\n [3575.]\n [4050.]\n [3300.]\n [3700.]\n [3450.]\n [4400.]\n [3600.]\n [3400.]\n [2900.]\n [3800.]\n [3300.]\n [4150.]\n [3400.]\n [3800.]\n [3700.]\n [4550.]\n [3200.]\n [4300.]\n [3350.]\n [4100.]\n [3600.]\n [3900.]\n [3850.]\n [4800.]\n [2700.]\n [4500.]\n [3950.]\n [3650.]\n [3550.]\n [3500.]\n [3675.]\n [4450.]\n [3400.]\n [4300.]\n [3250.]\n [3675.]\n [3325.]\n [3950.]\n [3600.]\n [4050.]\n [3350.]\n [3450.]\n [3250.]\n [4050.]\n [3800.]\n [3525.]\n [3950.]\n [3650.]\n [3650.]\n [4000.]\n [3400.]\n [3775.]\n [4100.]\n [3775.]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#datatypes",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#datatypes",
    "title": "Fundamentals of Machine Learning",
    "section": "Datatypes",
    "text": "Datatypes\n\nx = np.array([[1, 2, 3], [2, 3, 4]], dtype=int)\nprint(x)\ny = np.array([[1, 2, 3], [2, 3, 4]], dtype=float)\nprint(y)\nprint(x + y)\n\n[[1 2 3]\n [2 3 4]]\n[[1. 2. 3.]\n [2. 3. 4.]]\n[[2. 4. 6.]\n [4. 6. 8.]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#creating-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#creating-matrices",
    "title": "Fundamentals of Machine Learning",
    "section": "Creating matrices",
    "text": "Creating matrices\n\nm <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 1)\nn <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 2)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    1    2    3    4    5    6    7    8\n\nprint(n)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#reshaping-and-broadcasting",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#reshaping-and-broadcasting",
    "title": "Fundamentals of Machine Learning",
    "section": "Reshaping and broadcasting",
    "text": "Reshaping and broadcasting\n\nm <- matrix(1:8)\nprint(m)\n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3\n[4,]    4\n[5,]    5\n[6,]    6\n[7,]    7\n[8,]    8\n\nm <- matrix(m, nrow = 2)\nprint(m)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\nm <- matrix(m, ncol = 2)\nprint(m)\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\n# note that R repeats things if they fit\nm <- matrix(c(1, 2), ncol = 10)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    2    1    2    1    2    1    2    1     2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#special-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#special-matrices",
    "title": "Fundamentals of Machine Learning",
    "section": "Special matrices",
    "text": "Special matrices\n\none <- matrix(1, nrow = 2, ncol = 3)\nprint(one)\n\n     [,1] [,2] [,3]\n[1,]    1    1    1\n[2,]    1    1    1\n\nzero <- matrix(0, nrow = 2, ncol = 3)\nprint(zero)\n\n     [,1] [,2] [,3]\n[1,]    0    0    0\n[2,]    0    0    0\n\nd <- diag(c(1, 2, 3, 4, 5))\nprint(d)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    0    0    0    0\n[2,]    0    2    0    0    0\n[3,]    0    0    3    0    0\n[4,]    0    0    0    4    0\n[5,]    0    0    0    0    5"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#addition-and-scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#addition-and-scalar-multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Addition and scalar multiplication",
    "text": "Addition and scalar multiplication\n\nx <- rnorm(4)\ny <- rnorm(4)\nprint(x + y)\n\n[1] -2.1037894 -1.4304159  1.6934975 -0.6133824\n\n# note that in R this makes sense\nu <- rnorm(2)\nprint(x + u)\n\n[1] -2.9142406 -1.7279669 -0.1146916 -2.5431762"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#element-by-element",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#element-by-element",
    "title": "Fundamentals of Machine Learning",
    "section": "Element by element",
    "text": "Element by element\n\nu = matrix(rnorm(20), ncol = 4)\nv = matrix(rnorm(20), ncol = 4)\nprint(u + v)\n\n           [,1]       [,2]       [,3]      [,4]\n[1,]  1.4329247  1.9759688  0.2877989  2.949777\n[2,] -0.6982862 -0.5985286  2.2305668 -0.497021\n[3,] -1.7256782  1.6170836  0.1721382  1.647774\n[4,]  0.4338453  0.1180034  0.5824849  2.240682\n[5,]  0.6738129 -1.9124949 -0.1324704  2.918217\n\nprint(u)\n\n           [,1]       [,2]       [,3]        [,4]\n[1,]  1.0547037  0.2258469 -0.2258626  1.73197392\n[2,]  0.5285672 -0.3444427  0.3950464 -0.06605677\n[3,] -0.8313874  0.2542622  0.7929003  0.98268556\n[4,] -0.8175623 -0.1955133 -0.3302900  2.15760687\n[5,] -0.8021234 -0.6320468  0.2825697  1.81576120\n\nprint(1 / u)\n\n           [,1]      [,2]      [,3]        [,4]\n[1,]  0.9481336  4.427779 -4.427470   0.5773759\n[2,]  1.8919071 -2.903240  2.531348 -15.1384948\n[3,] -1.2028087  3.932948  1.261193   1.0176195\n[4,] -1.2231484 -5.114742 -3.027642   0.4634765\n[5,] -1.2466910 -1.582161  3.538950   0.5507332\n\nprint(log(abs(u)))\n\n            [,1]       [,2]       [,3]        [,4]\n[1,]  0.05325988 -1.4878980 -1.4878283  0.54926175\n[2,] -0.63758536 -1.0658274 -0.9287520 -2.71724083\n[3,] -0.18465943 -1.3693892 -0.2320578 -0.01746609\n[4,] -0.20142818 -1.6321271 -1.1077842  0.76899968\n[5,] -0.22049288 -0.4587918 -1.2638300  0.59650477"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#slices-using-apply",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#slices-using-apply",
    "title": "Fundamentals of Machine Learning",
    "section": "Slices using apply",
    "text": "Slices using apply\n\nu = matrix(rnorm(20), ncol = 4)\nprint(colMeans(u))\n\n[1] -0.5212116 -0.5681615  0.7080600  0.5048978\n\nprint(rowMeans(u))\n\n[1] -0.5530287  0.1067158  0.3077092 -0.1832878  0.4763722\n\napply(u, 1, function(x) mean(x))\n\n[1] -0.5530287  0.1067158  0.3077092 -0.1832878  0.4763722\n\napply(u, 2, function(x) var(x))\n\n[1] 1.0098110 0.6319386 0.1474439 0.5971405"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Multiplication",
    "text": "Multiplication\n\nx <- matrix(rnorm(12), nrow = 3)\ny <- matrix(rnorm(15), ncol = 3)\nprint(y %*% x)\n\n          [,1]       [,2]       [,3]        [,4]\n[1,] -4.635421 -3.0440807 -0.2415493  2.04916853\n[2,]  0.836025  0.7097780  0.1428981 -0.03927833\n[3,]  4.335570  2.6573764  0.5240583 -1.57242168\n[4,] -0.754871  2.2121347 -0.6641564  1.83609356\n[5,]  2.763042  0.9533438 -0.6809747 -3.50833833"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#transpose",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#transpose",
    "title": "Fundamentals of Machine Learning",
    "section": "Transpose",
    "text": "Transpose\n\nx = matrix(rnorm(12), nrow = 3)\nprint(t(x))\n\n           [,1]       [,2]        [,3]\n[1,] -1.7056572  0.5402882 -0.32563790\n[2,]  0.0529007 -0.9288533  1.31451113\n[3,] -0.7423898 -0.3594810 -0.06003756\n[4,] -0.7855897  0.5074435 -0.51050585\n\nprint(nrow(t(x)))\n\n[1] 4"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#norm",
    "title": "Fundamentals of Machine Learning",
    "section": "Norm",
    "text": "Norm\n\nx = matrix(c(1, 2, 3, 4), nrow = 2)\nnorm(x, type = \"2\")\n\n[1] 5.464986\n\napply(x, 2, function(x) norm(x, type = \"2\"))\n\n[1] 2.236068 5.000000\n\napply(x, 1, function(x) norm(x, type = \"2\"))\n\n[1] 3.162278 4.472136"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#rank",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#rank",
    "title": "Fundamentals of Machine Learning",
    "section": "Rank",
    "text": "Rank\n\nlibrary(Matrix)\nx = matrix(c(1,2,3,4),nrow=2)\nz=rankMatrix(x)\nz[[1]]\n\n[1] 2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#dataframes-and-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#dataframes-and-arrays",
    "title": "Fundamentals of Machine Learning",
    "section": "Dataframes and arrays",
    "text": "Dataframes and arrays\nUse the “[[]]” or as.vector to convert tibbles to vectors.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ndata = read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmass <- data |> select(\"Body Mass (g)\")\nprint(mass)\n\n# A tibble: 344 × 1\n   `Body Mass (g)`\n             <dbl>\n 1            3750\n 2            3800\n 3            3250\n 4              NA\n 5            3450\n 6            3650\n 7            3625\n 8            4675\n 9            3475\n10            4250\n# ℹ 334 more rows\n\nprint(as.vector(mass))\n\n$`Body Mass (g)`\n  [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400\n [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950\n [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000\n [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750\n [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700\n [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600\n [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925\n[106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325\n[121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425\n[136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750\n[151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650\n[166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650\n[181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300\n[196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000\n[211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100\n[226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300\n[241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975\n[256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000\n[271] 4925   NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150\n[286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800\n[301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700\n[316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050\n[331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775\n\n\nprint(data[“Body Mass (g)”]) print(data[[‘Body Mass (g)’]])"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html",
    "href": "chapters/07-Calculus/calculus.html",
    "title": "Key ideas from calculus",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-dark')"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#why-calculus-in-data-science",
    "href": "chapters/07-Calculus/calculus.html#why-calculus-in-data-science",
    "title": "Key ideas from calculus",
    "section": "Why Calculus in data science?",
    "text": "Why Calculus in data science?\nThe central application of calculus in data science is in the problem of “optimization.” ML algorithms generally ask for the “best fit” of something, and the “best fit” usually means finding the parameters where a measure of error, a loss function, is as small as possible.\n(Differential) calculus is the most powerful tool we have for finding the minimal (or maximum) values of functions.\nCalculus also plays a key role in Probability and Statistics, because questions about probability in continuous settings relies on the idea of an integral."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#one-variable-differential-calculus",
    "href": "chapters/07-Calculus/calculus.html#one-variable-differential-calculus",
    "title": "Key ideas from calculus",
    "section": "One-variable differential calculus",
    "text": "One-variable differential calculus\n\nSimple function with one input variable and one output variable\nDerivative measures rate of change of output with respect to input\nFamous formula: given a function \\(f:\\mathbf{R}\\to\\mathbf{R}\\), the derivative is defined by \\[\nf'(x) = \\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\n\\]"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#interpretations-of-the-derivative",
    "href": "chapters/07-Calculus/calculus.html#interpretations-of-the-derivative",
    "title": "Key ideas from calculus",
    "section": "Interpretations of the derivative",
    "text": "Interpretations of the derivative\n\n“Slope of the curve”\n“Rate of change”\n\n\nx=np.linspace(0,1, 100)\ny=x**3*(1-x)**5\nplt.plot(x,y)\nm = (y[41]-y[40])/.01 # <1>\nytan = y[40]+m*(x-x[40]) # <2>\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('$x^3(1-x)^5$ with tangent line at $x=.4$')\nim = plt.plot(x,ytan)\n\n\n\n\n\nHere we compute the (approximate) slope/derivative m at the point (x[40],y[40])\nThis is the equation of the line through that point with the computed slope.\n\nKey facts:\n\nDerivative is positive means function is increasing\nDerivative is negative means function is decreasing\nDerivative is zero means a critical point, often a local maximum or local minimum."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#an-example",
    "href": "chapters/07-Calculus/calculus.html#an-example",
    "title": "Key ideas from calculus",
    "section": "An example",
    "text": "An example\n\nfig, axes = plt.subplots(1, 2, sharey=\"row\")\nfig.set_size_inches(8, 4)\n# ----\nx = np.linspace(0, 1, 100)\ny = x**3 * (1 - x) ** 5\naxes[0].plot(x, y)\nt1 = axes[0].set_title(r\"$f(x)=x^3(1-x)^5$\")\naxes[0].grid()\n# ----\nyprime = (y[1:] - y[:-1]) / 0.01  #  <1>\naxes[1].plot(x[1:], yprime)\naxes[1].grid()\nt2 = axes[1].set_title(r\"$f'(x)$\")\n\n\n\n\n\nThe array y has the y values corresponding to the x values in the array x. So the difference y[1:]-y[:-1] is \\(f(x+h)-f(x)\\). Since there are 100 x values between 0 and 1, \\(h=.01\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#some-key-reminders-from-differential-calculus",
    "href": "chapters/07-Calculus/calculus.html#some-key-reminders-from-differential-calculus",
    "title": "Key ideas from calculus",
    "section": "Some key reminders from differential calculus",
    "text": "Some key reminders from differential calculus\n\nThe derivative is linear, so the derivative of a sum is the sum of the derivatives and the derivative \\((af(x))'\\) is \\(af'(x)\\).\nThe derivative of a constant is zero.\nThe derivative of \\(x^{n}\\) is \\(nx^{n-1}\\).\n\nThe derivative of \\(e^{x}\\) is \\(e^{x}\\).\nThe derivative of \\(\\log(x)\\) is \\(1/x\\) (natural logarithm)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#notation",
    "href": "chapters/07-Calculus/calculus.html#notation",
    "title": "Key ideas from calculus",
    "section": "Notation",
    "text": "Notation\nSometimes we write \\(f'(x)\\), sometimes \\(\\frac{df}{dx}\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-product-rule",
    "href": "chapters/07-Calculus/calculus.html#the-product-rule",
    "title": "Key ideas from calculus",
    "section": "The product rule",
    "text": "The product rule\nThe derivative of a product of functions \\(fg\\) satisfies the product rule \\[\n(fg)'=fg'+f'g\n\\]"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-chain-rule",
    "href": "chapters/07-Calculus/calculus.html#the-chain-rule",
    "title": "Key ideas from calculus",
    "section": "The chain rule",
    "text": "The chain rule\nThe chain rule is a key fact from one variable calculus. Its simple form is\n\\[\n\\frac{d}{dt}f(x+th)|_{t=0}=hf'(x)\n\\]\nand more generally\n\\[\n\\frac{d}{dx}(f(g(x))) = f'(g(x))g'(x)\n\\]"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#functions-of-several-variables",
    "href": "chapters/07-Calculus/calculus.html#functions-of-several-variables",
    "title": "Key ideas from calculus",
    "section": "Functions of several variables",
    "text": "Functions of several variables\nIn data science, we generally want to look at functions that depend on many variables, rather than just one.\nFor example, let us consider the problem of finding the line of best fit to a collection of points \\((x,y)\\).\nFirst we generate some random data to work with.\n\nx=np.linspace(0,5,20)\ny=3*x+1+np.random.normal(0,2,size=x.shape[0]) #<1>\nplt.scatter(x,y)\nplt.grid()\nplt.title(\"$y=3+1+\\epsilon$ where $\\epsilon$ is a normal error\")\n\nText(0.5, 1.0, '$y=3+1+\\\\epsilon$ where $\\\\epsilon$ is a normal error')\n\n\n\n\n\n\nHere we find \\(y=3x+1+\\epsilon\\) where \\(\\epsilon\\) is drawn from a normal random variable with standard deviation \\(2\\).\n\nThe line of best fit has the equation \\(y=mx+b\\) where \\(m\\) and \\(b\\) are the unknowns. The “error” is \\[\nE(m,b) = \\frac{1}{N}\\sum_{i=1}^{N} (y_i-mx_i-b)^2\n\\]\nThe \\(x_i\\) and \\(y_i\\) are the data, and \\(m\\) and \\(b\\) are the things we want to find. So this is a function of two variables.\nIt is a (possibly very big) quadratic function of \\(m\\) and \\(b\\).\nBut in more general regression problems we may have many slopes \\(m_{i}\\) so our error depends on many variables.\nIn neural networks there may be billions of parameters."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#visualization-of-functions-of-two-variables",
    "href": "chapters/07-Calculus/calculus.html#visualization-of-functions-of-two-variables",
    "title": "Key ideas from calculus",
    "section": "Visualization of functions of two variables",
    "text": "Visualization of functions of two variables\nContour plots are a way to represent a function of two variables. For example suppose \\(f(x,y)=3x^2+2xy+5y^22\\).\n\nfig,ax = plt.subplots()\nx=np.linspace(-3,3,40)\ny=np.linspace(-3,3,40)\nax.set_aspect('equal')                          #<1>\nxx,yy = np.meshgrid(x,y)                        #<2>\nz = 3*xx**2+2*xx*yy+5*yy**2\nax.contour(xx,yy,z)\nax.grid()\n\n\n\n\n\nWhy do you need this?\nmeshgrid changes two one-dimensional arrays into two two dimensional arrays - examine them to see what happens.\n\n\nfrom scipy.stats import norm\nfig,ax = plt.subplots()\nx=np.linspace(-10,10,50)\ny=np.linspace(-10,10,50)\nxx,yy = np.meshgrid(x,y)\nz = 3*norm.pdf(np.sqrt((xx-2)**2+(xx-2)*(yy-3)+(yy-3)**2))-5*norm.pdf(np.sqrt((xx+3)**2+(yy+1)**2))\nP=ax.contourf(xx,yy,z,levels=10)\nQ=ax.contour(xx,yy,z,levels=np.linspace(-1,1,19),colors='black')\nt=ax.clabel(Q,inline=True,fontsize=5)\nt=ax.set_title(\"Contour Plot of sum of two Gaussians\")"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#plotting-in-3d",
    "href": "chapters/07-Calculus/calculus.html#plotting-in-3d",
    "title": "Key ideas from calculus",
    "section": "Plotting in 3d",
    "text": "Plotting in 3d\nGenerally 3d plots aren’t that useful, but sometimes you just really want one.\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211,projection='3d')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = norm.pdf(np.sqrt(xx**2+yy**2))\nax.plot_wireframe(xx,yy,z,cmap='gray')\nax = fig.add_subplot(212)\nQ=ax.contour(xx,yy,z)\nax.clabel(Q)\nax.set_aspect('equal')\n\n\n\n\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211,projection='3d')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = xx**2-yy**2\nax.plot_wireframe(xx,yy,z,cmap='gray')\nax = fig.add_subplot(212)\nQ=ax.contour(xx,yy,z,levels=10)\nax.clabel(Q)\nax.set_aspect('equal')\nax.grid()"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#vectors-and-functions",
    "href": "chapters/07-Calculus/calculus.html#vectors-and-functions",
    "title": "Key ideas from calculus",
    "section": "Vectors and functions",
    "text": "Vectors and functions\nIt’s useful to think of a function of multiple variables \\(x_1,\\ldots, x_n\\) as a function of a vector \\(\\mathbf{x}=(x_1,\\ldots, x_n)\\).\nIf \\(x_0\\) is a point in \\(\\mathbf{R}^{n}\\) (thought of as a vector) and \\(v\\) is another vector, then the points \\[\n\\ell(t) = x_0+tv\n\\]\ntrace out a line as \\(t\\) varies.\nFor example if \\(x_0=(1,1)\\) and \\(v=(-2,3)\\) then \\[\n\\ell(t) = (1-2t,2+3t)\n\\]\n\nx = np.array([1,1]).reshape(2,1)  # <1>\nv = np.array([-2,3]).reshape(2,1)\nt=np.arange(-5,5,1)\npts = x+t*v\nplt.grid()\nplt.plot(pts[0,:],pts[1,:],color='black')\nplt.plot([1],[1],marker=\"*\",markersize=12,color='red')\nplt.arrow(1,1,-2,3,color='blue',width=.4)\nplt.scatter(pts[0,:],pts[1,:])\nplt.title(\"Vector form of a line from (1,1) towards v=(-2,3)\")\nplt.xlabel('x')\n_=plt.ylabel('y')\n\n\n\n\n\nTo see why x and v need to be column vectors, try this without the reshape and look at the error you get.\n\nIn this version, the vector \\(v\\) represents the velocity of a point travelling along the line. So the dots are the position of the object at different times \\(t\\).\nIf we scale \\(v\\) by a constant:\n\nthe line stays the same\nthe speed is different\n\nThe speed is \\(\\|v\\|\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#directional-derivatives",
    "href": "chapters/07-Calculus/calculus.html#directional-derivatives",
    "title": "Key ideas from calculus",
    "section": "Directional Derivatives",
    "text": "Directional Derivatives\nFor a function of multiple variables, the directional derivative is the rate of change in a particular direction.\n\\[\nD_{v}(f)(\\mathbf{x}) = \\frac{d}{dt}f(\\mathbf{x}+t\\mathbf{v})|_{t=0}\n\\]\nThis means: how fast is \\(f\\) at time zero as you travel through space in a straight line with velocity \\(v\\) passing through point \\(x\\).\nDepends on direction and magnitude of \\(v\\).\nSuppose that \\(f(\\overline{x})=x_1^2-x_0^2\\), that \\(\\mathbf{x}=(1,1)\\) and that \\(v=(-.4,.6)\\) Then\n\\[\n\\mathbf{x}+t\\mathbf{v} = (1-.4t,1+.6t)\n\\]\nand \\[\nf(\\mathbf{x}+t\\mathbf{v}) = (1-.4t)^2-(1+.6t)^2\n\\]\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211)\nax.set_title('contour plot with path')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = xx**2-yy**2\nQ=ax.contour(xx,yy,z,levels=10)\nax.clabel(Q)\nax.set_aspect('equal')\nax.grid()\n\nx = np.array([1,1]).reshape(2,1) \nv = np.array([-.4,.6]).reshape(2,1)\nt=np.arange(-10,10,1)\npts = x+t*v\nax.set_xlim((-5,5))\nax.set_ylim((-5,5))\nax.plot(pts[0,:],pts[1,:],color='black')\nax.plot([1],[1],marker=\"*\",markersize=12,color='red')\nax.arrow(1,1,-.4,.6,color='blue',width=.2)\nax.scatter(pts[0,:],pts[1,:])\n\nax1 = fig.add_subplot(212)\nax1.set_aspect('equal')\nax1.set_xticks(np.arange(-10,11,4))\nax1.set_title('Height vs time along path')\nht = -(1+0.6*t)**2+(1-0.4*t)**2\nax1.plot(np.arange(-10,10,1),ht)\nax1.plot([0],[0],marker='*',markersize=10)\nax1.grid()"
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#partial-derivatives",
    "href": "chapters/07-Calculus/calculus.html#partial-derivatives",
    "title": "Key ideas from calculus",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\nThe partial derivatives of a function are the special cases of the directional derivative in the direction of coordinate axes.\nSo if \\(f\\) is a function of \\(\\mathbf{x}=(x_0,\\ldots, x_{n-1})\\) and if \\(\\mathbf{e}_{i}\\) is the vector \\[\ne_{i} = (0,0,\\ldots,0,1,0,\\ldots, 0)\n\\] where the \\(1\\) is in the \\(i^{th}\\) position, then \\[\n\\frac{\\partial f}{\\partial x_{i}}=D_{e_{i}}f.\n\\]\nYou can compute the partial derivatives using calculus rules where you treat all of the variables except \\(x_{i}\\) as constants."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-vector-chain-rule",
    "href": "chapters/07-Calculus/calculus.html#the-vector-chain-rule",
    "title": "Key ideas from calculus",
    "section": "The vector chain rule",
    "text": "The vector chain rule\nThe vector chain rule says that \\[\n\\frac{d}{dt}f(x_1(t),x_2(t),\\ldots, x_n(t))=\\frac{\\partial f}{\\partial x_1}\\frac{d x_1}{d t}+\\frac{\\partial f}{\\partial x_2}\\frac{d x_2}{d t}+\\cdots+\\frac{\\partial f}{\\partial x_n}\\frac{d x_n}{d t}\n\\]\nHere \\((x_1(t),\\ldots,x_n(t))\\) can be thought of as a path where the \\(x_i\\) vary with time \\(t\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-gradient",
    "href": "chapters/07-Calculus/calculus.html#the-gradient",
    "title": "Key ideas from calculus",
    "section": "The gradient",
    "text": "The gradient\nSuppose that \\(f\\) is a function of variables \\(x_1,\\ldots, x_n\\). The gradient of \\(f\\), written \\(\\nabla f\\), is a vector valued function where\n\\[\n\\nabla f (x) = \\left[\\begin{matrix} \\frac{\\partial f}{\\partial x_0} & \\frac{\\partial f}{\\partial x_1} & \\cdots & \\frac{\\partial f}{\\partial x_n} \\end{matrix}\\right]\n\\]\nThe gradient of \\(f\\) gives a vector at each point."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#key-property-of-the-gradient",
    "href": "chapters/07-Calculus/calculus.html#key-property-of-the-gradient",
    "title": "Key ideas from calculus",
    "section": "Key property of the gradient",
    "text": "Key property of the gradient\nTheorem: If \\(v\\) is any vector, then the directional derivative \\(D_{v}(f)=\\nabla f \\cdot v\\). As a result of this fact:\n\nThe gradient points in the direction where \\(f\\) increases most rapidly.\n\\(-\\nabla f\\) points in the direction where \\(f\\) decreases most rapidly.\nThe gradient is perpendicular to the contour lines of the function.\nThe gradient is zero at local minima and maxima of a function (but possibly also at other places)\n\nThese facts follow from the chain rule and properties of the dot product.\nFirst of all, \\[\nD_{v}(f)(\\mathbf{x}) = \\frac{d}{dt}f(\\mathbf{x}+t\\mathbf{v})=f(x_1+tv_1,x_2+tv_2,\\ldots, x_n+tv_n)|_{t=0}\n\\]\nFrom the vector chain rule this is the same as\n\\[\nD_{v}(f)(\\mathbf{x}) = \\frac{\\partial f}{\\partial x_1}v_1+\\frac{\\partial f}{\\partial x_2}v_2+\\cdots+\\frac{\\partial f}{\\partial x_n}v_{n}|_{t=0}\n\\] which is\n\\[\n(\\nabla f)(\\mathbf{x})\\cdot \\mathbf{v}.\n\\]\nBut the dot product satisfies\n\\[\n(\\nabla f)(\\mathbf{x})\\cdot \\mathbf{v} = \\|(\\nabla f)(\\mathbf{x})\\|\\|v\\|\\cos(\\theta)\n\\]\nwhere \\(\\theta\\) is the angle between the gradient and the vector \\(v\\). This is maximum when \\(\\theta=0\\), and minimum when \\(\\theta=\\pi\\).\nTo see the significance of this, check out this page.."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#functions-from-mathbfrm-to-mathbfrn-and-their-derivatives",
    "href": "chapters/07-Calculus/calculus.html#functions-from-mathbfrm-to-mathbfrn-and-their-derivatives",
    "title": "Key ideas from calculus",
    "section": "Functions from \\(\\mathbf{R}^{m}\\) to \\(\\mathbf{R}^{n}\\) and their derivatives",
    "text": "Functions from \\(\\mathbf{R}^{m}\\) to \\(\\mathbf{R}^{n}\\) and their derivatives\nThe most general situation we might want to consider is a function that converts a point in \\(\\mathbf{R}^{m}\\) to a point in \\(\\mathbf{R}^{n}\\):\n\\[\nF:\\mathbf{R}^{m}\\to \\mathbf{R}^{n}\n\\]\nHere is an example. Suppose we have \\(28\\times 28\\) images represented as arrays of pixel values. And suppose that we know that this image is a handwritten number between \\(0\\) and \\(9\\).\nAn image recognition neural network takes such an image an outputs a vector of length \\(10\\) of the form \\((p_0,\\ldots, p_{9})\\) where \\(p_i\\) is the probability that the image represents the digit \\(i\\).\nThis neural network is a function \\(F:\\mathbf{R}^{784}\\to \\mathbf{R}^{10}\\).\nSuch a function is actually given by \\(10\\) (or, more generally, \\(n\\)) “coordinate functions” \\(f_{i}\\), each of which is a function of \\(m\\) variables. So the neural network function \\(F\\) consists of functions \\[\np_{i} = F_{i}(x_0,\\ldots, x_{783})\\quad i=0,\\ldots, 9\n\\]\nEach of these functions has a gradient which measures how \\(p_{i}\\) changes if you modify the \\(x_i\\). The total derivative of \\(F\\) is made up of all of these gradients. You can think of this as a column vector of row vectors: \\[\nDF = \\left[\\begin{matrix} \\nabla F_{0} \\\\ \\nabla F_{1} \\\\  \\cdots \\\\ \\nabla F_{n}\\end{matrix}\\right]\n\\]\nwhere each \\(\\nabla F_{i}\\) is a row with \\(m\\) entries.\nBut this is really a matrix called the total derivative \\(DF\\) of \\(F\\) of size \\(n\\times m\\).\nThe total derivative tells us how a small step in \\(\\mathbf{R}^{m}\\) translates to a step in \\(\\mathbf{R}^{m}\\) when you apply the function \\(F:\\mathbf{R}^{m}\\to mathbf{R}^{n}\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#linear-functions",
    "href": "chapters/07-Calculus/calculus.html#linear-functions",
    "title": "Key ideas from calculus",
    "section": "Linear functions",
    "text": "Linear functions\nA very special case of a function from \\(F:\\mathbf{R}^{m}\\to mathbf{R}^{n}\\) is the situation where \\[\nF(x) = Ax\n\\] for an \\(n\\times m\\) matrix.\nIn this special case, the total derivative \\(DF\\) of \\(F\\) is the matrix \\(A\\)."
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-chain-rule-in-the-general-case",
    "href": "chapters/07-Calculus/calculus.html#the-chain-rule-in-the-general-case",
    "title": "Key ideas from calculus",
    "section": "The chain rule in the general case",
    "text": "The chain rule in the general case\nIf \\(F:\\mathbf{R}^{m}\\to\\mathbf{R}^{n}\\) is a function, and \\(G:\\mathbf{R}^{n}\\to\\mathbf{R}^{k}\\) is another function, then it makes sense to compute \\(G(F(x))\\) for \\(x\\in \\mathbf{R}^{m}\\), and the result is in \\(\\mathbf{R}^{k}\\).\nThe chain rule in general says that the derivative of \\(G(F(x))\\) is the product of the matrices corresponding to \\(DG\\) and \\(DF\\). Here \\(DG\\) is \\(k\\times n\\) and \\(DF\\) is \\(n\\times m\\) so \\((DG)(DF)\\) is \\(k\\times m\\) as it should be."
  },
  {
    "objectID": "chapters/08-Summarizing/experiments.html",
    "href": "chapters/08-Summarizing/experiments.html",
    "title": "Pandas Grouping and Summarizing",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "chapters/08-Summarizing/experiments.html#exercise",
    "href": "chapters/08-Summarizing/experiments.html#exercise",
    "title": "Pandas Grouping and Summarizing",
    "section": "Exercise",
    "text": "Exercise\nAre there missing values? If so, where?\nSuppose you want to study the price differential by neighborhood. To start, make a pivot table showing average price by neighborhood and room type.\nDo these exercises in R as well."
  },
  {
    "objectID": "chapters/08-Summarizing/groupingR.html",
    "href": "chapters/08-Summarizing/groupingR.html",
    "title": "Grouping and Summarizing in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\npenguins = read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npenguins |> summarise_all(class)\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species   Region    Island    Stage  `Individual ID`\n  <chr>     <chr>           <chr>     <chr>     <chr>     <chr>  <chr>          \n1 character numeric         character character character chara… character      \n# ℹ 10 more variables: `Clutch Completion` <chr>, `Date Egg` <chr>,\n#   `Culmen Length (mm)` <chr>, `Culmen Depth (mm)` <chr>,\n#   `Flipper Length (mm)` <chr>, `Body Mass (g)` <chr>, Sex <chr>,\n#   `Delta 15 N (o/oo)` <chr>, `Delta 13 C (o/oo)` <chr>, Comments <chr>\n\n\n\nFocus on the relevant numerical variables\n\n\nfocus <- c('Species','Island','Sex','Culmen Length (mm)','Culmen Depth (mm)','Flipper Length (mm)','Body Mass (g)')\nsimplified <- penguins |> select(all_of(focus))\n\n\nClean up the column names\n\nUsing a named vector\n\nedited_columns <- c(species = \"Species\", island = \"Island\", culmen_length='Culmen Length (mm)', culmen_depth = 'Culmen Depth (mm)', flipper_length = 'Flipper Length (mm)', body_mass = 'Body Mass (g)')\nrename(simplified, all_of(edited_columns))\n\n# A tibble: 344 × 7\n   species      island Sex   culmen_length culmen_depth flipper_length body_mass\n   <chr>        <chr>  <chr>         <dbl>        <dbl>          <dbl>     <dbl>\n 1 Adelie Peng… Torge… MALE           39.1         18.7            181      3750\n 2 Adelie Peng… Torge… FEMA…          39.5         17.4            186      3800\n 3 Adelie Peng… Torge… FEMA…          40.3         18              195      3250\n 4 Adelie Peng… Torge… <NA>           NA           NA               NA        NA\n 5 Adelie Peng… Torge… FEMA…          36.7         19.3            193      3450\n 6 Adelie Peng… Torge… MALE           39.3         20.6            190      3650\n 7 Adelie Peng… Torge… FEMA…          38.9         17.8            181      3625\n 8 Adelie Peng… Torge… MALE           39.2         19.6            195      4675\n 9 Adelie Peng… Torge… <NA>           34.1         18.1            193      3475\n10 Adelie Peng… Torge… <NA>           42           20.2            190      4250\n# ℹ 334 more rows\n\n\nRenaming with a function:. Note the escape codes (double ).\n\nfixer <- function(n) {\n        a <- gsub(\" \\\\(mm\\\\)\",\"\",n)\n        a <- gsub(\" \\\\(g\\\\)\",\"\",a)\n        a <- gsub(\" \",\"_\",a)\n        return(tolower(a))\n}\nsimplified <- rename_with(simplified,fixer)\n\n\nSimplify factor names\n\n\nspecies <- simplified |>\n    select(`species`) |>\n    unique()\nsimplified <- simplified |> mutate(`species` = tolower(word(`species`, 1)))\nsimplified <- simplified |> mutate(`island` = tolower(`island`))\nsimplified <- simplified |> mutate(`sex` = tolower(`sex`))\n\n\nMissing Values\n\nNote use of anonymous function.\n\nsimplified |> summarize_all(\\(x) sum(is.na(x)))\n\n# A tibble: 1 × 7\n  species island   sex culmen_length culmen_depth flipper_length body_mass\n    <int>  <int> <int>         <int>        <int>          <int>     <int>\n1       0      0    11             2            2              2         2\n\n\n\nsimplified |> summarize(across(culmen_length:body_mass,  \\(x) sum(is.na(x))))\n\n# A tibble: 1 × 4\n  culmen_length culmen_depth flipper_length body_mass\n          <int>        <int>          <int>     <int>\n1             2            2              2         2\n\n\n\nsimplified <- simplified |> filter(if_all(names(simplified), \\(x) !is.na(x)))\n\n\nStandardizing\n\nR can do it pretty efficiently using across and mutate.\n\nsimplified |> mutate(across(culmen_length:body_mass, list(std=\\(x) (x-mean(x))/sd(x))))\n\n# A tibble: 333 × 11\n   species island    sex    culmen_length culmen_depth flipper_length body_mass\n   <chr>   <chr>     <chr>          <dbl>        <dbl>          <dbl>     <dbl>\n 1 adelie  torgersen male            39.1         18.7            181      3750\n 2 adelie  torgersen female          39.5         17.4            186      3800\n 3 adelie  torgersen female          40.3         18              195      3250\n 4 adelie  torgersen female          36.7         19.3            193      3450\n 5 adelie  torgersen male            39.3         20.6            190      3650\n 6 adelie  torgersen female          38.9         17.8            181      3625\n 7 adelie  torgersen male            39.2         19.6            195      4675\n 8 adelie  torgersen female          41.1         17.6            182      3200\n 9 adelie  torgersen male            38.6         21.2            191      3800\n10 adelie  torgersen male            34.6         21.1            198      4400\n# ℹ 323 more rows\n# ℹ 4 more variables: culmen_length_std <dbl>, culmen_depth_std <dbl>,\n#   flipper_length_std <dbl>, body_mass_std <dbl>\n\n\n\nGrouping\n\n\nsimplified |> select(sex:body_mass) |> group_by(sex) |> summarize(across(culmen_length:body_mass,mean))\n\n# A tibble: 2 × 5\n  sex    culmen_length culmen_depth flipper_length body_mass\n  <chr>          <dbl>        <dbl>          <dbl>     <dbl>\n1 female          42.1         16.4           197.     3862.\n2 male            45.9         17.9           205.     4546.\n\n\n\nby_sex_and_species <- simplified |> group_by(species,sex) |> summarize(across(culmen_length:body_mass,mean))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\nYou can select using filter.\n\nby_sex_and_species |> filter(sex=='male')\n\n# A tibble: 3 × 6\n# Groups:   species [3]\n  species   sex   culmen_length culmen_depth flipper_length body_mass\n  <chr>     <chr>         <dbl>        <dbl>          <dbl>     <dbl>\n1 adelie    male           40.4         19.1           192.     4043.\n2 chinstrap male           51.1         19.3           200.     3939.\n3 gentoo    male           49.5         15.7           222.     5485.\n\n\n\nMaking a pivot table.\n\n\nby_sex_and_species |>\n    select(species, sex, culmen_length) |>\n    pivot_wider(names_from = species, values_from = culmen_length)\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  <chr>   <dbl>     <dbl>  <dbl>\n1 female   37.3      46.6   45.6\n2 male     40.4      51.1   49.5\n\n\n\nMaking a function for each possibility\n\n\nptable <- function(value) {\n    by_sex_and_species |>\n        select(species, sex, {{ value }}) |>\n        pivot_wider(names_from = species, values_from = {{ value }})\n}\nptable(\"body_mass\")\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  <chr>   <dbl>     <dbl>  <dbl>\n1 female  3369.     3527.  4680.\n2 male    4043.     3939.  5485."
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html",
    "href": "chapters/08-Summarizing/grouping_pandas.html",
    "title": "Grouping and Summarizing in Pandas",
    "section": "",
    "text": "dictionaries\nlambda functions"
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#refactoring",
    "href": "chapters/08-Summarizing/grouping_pandas.html#refactoring",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Refactoring",
    "text": "Refactoring\nSee this python script file for an example of how to pull out code into a python function that standardizes your data preparation. To use this, you can use the %load command in a jupyter notebook. The command %load filename loads the content of the file into an executable cell. You need to execute that cell.\nIf you modify the script, you need to reload it."
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#grouping-and-summarizing",
    "href": "chapters/08-Summarizing/grouping_pandas.html#grouping-and-summarizing",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\n\nimport pandas as pd\nimport  numpy as np\n\nOur first pass will be with our old friends the penguins.\n\npenguins = pd.read_csv(\"data/penguins-raw.csv\")"
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#some-basic-data-cleaning",
    "href": "chapters/08-Summarizing/grouping_pandas.html#some-basic-data-cleaning",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Some basic data cleaning",
    "text": "Some basic data cleaning\n\nData types\n\n\npenguins.dtypes\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\nComments                object\ndtype: object\n\n\n\nFocus on Species, Island, Sex, Culmen Length/Depth, Flipper Length, Body Mass.\n\n\nfocus = ['Species','Island','Sex','Culmen Length (mm)','Culmen Depth (mm)','Flipper Length (mm)', 'Body Mass (g)']\nsimplified = penguins[focus]\n\n\nClean up column names\n\n\nedited_columns = ['species','island','sex','culmen_length', 'culmen_depth','flipper_length','body_mass']\nsimplified.columns = edited_columns\n\n\nSimplify factor names. (Note use of dictionary)\n\n\nspecies = simplified['species'].unique()\nsimple_species_dict={x:x.split(' ')[0].lower() for x in species}\nsimplified['species'].map(simple_species_dict)\n\n0         adelie\n1         adelie\n2         adelie\n3         adelie\n4         adelie\n         ...    \n339    chinstrap\n340    chinstrap\n341    chinstrap\n342    chinstrap\n343    chinstrap\nName: species, Length: 344, dtype: object\n\n\n\nRemaking a column (watch out!)\n\n\n#simplified['species'] = simplified['species'].map(simple_species_dict)\n\nOld option: use .loc.\n\n#simplified.loc[:,'species'] = simplified['species'].map(simple_species_dict)\n\nNewer option: use .assign(). Notice that .assign() returns a dataframe.\n\nsimplified = simplified.assign(species = lambda x: x['species'].map(simple_species_dict))\n\nFix some other factor variables:\n\nsimplified  = simplified.assign(island = lambda x: x.island.str.lower())\nsimplified = simplified.assign(sex = lambda x: x['sex'].str.lower())\n\n\nStandardize the variables - column by column\n\n\n#simplified = simplified.assign(culmen_length_std = lambda x: (x.culmen_length-x.culmen_length.mean())/x.culmen_length.std())\n\nor make a standardization function. (note use of **)\n\ndef standardize(x):\n    return (x-x.mean())/x.std()\nsimplified = simplified.assign(\n    **{i+'_std':(lambda x: standardize(x[i])) for i in simplified.columns[3:]}\n)\n\n\nMissing Values\n\n\nsimplified.isna().sum()\nsimplified = simplified.dropna(axis=0)\n\n\nGrouping\n\nGrouping combines with aggregation.\n\nnumerical_variables = ['culmen_length','culmen_depth','flipper_length','body_mass']\nby_sex_mean = simplified[['sex']+numerical_variables].groupby('sex').mean()\n\nAlternatively one can use .agg\n\nnumerical_variables = ['culmen_length','culmen_depth','flipper_length','body_mass']\nby_sex = simplified[['sex']+numerical_variables].groupby('sex').agg('mean')\n\nAnd then get multiple aggregations.\n\nby_sex = simplified[['sex']+numerical_variables].groupby('sex').agg(['count','mean','std'])\n\nTo access individual elements, use tuples as names.\n\nby_sex.loc[:,('culmen_depth','mean')]\n\nsex\nfemale    16.425455\nmale      17.891071\nName: (culmen_depth, mean), dtype: float64\n\n\nOne can also group on multiple factors.\n\nby_sex_and_species = (\n    simplified[[\"sex\", \"species\"] + numerical_variables]\n    .groupby([\"sex\", \"species\"])\n    .mean()\n)\nfemales_by_species = by_sex_and_species.loc[(\"female\",)]\nmales_by_species = by_sex_and_species.loc[(\"male\",)]\n\nYou can skip levels in the hierarchy using slice(None):\n\nby_sex_and_species.loc[(slice('female'),slice('adelie','chinstrap')),:]\n\n\n\n\n\n  \n    \n      \n      \n      culmen_length\n      culmen_depth\n      flipper_length\n      body_mass\n    \n    \n      sex\n      species\n      \n      \n      \n      \n    \n  \n  \n    \n      female\n      adelie\n      37.257534\n      17.621918\n      187.794521\n      3368.835616\n    \n    \n      chinstrap\n      46.573529\n      17.588235\n      191.735294\n      3527.205882\n    \n  \n\n\n\n\n\nPivot tables\n\n\nexpanded = by_sex_and_species.reset_index()\nexpanded.pivot(index='sex',columns='species',values='culmen_length')\n\n\n\n\n\n  \n    \n      species\n      adelie\n      chinstrap\n      gentoo\n    \n    \n      sex\n      \n      \n      \n    \n  \n  \n    \n      female\n      37.257534\n      46.573529\n      45.563793\n    \n    \n      male\n      40.390411\n      51.094118\n      49.473770\n    \n  \n\n\n\n\n\npd.pivot_table(simplified,values='culmen_length',index='sex',columns='species',aggfunc='mean')\n\n\n\n\n\n  \n    \n      species\n      adelie\n      chinstrap\n      gentoo\n    \n    \n      sex\n      \n      \n      \n    \n  \n  \n    \n      female\n      37.257534\n      46.573529\n      45.563793\n    \n    \n      male\n      40.390411\n      51.094118\n      49.473770\n    \n  \n\n\n\n\n\nMaking a function\n\n\ndef ptable(value, aggfunc=\"mean\"):\n    return pd.pivot_table(\n        simplified, values=value, index=\"sex\", columns=\"species\", aggfunc=aggfunc\n    )\n\n\nptable(\"body_mass\", \"std\")\n\n\n\n\n\n  \n    \n      species\n      adelie\n      chinstrap\n      gentoo\n    \n    \n      sex\n      \n      \n      \n    \n  \n  \n    \n      female\n      269.380102\n      285.333912\n      281.578294\n    \n    \n      male\n      346.811553\n      362.137550\n      313.158596"
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html",
    "href": "chapters/09-Regexps/RegexProblems.html",
    "title": "Exercises with Regexps",
    "section": "",
    "text": "The following exercises were taken from Chapter 15 of R for Data Science by Wickham, et. al. See the online version."
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#first-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#first-batch",
    "title": "Exercises with Regexps",
    "section": "First Batch",
    "text": "First Batch\nYou can use either R or Python to approach these problems. The file words.txt contains about 1000 common English words. You can read that file into Python or, in R, use the variable stringr::words to get them.\n\nFind all the words that start with “y”.\nFind all the words that end with “x”.\nFind all the words that are exactly 3 letters long.\nContain a vowel followed by a consonant.\nContain at least two vowel-consonant pairs in a row."
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#second-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#second-batch",
    "title": "Exercises with Regexps",
    "section": "Second Batch",
    "text": "Second Batch\nUse the filenames.txt file. We saw how to extract the netid and the file extension from these files. Now extract the date/time info.\nSuppose the we want to obscure the netids by making up “fake” netids and substituting those into the filenames. How do you do that?"
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#third-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#third-batch",
    "title": "Exercises with Regexps",
    "section": "Third batch",
    "text": "Third batch\nUse the pandas pd.read_csv function or the tidyverse read_csv function to load the data/aircrashesFullData.csv dataset. Then use one of the file I/O functions from R or python to load the file. Compare the results. For example, how many rows does the dataframe have? How many lines did you read? Why the difference?"
  },
  {
    "objectID": "chapters/09-Regexps/Rfiles.html",
    "href": "chapters/09-Regexps/Rfiles.html",
    "title": "Reading from and Writing to Files in R",
    "section": "",
    "text": "The R/tidyverse library readr is the main tool for reading various types of data files.\n\nlibrary(readr)\n\n\nfile <- read_file(\"data/gettysburg.txt\")\n\n\nline <- read_lines(\"data/gettysburg.txt\", n_max = 1)\n\n\nlines <- read_lines(\"data/gettysburg.txt\")\n\n\ntext <- c(\"Now is the time\", \"for us to rise up\", \"against our robot overlords\")\nwrite_lines(text, \"data/robots.txt\", sep = \"-\")\n\n\n# write_file overwrites.  Use the append flag to append\nwrite_file(paste0(text, collapse = \" \")[1], \"data/robots.txt\", append = TRUE)\n\n\nFile operations\nThe fs library allows you to do file manipulations.\n\nlibrary(fs)\n# file_create\n# file_move\n# file_copy\n# file_ls to list directory\n# file_exists\n# file_show"
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html",
    "href": "chapters/09-Regexps/pythonFiles.html",
    "title": "Reading and Writing to Files in Python",
    "section": "",
    "text": "We have already seen how to use the read_csv commands (in R and python/pandas) to read data from files into dataframes/tibbles. But sometimes we need to work directly with text files."
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#the-basics",
    "href": "chapters/09-Regexps/pythonFiles.html#the-basics",
    "title": "Reading and Writing to Files in Python",
    "section": "The basics",
    "text": "The basics\n\n#with open(\"path\",\"r\") as f:\n#    (put logic to read file here)\n\nThis structure guarantees that the file will be properly closed when you’re done.\n\nSlurp up the whole file into a string.\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    data = f.read()\nlen(data)\n\n1477\n\n\n\nlines = data.split('\\n')\nfor x in lines[:10]:\n    print(x)\n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\nNow we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n\nBut, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\n\n\n\n\n\nRead the file line by line\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    for line in f:\n        print(line) \n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\n\n\nNow we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n\n\n\nBut, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\n\n\n\n\n\nRead a line from the file\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    line = f.readline()\n    print(line)\n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\n\n\n\n\nSlurp the file into a list\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    line_list = f.readlines()\n\nlowercase = [x.lower() for x in line_list]\nlowercase\n\n[' four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.\\n',\n '\\n',\n 'now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. we are met on a great battle-field of that war. we have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. it is altogether fitting and proper that we should do this.\\n',\n '\\n',\n 'but, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. the brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. the world will little note, nor long remember what we say here, but it can never forget what they did here. it is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. it is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under god, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\\n']"
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#writing-to-a-file",
    "href": "chapters/09-Regexps/pythonFiles.html#writing-to-a-file",
    "title": "Reading and Writing to Files in Python",
    "section": "Writing to a file",
    "text": "Writing to a file\nAn entire string to the file. This will overwrite what is in the file.\n\nwith open(\"data/gettysburg_lower.txt\",\"w\") as f:\n    f.write('\\n'.join(lowercase))\n\nOne line at a time. This will overwrite what is in the file.\n\nwith open(\"data/gettysburg_lower.txt\",\"w\") as f:\n    for x in lowercase:\n        f.write(x+\"\\n\")"
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#appending-to-a-file",
    "href": "chapters/09-Regexps/pythonFiles.html#appending-to-a-file",
    "title": "Reading and Writing to Files in Python",
    "section": "Appending to a file",
    "text": "Appending to a file\n\nwith open(\"data/gettysburg_lower.txt\",\"a\") as f:\n    f.write(\"This goes at the end\\n\")"
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#working-with-directories-folders",
    "href": "chapters/09-Regexps/pythonFiles.html#working-with-directories-folders",
    "title": "Reading and Writing to Files in Python",
    "section": "Working with directories (folders)",
    "text": "Working with directories (folders)\n\nimport os\nimport shutil\n#os.getcwd()\n#os.chdir('/home/jet08013')\n#os.getcwd()\n#files = os.listdir('.')\n#os.rename()\n#shutil.copy()"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html",
    "href": "chapters/09-Regexps/regexpsPython.html",
    "title": "Python regexps",
    "section": "",
    "text": "# Regular Expressions\nimport re\nimport pandas as pd"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#guide-works-in-both-python-and-r",
    "href": "chapters/09-Regexps/regexpsPython.html#guide-works-in-both-python-and-r",
    "title": "Python regexps",
    "section": "Guide (works in both python and R)",
    "text": "Guide (works in both python and R)\n\nLetters, Numbers match themselves\n‘.’ matches one of anything\n‘+’ means one or more of the preceeding\n’*’ means 0 or more of the preceding\n‘?’ matches 0 or 1 occurrences of the previous pattern.\n[] groups things ([A-Z]+ matches a sequence of one or more capital letters); [^...] matches anything not in the range.\n‘\\w’ matches “word” characters (`[a-zA-Z0-9_]’)\n‘\\W’ matches non-word characters\n‘\\b’ matches boundaries (end or start of string)\n‘{5}’’ matches 5 times\n‘{3,5}’ matches 3, 4 or 5 occurrences.\n‘{3,}’ matches 3 or more occurrences\n‘\\s’ matches whitespace\n‘\\S’ matches non-whitespace\n‘^….’ matches at the start of a line\n‘…$’ matches at the end of a line\n‘(a|b)’ matches a or b.\nUse backslash to escape."
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#key-functions",
    "href": "chapters/09-Regexps/regexpsPython.html#key-functions",
    "title": "Python regexps",
    "section": "Key functions",
    "text": "Key functions\n\nmatch finds matches at the start of the string; returns None if it doesn’t find one, otherwise returns match object.\nsearch finds matches; returns None if it doesn’t find one, otherwise returns first match object\nfindall returns a list of all matches (not match objects)\nfinditer iterates over matches"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#match-objects",
    "href": "chapters/09-Regexps/regexpsPython.html#match-objects",
    "title": "Python regexps",
    "section": "Match objects",
    "text": "Match objects\n\nif m is a match object, then\n\nm[0] is the match\nm[2], m[3] and so on are the subgroup matches\nm.span(n) is (start, stop) for match n.\nm.start(n) and m.end(n) are the start and end of match n.\nm.string is the string being matched against"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#looking-for-explicit-strings",
    "href": "chapters/09-Regexps/regexpsPython.html#looking-for-explicit-strings",
    "title": "Python regexps",
    "section": "Looking for explicit strings",
    "text": "Looking for explicit strings\n\nif re.search(r\"travel\", text):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n\nif re.match(r\"travel\", text):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n\nYes\nNo"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#some-fancier-examples",
    "href": "chapters/09-Regexps/regexpsPython.html#some-fancier-examples",
    "title": "Python regexps",
    "section": "Some fancier examples",
    "text": "Some fancier examples\n\n# All the words\nall_words = re.findall(r\"\\b[a-zA-Z]+\\b\", text)\nall_words[0:5]\n\n['Long', 'ago', 'I', 'travelled', 'to']\n\n\n\n# words (allowing numbers and underline) but lower case\nre.findall(r\"\\b\\w+\\b\", text.lower())[0:5]\n\n['long', 'ago', 'i', 'travelled', 'to']\n\n\n\n# numbers\nre.findall(r\"\\b\\d+\\b\", text)\n\n['1865']\n\n\n\nregular = re.search(r'[A-Z][a-z]+',text)\nshort = re.search(r'[A-Z][a-z]?',text)\n\n\n#Compare these\nplus = re.findall(r'[A-Z][a-z ]+',text)\nplusq = re.findall(r'[A-Z][a-z ]+?',text)\n\n\n# Finding capitalized words\nre.findall(r\"\\b[A-Z][a-z]*\\b\", text)\n\n['Long', 'I', 'I', 'At', 'I', 'Joy', 'Anonymous']\n\n\n\n# Problem: Find all sentences (Start with capital letter, end with period. Remember to use `\\.`"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#an-example",
    "href": "chapters/09-Regexps/regexpsPython.html#an-example",
    "title": "Python regexps",
    "section": "An example",
    "text": "An example\n\nwith open(\"data/filenames.txt\",\"r\") as f:\n    filenames = f.readlines()\nprint(filenames[0])\nfilenames = [x.strip() for x in filenames] #get rid of the newlines\n\nHW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-28_Homework2-R.qmd\n\n\n\n\n# Using alternation to select qmd or Rmd files\nselected = [x for x in filenames if re.match(r\".*\\.(qmd|Rmd)\",x)]\nrejected = [x for x in filenames if not re.match(r\".*\\.(qmd|Rmd)\",x)]\n\n\n# Using grouping to extract netid\nmatches = [re.search(r\"_([a-z]{3}[0-9]{5})_\",x) for x in selected]\n[x[1] for x in matches][0:5]\n\n['aft85126', 'pez35105', 'min29847', 'imk48906', 'uwc08078']\n\n\n\nfilenames = pd.read_csv(\"data/filenames.txt\",names=[\"Name\"])\n\n\nfilenames['Name'].map(lambda x: re.search(r\"_([a-z]{3}[0-9]{5})_\",x)[1])\nfilenames = filenames.assign(netid = filenames['Name'].map(lambda x: re.search(r\"_([a-z]{3}[0-9]{5})_\",x)[1])\n )\nfilenames = filenames.assign(extension = filenames['Name'].map(lambda x: re.search(r\".*\\.(qmd|Rmd|pdf)$\",x)[1]))\n\nAdding (?P<name>...) names the submatch. You can then extract or refer to the submatch by name.\n\nm = re.search(r\"(?P<found>[a-z]{3})\",\"abcdefghij\")\nprint(m[0],m.group(1),m.group('found'))\n\nabc abc abc\n\n\nThe .str.extract method is a powerful way to pick apart a string into columns in a pandas dataframe. It combines the operations above into a single operation. Combining it with named submatches gives names to the new columns.\n\nfilenames = pd.read_csv(\"data/filenames.txt\",names=[\"Name\"])\nfilenames=filenames['Name'].str.extract(r\"(?P<name>.*_(?P<netid>[a-z]{3}[0-9]{5})_.*\\.(?P<extension>qmd|Rmd|pdf))$\")\n\nThere are many other useful operations available with the pandas str library.\n\nstr.split\nstr.replace\nstr.cat (joins strings together with argument sep=)"
  },
  {
    "objectID": "chapters/09-Regexps/regexpsR.html",
    "href": "chapters/09-Regexps/regexpsR.html",
    "title": "Regexps in R",
    "section": "",
    "text": "The language is the same, but the wrapper functions are different.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"Hel\")\n\n[1] │ <Hel>p\n[3] │ <Hel>lo\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"He.*l\")\n\n[1] │ <Hel>p\n[3] │ <Hell>o\n\n\n\nstr_view(c(\"Now is the time for us to rise up\"), \"[A-Za-z]+[a-z]?\")\n\n[1] │ <Now> <is> <the> <time> <for> <us> <to> <rise> <up>\n\n\n\nstr_detect(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] TRUE TRUE\n\nstr_view(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] │ <Now> <is> <the>\n[2] │ <time> <to> <rise> <up>\n\n\n\nstr_count(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] 3 4\n\n\n\ngettysburg <- read_lines(\"data/gettysburg.txt\")\nstr_extract(gettysburg, \"\\\\b(\\\\w+)\\\\b\")\n\n[1] \"Four\" NA     \"Now\"  NA     \"But\" \n\n\n\n# str_match_all is inconvenient -- output is a list\nwords <- str_match_all(gettysburg[1], \"\\\\b\\\\w+\\\\b\")\n\n\nfilenames <- read_lines(\"data/filenames.txt\")\nmatches <- str_match_all(filenames, \".*_([a-z]{3}[0-9]{5})_.*\\\\.(qmd|Rmd|pdf)\")\n\n\n# separate_wider_regex works with tibbles\n# note also separate_wider_delim\n\nfilenames <- read_lines(\"data/filenames.txt\")\nfilenames <- tibble(names = filenames)\nfilenames <- filenames |> separate_wider_regex(names, patterns = c(\n    \".*_\",\n    netid = \"[a-z]{3}[0-9]{5}\",\n    \"_.*\\\\.\",\n    extension = \"qmd|Rmd|pdf\"\n), cols_remove = FALSE)\n# matches have to fill the line\n# use too_few = \"debug\" to get extra info if this fails (omit pdf from extension for example)\nfilenames |> mutate(new_name = str_c(netid, \".\", extension))\n\n# A tibble: 40 × 4\n   netid    extension names                                             new_name\n   <chr>    <chr>     <chr>                                             <chr>   \n 1 aft85126 qmd       HW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-… aft8512…\n 2 pez35105 qmd       HW2 - R - QMD_pez35105_attempt_2023-09-23-23-21-… pez3510…\n 3 qty84085 pdf       HW2 - R - QMD_qty84085_attempt_2023-09-23-23-21-… qty8408…\n 4 min29847 qmd       HW2 - R - QMD_min29847_attempt_2023-09-24-00-57-… min2984…\n 5 imk48906 qmd       HW2 - R - QMD_imk48906_attempt_2023-09-24-13-30-… imk4890…\n 6 uwc08078 qmd       HW2 - R - QMD_uwc08078_attempt_2023-09-24-00-03-… uwc0807…\n 7 kld62064 Rmd       HW2 - R - QMD_kld62064_attempt_2023-09-24-18-53-… kld6206…\n 8 mnr42924 qmd       HW2 - R - QMD_mnr42924_attempt_2023-09-24-22-44-… mnr4292…\n 9 kzs45796 qmd       HW2 - R - QMD_kzs45796_attempt_2023-09-12-11-29-… kzs4579…\n10 vhy10473 qmd       HW2 - R - QMD_vhy10473_attempt_2023-09-24-22-34-… vhy1047…\n# ℹ 30 more rows"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html",
    "href": "chapters/10-Shell/UnixCommandLine.html",
    "title": "The UNIX command line",
    "section": "",
    "text": "Access to remote servers is generally purely CLI\nProcess automation often relies on CLI\nCLI is a quick and efficient way to work with files and directories"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#unix",
    "href": "chapters/10-Shell/UnixCommandLine.html#unix",
    "title": "The UNIX command line",
    "section": "UNIX",
    "text": "UNIX\nUNIX is a generic term for a family of operating systems dating back to the 1960’s. Many systems today are in the UNIX family. The most notable examples are\n\nLinux (actually a whole family of Linux OS’s) – derived from an open source system created by Linus Torvalds\nMacOS\n\nIn addition, Microsoft now supports a system called WSL (Windows subsystem for Linux) that allows you to work with Linux on a windows machine."
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-gnu-project",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-gnu-project",
    "title": "The UNIX command line",
    "section": "The GNU project",
    "text": "The GNU project\nThe GNU project is a collection of open source tools written (primarily) for the UNIX ecosystem. The GNU project includes shells (bash), compilers (gcc), text editors (emacs), and many other resources. Most Linux systems are closely integrated with GNU tools."
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-unix-shell",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-unix-shell",
    "title": "The UNIX command line",
    "section": "The UNIX shell",
    "text": "The UNIX shell\nThe shell is a program that provides access to a range of tools for working with files and directoriees, and which can launch other programs that can do pretty much anything.\nOne can write programs for the shell to execute (these are called shell scripts) or one can use the shell interactively.\nThere are many shells available but the three you are most likely to encounter are:\n\nthe bourne shell (sh). This is the simplest shell program and mostly occurs in shell scripts. It is the “lowest common denominator” of UNIX shells.\nbash is the standard shell that is associated with the GNU toolkit\nzsh has become a popular shell because of its flexibility and its many customization options.\n\nOn Windows, the gitbash package provides a bash shell that runs in the Windows environment.\nMost interactive commands are the same regardless of which shell you use, but the programming languages for each shell are similar but definitely not the same."
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#which-shell-am-i-running",
    "href": "chapters/10-Shell/UnixCommandLine.html#which-shell-am-i-running",
    "title": "The UNIX command line",
    "section": "Which shell am I running?",
    "text": "Which shell am I running?\nWhen you launch a terminal window on Linux or MacOS, the system starts a shell program in that window and you interact with that shell. On MacOS, the default shell is zsh. On most Linux installations, it is bash.\nTo see what’s happening on your computer, run the following command in a terminal window. Here, and later, the initial ‘$’ stands for the prompt you receive from the shell. Yours may be fancier. We’ll see later how to customize it.\n\n$ echo $0\n\n(Note: for a whole range of technical reasons this isn’t 100% guaranteed to work but it is almost certainly correct!)"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#navigation",
    "href": "chapters/10-Shell/UnixCommandLine.html#navigation",
    "title": "The UNIX command line",
    "section": "Navigation",
    "text": "Navigation\nYour shell process always has a notion of “current directory.” This is the folder/directory that will be accessed by default when you run commands.\nWhen you start a shell, the current directory is your home directory.\nFiles and directories are referred to by paths that (in UNIX derived OS’s) always use the ‘/’ character.\nThree important conventions\n\nThe current working directory is abbreviated as ‘.’\nThe parent of the current working directory is abbreviated as ‘..’\nYour home directory is abbreviated as ‘~’.\n\n\nKey Navigation Commands\nThe key commands for navigation through the file system are:\n\npwd prints the current working directory\nls lists the files in the current directory\ncd changes the working directory\nmkdir creates a new directory\nrmdir deletes a directory, assuming it is empty.\n\nNote: The ‘#’ symbol means to treat everything following as a comment, not to be executed.\n\n$ pwd\n/home/jeremy9959\n\n\n$ ls\ndata/  model.py  notes/\n\n\n$ cd data # change working directory to data\n$ pwd # check our working directory\n/home/jeremy9959/data\n$ ls # list files\ntest.csv  training.csv\n$ cd .. # change to parent directory\n$ pwd # confirm our location\n/home/jeremy9959\n\n\n\nOptions\nUnix commands typically take (many) options. The general structure of these options are either - followed by a letter, or --word. Sometimes you specify the option as --word=value.\n\n$ (command) -a -b -c --name --option=whatever\n\nYou can usually run commands together like this:\n\n$ (command) -abc\n\nThe ls command has many options and variations. These vary from system to system.\n\n$ ls --help  # sometimes this works, but not always\n$ man ls # this opens a manual page for the ls command which may tell you more than you want to know\n\nSome important special cases that (almost always) work.\n\n$ ls -l # long form listing\ndrwxrwxr-x - jet08013 11 Oct 09:21 data  # permissions/size/owner/group/modification date\n.rw-rw-r-- 0 jet08013 11 Oct 09:20 model.py\ndrwxrwxr-x - jet08013 11 Oct 09:21 notes\n\n\n$ ls -a # show  \"hidden files\" (names start with .)\n.settings  data  model.py  notes\n\n\n$ ls -F # \ndata/ model.py notes/\n\n\n$ ls data  # lists the contents of the directory\ntest.csv training.csv\n$ ls -F -d data  # list the directory name\ndata/\n\nYou can also use wildcards.\n\n$ ls *.py\nmodel.py\n$ ls -Fd d* # what happens if you just do ls -F?\ndata/\n\n\n\nMaking and removing directories\nYou can always create a directory, but the system won’t let you remote directories that aren’t empty.\n\n$ ls \ndata  model.py  notes\n$ mkdir report\n$ ls -F\ndata/  model.py  notes/  report/\n$ cd report\n$ pwd\n/home/jeremy9959/report\n$ ls \n(nothing)\n$ cd ..\n$ pwd\n/home/jeremy9959\n$ rmdir report\n$ ls -F\ndata/ model.py notes/\n$ rmdir data\nrmdir: failed to remote `data`: Directory not empty\n$ ls data\ntest.csv  training.csv\n\n\n\nWorking with files\nKey commands for working with files.\n\nnano is a tiny text editor that works from the command line and is very easy to use. Other options are vi and emacs. vscode has options allowing you to work remotely as well.\ncp copy a file\nmv rename/move a file or directory\ncat type a file onto the terminal (or more generally combine files)\nmore and less list files page by page\nhead and tail look at first and last lines of a file\nrm remove/delete a file.\n\n\n$ cd data\n$ cp test.csv test_2.csv # make a new copy called test_2.csv\n$ ls\ntest.csv test_2.csv training.csv\n$ mv test_2.csv new_test.csv # rename test_2.csv to new_test.csv\n$ ls\nnew_test.csv test.csv training.csv\n$ cat test.csv\n(... bunch of stuff)\n$ head test.csv\n(first ten lines)\n$ tail test.csv\n(last ten lines)\n$ head -5 test.csv # first 5 lines\n(first 5 lines)\n$ tail -5 test.csv # last 5 lines\n(last 5 lines)\n$ tail  +2 test.csv # start with line 2 and go to the end\n(lots of lines)\n$ ls \nnew_test.csv test.csv training.csv\n$ rm new_test.csv\nrm: remove regular file 'new_test.csv'? y # you may not see this\n$ ls\ntest.csv training.csv\n\n\n\nNotes and variations\n\nYou can copy a bunch of files to a directory if the target of the copy is a directory. You can use wildcards if you want.\n\n\n$ cp file1 file2 file3 ... filen directory \n$ cp *.csv directory # copy all .csv files into the specified directory\n\n\nThe mv command will work on directories to rename them.\n\n\n$ ls -F\ndata/ model.py notes/\n$ mv data old_data\n$ ls -F\nmodel.py old_data/ notes/\n\n\nThe cp command doesn’t work on directories unless you use the -r or --recursive flag, in which case it copies the entire directory tree.\nYou should assume that these operations are irrevocable and destructive. There is no trash can in UNIX So for example if you rename file1 ontop of another file2 , you delete the existing file2. You can prevent this (and get warnings) with the -i flag.\n\n\n$ rm -i model.py\nrm: remove regular file `model.py`? n # cancel the operation\n$  cp model.py model2.py \n$  mv model.py model2.py # this will overwrite model2.py \n$  ls -failed\ndata/ model2.py notes/\n\n\nThe -f flag means “force” and will override any warnings. So cp -f will do a copy over an existing file without a warning. In particular, rm -f will remove a directory and its contents even if the directory is nonempty. Use with extreme caution!\nThe shell wildcards are * (which matches anything) and ? which matches one character.\nThe ls -R command lists the contents of all subdirectories as well as the directory itself. The tree command (which isn’t always available) gives you a nicer picture.\n\n\n$ tree \n.\n├── data\n│   ├── test.csv\n│   └── training.csv\n├── model.py\n└── notes\n    ├── algorithm_notes.txt\n    └── to_do.txt\n\n\n\nExercise\nYou receive the following note from your boss together with this attachment.\n\nHi, one of our analysts just quit and he sent me the attached zip file of his work so far\non one of our projects.  Can you get it organized?\n\nUnzip the attachment. Using the command line, organize the data into appropriate directories and standardize the file names in a reasonable way.\nA few notes:\nTo unzip the attachment on the command line, use the unzip command.\n\n$ unzip joe.zip\n\nTo create a zip file you use the zip command. The -r option means to descend into directories as well.\n\n$ zip -r zipfile.zip ...files and directories to zip...\n\nTo run a python program from the command line, use the python command:\n\n$ python program.py \n...program runs"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#redirection-pipes-and-filters",
    "href": "chapters/10-Shell/UnixCommandLine.html#redirection-pipes-and-filters",
    "title": "The UNIX command line",
    "section": "Redirection, Pipes, and Filters",
    "text": "Redirection, Pipes, and Filters\n\nStandard input and standard output\nWhen a UNIX command runs, it typically has three I/O pathways associated to it:\n\nan input stream called the standard input.\nan output stream called the standard output.\nan output stream called the standard error output.\n\nPrograms which read from standard input and write to standard output are called filters.\nSome key commands for this section:\n\ncat combines the files given as arguments and outputs them to standard output chained together. Without any files, reads from standard input and outputs to standard output.\nwc counts words, characters, and lines from the file on the command line, or from standard input, and outputs to standard output. wc -c, wc -l, and wc -w give the individual numbers.\ncut extracts a field from the file on the command line (or from standard input) and outputs to standard output.\necho sends its command line to standard output.\nsort sorts files or standard input, outputs to standard output.\ngrep looks for matching patterns in files or standard input, outputs matching lines to standard output.\nuniq finds unique lines in a sorted file or standard input.\n\n\n\nRedirection\nOne of the most powerful features of the shell is its ability to redirect standard input, standard output, and standard error to other files, and thereby construct pipelines.\n\nRedirection of output\n\n$ ls > files.txt # the > sign sends standard output to the given file.\n$ cat files.txt # cat types the file to standard output\ndata\nfiles.txt\nmodel2.py \nnotes\n$ ls -F # notice that files.txt has been created\ndata/ files.txt model2.py notes/\n\nOrdinarily, redirecting output using > overwrites the target. But if you use >> you can append to the end of a file.\n\n\nPipes\nA pipe between commands is written with |. A pipe means the output from the first command should be sent as input to the second command.\nFirst, let’s look at the wc command.\n\n$ wc files.txt\n4 4 31 files.txt # lines words characters in files.txt\n$ wc -l files.txt # just the lines please\n4\n\nNow we put wc into a pipeline with ls to count the number of files in our directory.\n\n$ ls | wc -l  # the output of ls (one file per line) goes to wc -l which counts lines \n4\n\nHere we combine the training and test files and count the number of characters.\n\n$ ls data/*\ntest.csv training.csv\n$ cat data/* | wc -l \n151\n\n\n\n\nThe standard input\nCommands like wc and cat either use files specified as arguments or, if there aren’t any, they read from standard input.\n\n$ wc \nHere, wc is reading this stuff (which comes from the terminal, i.e. standard input)\nand is counting words, lines and so on.\nI use CTRL-D to send an end of file to tell wc that I'm done.\n^D \n3 37 86\n\nYou can redirect standard input using <.\n\n$ wc < files.txt\n4 4 31\n\nThe output is the line/word/character counts, but there’s no file name because the data comes from standard input via the ‘<’ operator.\nCheck-in: Explain what these commands do and why.\n\n$ echo \"Hello There\"\n$ echo \"Hello There\" > hello.txt\n$ echo \"Hello There\" | wc \n\nTwo useful commands are sort and cut.\nThe cut command extracts fields from a delimited file. You can specify the field separator and the fields you want. The default delimiter for cut is the TAB character.\nWARNING: cut (and sort) are not sophisticated about quoted fields that contain commas, unlike, say, pandas or the tidyverse. So you may not always get what you are expecting if you have quoted fields that contain commas.\n\n$ cut -f4 -d, data/training.csv | head\nRegion\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\n$ cut -f1-4 -d, data/test.csv | tail -3\nPAL0910,66,Chinstrap penguin (Pygoscelis antarctica),Anvers\nPAL0910,67,Chinstrap penguin (Pygoscelis antarctica),Anvers\nPAL0910,68,Chinstrap penguin (Pygoscelis antarctica),Anvers\n$ ls -l  | cut  -f1 -d' ' # here we use space as a delimiter.\n$ cut -c1-10 data/training.csv | head -2 # first 10 characters.\nstudyName,\nPAL0708,1,\n\nThe sort command sorts (not surprisingly). You can specify the file on the command line or use sort as a filter. Ordinarily it sorts on the entire line.\n\n$ sort data/titanic_train.csv > data/titanic_train_sorted.csv\n$ ls data\ntest.csv  titanic_test.csv  titanic_train.csv  titanic_train_sorted.csv  training.csv\n$ head -3 data/titanic_train_sorted.csv\n100,0,2,\"Kantor, Mr. Sinai\",male,34,1,0,244367,26,,S\n101,0,3,\"Petranec, Miss. Matilda\",female,28,0,0,349245,7.8958,,S\n10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C\n\nYou can specify fields (sort key) with -f, numerical sort with -n, reverse with -r, case folding with -f, and a field separator with -t. The quoted names throw things off here!\n\n$ sort -k4 -t, data/titanic_train.csv | head -3 # field four, sep=,\n846,0,3,\"Abbing, Mr. Anthony\",male,42,0,0,C.A. 5547,7.55,,S\n747,0,3,\"Abbott, Mr. Rossmore Edward\",male,16,1,1,C.A. 2673,20.25,,S\n280,1,3,\"Abbott, Mrs. Stanton (Rosa Hunt)\",female,35,1,1,C.A. 2673,20.25,,S\n$ sort -k4 -r -t, data/titanic_train.csv | head -2\n423,0,3,\"Zimmerman, Mr. Leo\",male,29,0,0,315082,7.875,,S\n241,0,3,\"Zabour, Miss. Thamine\",female,,1,0,2665,14.4542,,C\n\nSorting is normally done “alphabetically” in which case the order might not be what you expect for numbers. The -n flag forces numeric values to be used.\n\n$ sort  data/titanic_train.csv | cut -f1 -d, | head -5 # alphabetical\n100\n101\n10\n102\n103\n$ sort -n data/titanic_train.csv | cut -f1 -d, | head -5 # numerical\nPassengerId\n1\n2\n3\n4\n\n\nSearching\nThe grep command searches for matches in its input and outputs any that it finds. There are several variants of grep and there are many, many options to the command.\nThe basics:\n\n$ grep 'William' data/titanic_train.csv | head -5  \n5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S\n13,0,3,\"Saundercock, Mr. William Henry\",male,20,0,0,A/5. 2151,8.05,,S\n18,1,2,\"Williams, Mr. Charles Eugene\",male,,0,0,244373,13,,S\n24,1,1,\"Sloper, Mr. William Thompson\",male,28,0,0,113788,35.5,A6,S\n32,1,1,\"Spencer, Mrs. William Augustus (Marie Eugenie)\",female,,1,0,PC 17569,146.5208,B78,C\n$ grep '^8' data/titanic_train.csv | head -5\n8,0,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S\n80,1,3,\"Dowdell, Miss. Elizabeth\",female,30,0,0,364516,12.475,,S\n81,0,3,\"Waelens, Mr. Achille\",male,22,0,0,345767,9,,S\n82,1,3,\"Sheerlinck, Mr. Jan Baptist\",male,29,0,0,345779,9.5,,S\n83,1,3,\"McDermott, Miss. Brigdet Delia\",female,,0,0,330932,7.7875,,Q\n$ grep '\\bWilliam\\b' data/titanic_train.csv | tail -5\n803,1,1,\"Carter, Master. William Thornton II\",male,11,1,2,113760,120,B96 B98,S\n811,0,3,\"Alexander, Mr. William\",male,26,0,0,3474,7.8875,,S\n865,0,2,\"Gill, Mr. John William\",male,24,0,0,233866,13,,S\n881,1,2,\"Shelley, Mrs. William (Imanita Parrish Hall)\",female,25,0,1,230433,26,,S\n886,0,3,\"Rice, Mrs. William (Margaret Norton)\",female,39,0,5,382652,29.125,,Q\n$ grep '\\bWilliam\\b' data/titanic_train.csv | wc -l\n\nYou can do a lot of useful stuff by combining grep with other tools.\n\n$ grep female data/titanic_train.csv > data/females_train.csv\n$ head data/females_train.csv\n2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n9,1,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S\n10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C\n\nUNIX tools aren’t as powerful as the csv tools in, for example, pandas, but you can still be clever. Suppose we want to get at the names in the titanic file. They have embedded commas but are set off with quotations\n\n$ cut -f2 -d\\\" data/titanic_train.csv\nPassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\nBraund, Mr. Owen Harris\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nHeikkinen, Miss. Laina\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | head -2\nSurvived\nmale\nfemale\n\nThe uniq command can be used to see the different elements in the field.\n\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | sort | uniq \n\nfemale\nmale\nSurvived\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | sort | uniq -c\n 53 \n 282 female\n 556 male\n 1 Survived\n\n\n\n\nExercise\n\nUse UNIX tools to determine:\n\nhow many of each type of penguin there are in the penguins_training.csv and penguins_test.csv files.\nhow many males and females there are in each file.\n\nCombine the training and test files for the penguins into a single file (penguins.csv). Then make a file male_penguins.csv containing just the males."
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#variables-and-loops",
    "href": "chapters/10-Shell/UnixCommandLine.html#variables-and-loops",
    "title": "The UNIX command line",
    "section": "Variables and Loops",
    "text": "Variables and Loops\n\nVariables\nYou use names for variables (like x), but to refer to the value of a variable you use $x$.\n\n$ x=\"hello\" # no spaces!\n$ echo $x\nhello\n\nThe various UNIX shells are programming languages and they have the full set of capabilities: variables, logical statements, loops….\nThe syntax for loops is different for zsh and bash unfortunately.\n\n$ for x in *.csv # bash\n> do\n> echo $x\n> done\n\n\n$ for x in *.csv # zsh\ncmdor cursh cmdand cursh then else> echo $x\n\nYou can use loops to (for example) rename a bunch of files.\n\n$ mkdir bkup\n$ for x in *.csv \ncmdor cursh cmdand cursh then else> cp $x bkup/$x\n\n\n$ mkdir bkup\n$ for x in *.csv\n> do\n> cp $x bkup/$x\n> done"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#scripts",
    "href": "chapters/10-Shell/UnixCommandLine.html#scripts",
    "title": "The UNIX command line",
    "section": "Scripts",
    "text": "Scripts\nA shell script is a file containing a sequence of shell commands. When a shell starts, it executes a startup script stored in .zshrc or .bashrc. This is where you can put commands to customize your shell."
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-environment",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-environment",
    "title": "The UNIX command line",
    "section": "The environment",
    "text": "The environment\nEvery shell has an environment which is a bunch of variables that are used by programs. Elements of the environment are called environment variables. Sometimes you have to set an environment variable.\nSome common and important shell environment variables are:\n\n$ echo $HOME # home directory\n$ echo $PATH # search path for commands\n$ echo $USER # your user id\n$ echo $PS1 # the shell prompt\n$ env # print the entire environment"
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#other-topics",
    "href": "chapters/10-Shell/UnixCommandLine.html#other-topics",
    "title": "The UNIX command line",
    "section": "Other topics",
    "text": "Other topics\n\nUsing wget to get information from the web.\nUsing ssh to make a remote connection.\nUsing rsync to copy files across computers.\nUsing tar or gzip to compress and uncompress archives of files."
  },
  {
    "objectID": "chapters/11-Git/Git.html",
    "href": "chapters/11-Git/Git.html",
    "title": "Version Control and Git",
    "section": "",
    "text": "We will be following the Software Carpentries Lesson on Git.\nTo prepare for this lesson, you should have installed git for windows if you are on a Windows machine.\nOn MacOS, git is typically available by default, but if you want the most recent version you can download it using one of the package managers for Mac (like homebrew). See this web page.\nYou will also need an account on github.com. If you have not created one, do so now."
  },
  {
    "objectID": "chapters/12-SQL/sql.html",
    "href": "chapters/12-SQL/sql.html",
    "title": "A brief introduction to Databases and SQL",
    "section": "",
    "text": "In this unit we will do some very basic work with a cloud database. We will:\n\ngive a brief introduction to relational databases\nillustrate how one can download information from such a database into R tibbles or python dataframes\ndiscuss the join operation on the R/python level\ngive a brief introduction to SQL\nwrite some SQL queries\n\nThere are many types of relational databases. For these examples we will work specifically with MySQL version 8.0 on Amazon Web Services. Most of what we will do would carry over with minor changes to any of the major relational databases."
  },
  {
    "objectID": "chapters/12-SQL/sql.html#rdbs-in-very-brief",
    "href": "chapters/12-SQL/sql.html#rdbs-in-very-brief",
    "title": "A brief introduction to Databases and SQL",
    "section": "RDBs in (very brief)",
    "text": "RDBs in (very brief)\nA relational database is an efficient means of storing data in a way that allows one to carry out the same family of operations that we have used with tibbles and dataframes: selecting, filtering, grouping, summarizing, ordering, and synthesizing new data.\nDatabases are generally designed to operate at a much larger scale than the tabular data structures we’ve used in Python and R. Instead of storing data in a single big table, relational databases break up the data into many tables which may have many rows but generally have relatively few columns. A family of indexes link the different tables together.\nFor a very simple example, imagine we have a dataframe with 10000 people’s names and addresses. The city column in this dataframe probably contains many repetitions (lots of occurrences of say, New York City). In a database, one would typically replace the city name column with an index into another table that just contains a list of cities.\nFor another example, in the sakila database (which is a database of films and actors often used for demo purposes) there is a table called language that contains a number which is alanguage_id and a name which is 20 text characters. In the film table, there is a language_id field which points into the language table so one can find the name of the film’s language.\nThe most fundamental trick to working with relational databases is learning how to put the information together from the different tables in order to obtain the specific information you are interested in.\nThe relationship among all the tables is presented in what’s called an entity-relationship diagram.\n\n\n\nSakila Database ER Diagram (from the MySQL Documentation)\n\n\nIn this diagram, the box for film_actor shows that each row of the table is defined by the combination of an actor_id and a film_id. Notice that the film table has two language_id fields, one for the original language and one for the language of the particular version.\nThe database had its origins in an inventory tracking system for a video rental store (yes, it’s that old) and that’s where the inventory/rental tables come from."
  },
  {
    "objectID": "chapters/12-SQL/sql.html#setting-up",
    "href": "chapters/12-SQL/sql.html#setting-up",
    "title": "A brief introduction to Databases and SQL",
    "section": "Setting up",
    "text": "Setting up\nSetting up for this lesson could be complicated. We need the following tools.\nFor Python, we need:\n\nthe sqlalchemy python library.\n\nthe pymysql odbc connector package.\n\nThese can be installed via the GUI package manager provided as part of anaconda Navigator, or using the conda shell command. If you use conda, execute the following commands in a terminal window.\n\n$ conda install sqlalchemy\n$ conda install pymysql\n\nIn Anaconda Navigator, you will see the “Environments” tab on the left side of the start up screen. You can select “All” from the dropdown on the top right, and search for pymysql; click the checkbox to install it.\n\n\n\nInstalling via Anaconda Navigator\n\n\nTo verify that you have the packages properly installed, start a jupyter notebook and run the following commands.\n\nimport sqlalchemy as sqla\nimport pymysql\n\nIf these commands fail, or you don’t want to deal with installing this software, you can use a Google colab notebook opened through Google Drive. In the colab notebook, you should already have sqlalchemy available. You can use !pip to install pymysql. The code here should work:\n\nimport sqlalchemy as sqla\n!pip install pymysql\nimport pymysql\n\nFor R, we need:\n\nThe dbplyr package (which gives database functionality to dplyr)\nThe DBI package which handles communication\nThe RMariaDB package which gives the MySQL interface\n\nIn RStudio, you should be able to run the following commands.\n\ninstall.packages(\"dbplyr\")\ninstall.packages(\"DBI\")\ninstall.packages(\"RMariaDB\")\nlibrary(dbplyr)\nlibrary(DBI)\nlibrary(RMariaDB)"
  },
  {
    "objectID": "chapters/12-SQL/sql_python.html",
    "href": "chapters/12-SQL/sql_python.html",
    "title": "Databases and SQL - Selection - Python",
    "section": "",
    "text": "Our first task is to make a connection to our database using python and the sqlalchemy package.\n\nimport sqlalchemy as sqla\nimport pymysql\nimport pandas as pd\n\nprint(pd.__version__)\n\nusername = \"user\"  # get this from the instructor\npassword = \"grad5100user\"  # get this from the instructor\nawsresource = \"database-1.cwvjklnp4wu3.us-east-1.rds.amazonaws.com\"\nport = 3306\ndbname = \"sakila\"\ndburi = f\"mysql+pymysql://{username}:{password}@{awsresource}:{port}/{dbname}\"\nengine = sqla.create_engine(dburi)\n\n1.5.3\n\n\nWe are going to use the following little command to send SQL to the database and return the result.\n\ndef run_sql(sql, engine):\n    with engine.connect() as conn:\n        result = conn.execute(sqla.text(sql))\n    return result.all()\n\n\ndef df_select(sql, engine):\n    with engine.connect() as conn:\n        result = pd.read_sql(sqla.text(sql), con=conn)\n    print(f\"Retrieved {result.shape[0]} records\")\n    return result\n\nTo test the connection, let’s use the show command to list the tables in the sakila database.\n\ntables = run_sql(\"show tables;\", engine)\nfor x in tables:\n    print(x)\n\n('actor',)\n('actor_info',)\n('address',)\n('category',)\n('city',)\n('country',)\n('customer',)\n('customer_list',)\n('film',)\n('film_actor',)\n('film_category',)\n('film_list',)\n('film_text',)\n('inventory',)\n('language',)\n('nicer_but_slower_film_list',)\n('payment',)\n('rental',)\n('sales_by_film_category',)\n('sales_by_store',)\n('staff',)\n('staff_list',)\n('store',)\n\n\nNow let’s take a closer look at one of these tables using the describe command. The most important info we learn here are the names of the fields in the actor table, and their datatypes.\n\nactor_info = run_sql(\"describe actor;\", engine)\nfor x in actor_info[:10]:\n    print(x)\n\n('actor_id', 'smallint unsigned', 'NO', 'PRI', None, 'auto_increment')\n('first_name', 'varchar(45)', 'NO', '', None, '')\n('last_name', 'varchar(45)', 'NO', 'MUL', None, '')\n('last_update', 'timestamp', 'NO', '', 'CURRENT_TIMESTAMP', 'DEFAULT_GENERATED on update CURRENT_TIMESTAMP')"
  },
  {
    "objectID": "chapters/12-SQL/sql_python.html#select-and-select-where",
    "href": "chapters/12-SQL/sql_python.html#select-and-select-where",
    "title": "Databases and SQL - Selection - Python",
    "section": "Select and select where",
    "text": "Select and select where\nThe fundamental SQL command is select. The syntax for the select command is\nselect field, field, field from table;\nIn our case, let’s select some information from the actor table.\n\nactor_data = run_sql(\"select actor_id, first_name, last_name from actor;\", engine)\nfor x in actor_data[:10]:\n    print(x)  # result is a list of tuples\n\n(1, 'PENELOPE', 'GUINESS')\n(2, 'NICK', 'WAHLBERG')\n(3, 'ED', 'CHASE')\n(4, 'JENNIFER', 'DAVIS')\n(5, 'JOHNNY', 'LOLLOBRIGIDA')\n(6, 'BETTE', 'NICHOLSON')\n(7, 'GRACE', 'MOSTEL')\n(8, 'MATTHEW', 'JOHANSSON')\n(9, 'JOE', 'SWANK')\n(10, 'CHRISTIAN', 'GABLE')\n\n\nIt’s a lot more convenient to get this in the form of a pandas dataframe. One could convert it “by hand”, but pandas actually gives us a direct method for this. It needs a connection as an argument.\nThe function sqla.text turns an SQL string into the appropriate format for passing to the pandas function.\n\nwith engine.connect() as conn:\n    actor_df = pd.read_sql(\n        sqla.text(\"SELECT actor_id, first_name, last_name FROM actor;\"), conn\n    )\nactor_df.head()\n\n\n\n\n\n  \n    \n      \n      actor_id\n      first_name\n      last_name\n    \n  \n  \n    \n      0\n      1\n      PENELOPE\n      GUINESS\n    \n    \n      1\n      2\n      NICK\n      WAHLBERG\n    \n    \n      2\n      3\n      ED\n      CHASE\n    \n    \n      3\n      4\n      JENNIFER\n      DAVIS\n    \n    \n      4\n      5\n      JOHNNY\n      LOLLOBRIGIDA\n    \n  \n\n\n\n\nFor another example, let’s look at the film table.\n\nfilm_info = run_sql(\"describe film;\", engine)\nfor x in film_info:\n    print(x)\n\n('film_id', 'smallint unsigned', 'NO', 'PRI', None, 'auto_increment')\n('title', 'varchar(128)', 'NO', 'MUL', None, '')\n('description', 'text', 'YES', '', None, '')\n('release_year', 'year', 'YES', '', None, '')\n('language_id', 'tinyint unsigned', 'NO', 'MUL', None, '')\n('original_language_id', 'tinyint unsigned', 'YES', 'MUL', None, '')\n('rental_duration', 'tinyint unsigned', 'NO', '', '3', '')\n('rental_rate', 'decimal(4,2)', 'NO', '', '4.99', '')\n('length', 'smallint unsigned', 'YES', '', None, '')\n('replacement_cost', 'decimal(5,2)', 'NO', '', '19.99', '')\n('rating', \"enum('G','PG','PG-13','R','NC-17')\", 'YES', '', 'G', '')\n('special_features', \"set('Trailers','Commentaries','Deleted Scenes','Behind the Scenes')\", 'YES', '', None, '')\n('last_update', 'timestamp', 'NO', '', 'CURRENT_TIMESTAMP', 'DEFAULT_GENERATED on update CURRENT_TIMESTAMP')\n\n\nUsing what we already know, the simplest way to work with these tables is to move them into a pandas dataframe locally and work there. For example, suppose we want to look at the film ratings.\n\nwith engine.connect() as conn:\n    film_df = pd.read_sql(sqla.text(\"select film_id, title, rating from film;\"), conn)\nfilm_df[\"rating\"].value_counts()\n\nPG-13    223\nNC-17    210\nR        195\nPG       194\nG        178\nName: rating, dtype: int64\n\n\nAnd, of course, if we want to pick out the ‘G’-rated films:\n\nGFilms = film_df[film_df[\"rating\"] == \"G\"]\nGFilms.shape\n\n(178, 3)\n\n\nBut suppose there are a huge number of films, and we don’t want to download all of them just to throw away the ones that aren’t G-rated. Then we can use a where clause.\nIn this example we also use the film_id as the table index.\n\nwith engine.connect() as conn:\n    g_film_df = pd.read_sql(\n        sqla.text(\"select film_id, title, rating from film where rating='G'\"),\n        conn,\n        index_col=\"film_id\",\n    )\nprint(f\"retrieved {g_film_df.shape[0]} records\")\n\nretrieved 178 records\n\n\nWhat about films between 90 minutes and two hours? And what if we want the result sorted by length?\n\nwith engine.connect() as conn:\n    midlength_df = pd.read_sql(\n        sqla.text(\n            \"select film_id, title, length from film where length>=90 and length<=120 order by length;\"\n        ),\n        conn,\n        index_col=\"film_id\",\n    )\nprint(f\"retrieved {midlength_df.shape[0]} records\")\n\nretrieved 223 records\n\n\nFor simplicity we can use the df_select function.\n\nmidlength_df = df_select(\n    \"Select film_id, title, length from film where length>=90 and length<=120 order by length desc;\",\n    engine,\n)\n\nRetrieved 223 records\n\n\nSo to summarize, we have\nselect f1, f2, ... fn from table where condition order by field;\nselect f1, f2, ... fn from table where condition order by field desc;"
  },
  {
    "objectID": "chapters/12-SQL/sql_python.html#grouping-and-summarizing",
    "href": "chapters/12-SQL/sql_python.html#grouping-and-summarizing",
    "title": "Databases and SQL - Selection - Python",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\nThe grouping and summarizing operations in pandas are modeled on those from SQL. The group by clause in SQL does the grouping, and then one can apply summarizing functions to fields. For example, suppose we want to count the number of movies with each rating.\nWe say:\nselect count(rating) from film group by rating; \n\nrun_sql(\"select rating, count(rating) from film group by rating;\", engine)\n\n[('PG', 194), ('G', 178), ('NC-17', 210), ('PG-13', 223), ('R', 195)]\n\n\nWe have the usual summary functions (count, avg, min, max,…)\n\nrun_sql(\n    \"select rating, min(length), avg(length), stddev(length), max(length) from film group by rating;\",\n    engine,\n)\n\n[('PG', 46, Decimal('112.0052'), 39.15571575801518, 185),\n ('G', 47, Decimal('111.0506'), 41.65431205970793, 185),\n ('NC-17', 46, Decimal('113.2286'), 40.717904601072505, 184),\n ('PG-13', 46, Decimal('120.4439'), 41.074090844322875, 185),\n ('R', 49, Decimal('118.6615'), 38.40817631559128, 185)]\n\n\nYou can of course put this in a dataframe.\n\ndf_select(\n    \"select rating, min(length), avg(length), stddev(length), max(length) from film group by rating;\",\n    engine,\n)\n\nRetrieved 5 records\n\n\n\n\n\n\n  \n    \n      \n      rating\n      min(length)\n      avg(length)\n      stddev(length)\n      max(length)\n    \n  \n  \n    \n      0\n      PG\n      46\n      112.0052\n      39.155716\n      185\n    \n    \n      1\n      G\n      47\n      111.0506\n      41.654312\n      185\n    \n    \n      2\n      NC-17\n      46\n      113.2286\n      40.717905\n      184\n    \n    \n      3\n      PG-13\n      46\n      120.4439\n      41.074091\n      185\n    \n    \n      4\n      R\n      49\n      118.6615\n      38.408176\n      185\n    \n  \n\n\n\n\nYou can rename the columns inside the SQL query:\n\ndf_select(\n    \"select rating, min(length) as minlen, avg(length) as avlen, stddev(length) as stdlen, max(length) as maxlen from film group by rating;\",\n    engine,\n)\n\nRetrieved 5 records\n\n\n\n\n\n\n  \n    \n      \n      rating\n      minlen\n      avlen\n      stdlen\n      maxlen\n    \n  \n  \n    \n      0\n      PG\n      46\n      112.0052\n      39.155716\n      185\n    \n    \n      1\n      G\n      47\n      111.0506\n      41.654312\n      185\n    \n    \n      2\n      NC-17\n      46\n      113.2286\n      40.717905\n      184\n    \n    \n      3\n      PG-13\n      46\n      120.4439\n      41.074091\n      185\n    \n    \n      4\n      R\n      49\n      118.6615\n      38.408176\n      185\n    \n  \n\n\n\n\nAnd you can sort the result:\n\ndf_select(\n    \"select rating, min(length) as minlen, avg(length) as avlen, stddev(length) as stdlen, max(length) as maxlen from film group by rating order by avlen;\",\n    engine,\n)\n\nRetrieved 5 records\n\n\n\n\n\n\n  \n    \n      \n      rating\n      minlen\n      avlen\n      stdlen\n      maxlen\n    \n  \n  \n    \n      0\n      G\n      47\n      111.0506\n      41.654312\n      185\n    \n    \n      1\n      PG\n      46\n      112.0052\n      39.155716\n      185\n    \n    \n      2\n      NC-17\n      46\n      113.2286\n      40.717905\n      184\n    \n    \n      3\n      R\n      49\n      118.6615\n      38.408176\n      185\n    \n    \n      4\n      PG-13\n      46\n      120.4439\n      41.074091\n      185\n    \n  \n\n\n\n\nSo to summarize we have:\nselect group_field, summary(f1) as name1, summary(f2) as name2,... from table \ngroup by group_field order by name1\n\nTwo extras: distinct and limit\nFinally, if you just want to see the possible values in a field, or you only want to consider distinct values in a sum, you can use the DISTINCT keyword.\n\nrun_sql(\"Select distinct rating from film\", engine)\n\n[('PG',), ('G',), ('NC-17',), ('PG-13',), ('R',)]\n\n\n\nrun_sql(\"select count(distinct rating) from film\", engine)\n\n[(5,)]\n\n\nIf you only want to retrieve, say, 20 records, you can use the LIMIT keyword.\n\nrun_sql(\"select title, length from film limit 20\", engine)\n\n[('ACADEMY DINOSAUR', 86),\n ('ACE GOLDFINGER', 48),\n ('ADAPTATION HOLES', 50),\n ('AFFAIR PREJUDICE', 117),\n ('AFRICAN EGG', 130),\n ('AGENT TRUMAN', 169),\n ('AIRPLANE SIERRA', 62),\n ('AIRPORT POLLOCK', 54),\n ('ALABAMA DEVIL', 114),\n ('ALADDIN CALENDAR', 63),\n ('ALAMO VIDEOTAPE', 126),\n ('ALASKA PHANTOM', 136),\n ('ALI FOREVER', 150),\n ('ALICE FANTASIA', 94),\n ('ALIEN CENTER', 46),\n ('ALLEY EVOLUTION', 180),\n ('ALONE TRIP', 82),\n ('ALTER VICTORY', 57),\n ('AMADEUS HOLY', 113),\n ('AMELIE HELLFIGHTERS', 79)]"
  },
  {
    "objectID": "chapters/12-SQL/sql_python.html#exercises",
    "href": "chapters/12-SQL/sql_python.html#exercises",
    "title": "Databases and SQL - Selection - Python",
    "section": "Exercises",
    "text": "Exercises\n\nRetrieve the list of actors first and last names, with their actor ids, into a pandas dataframe. (They are in the table actor).\nRetrieve the list of actors sorted by last name.\nRetrieve just a count of the number of actors.\nThe function substring returns a substring so substring(last_name, 1,1) refers to the first letter of the last_name. Retrieve all the actors whose last name starts with “A”.\nDo problem 4, but sort them in alphabetical order by their first name.\nRetrieve a count of the number of actors grouped by the first letter of their last name. Which is the most common?"
  },
  {
    "objectID": "chapters/99-Resources/Cheatsheets.html",
    "href": "chapters/99-Resources/Cheatsheets.html",
    "title": "Cheatsheets and other References",
    "section": "",
    "text": "This is a compilation of resources from various sites on the web.\n\n\nFrom the pandas home page.\n\npandas cheatsheet\n\n\n\n\nThanks to the matplotlib home page.\n\nbeginner cheatsheet\nintermediate cheatsheet\ntip sheet\ncomplete (front)\ncomplete (back)\nstyles\n\n\n\n\nSeaborn is a fancier interface to matplotlib that offers high quality statistical plots of various types.\n\nseaborn cheatsheet\n\n\n\n\nFrom the posit home page\n\nbase r cheatsheet\ntidyverse cheatsheet\nr markdown cheatsheet\n\n\n\n\nFrom the posit home page\n\nggplot cheatsheet\n\n\n\n\nFrom the vscode home page\n\nwindows keybindings\nmac keybindings\nlinux keybindings\n\n\n\n\n\nMarkdown Cheat Sheet"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html",
    "href": "chapters/99-Resources/regexps.html",
    "title": "Python regexps",
    "section": "",
    "text": "# Regular Expressions\nimport re\nfrom collections import Counter"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#guide",
    "href": "chapters/99-Resources/regexps.html#guide",
    "title": "Python regexps",
    "section": "Guide",
    "text": "Guide\n\nLetters, Numbers match themselves\n‘.’ matches one of anything\n‘+’ means one or more of the preceeding\n’*’ means 0 or more of the preceding\n[] groups things ([A-Z]+ matches a sequence of one or more capital letters);\n‘\\w’ matches “word” characters\n‘\\W’ matches non-word characters\n‘\\b’ matches boundaries (end or start of string)\n‘{5}’’ matches 5 times\n‘\\s’ matches whitespace\n‘\\S’ matches non-whitespace\n\n\nif re.search(r\"travel\", text):\n    print(\"Yes\")\n\nif re.match(r\"travel\", text):\n    print(\"Yes\")\n\n# m = re.search(r\"travel\",text)\n# print(m,m.start(), m.end(),m.span(),m.string)\n\nm = re.search(r\"I (\\w+) to \", text)\nprint(m[0], m[1])\n\nYes\nI travelled to  travelled\n\n\n\nastrings = re.findall(r\"a\\w+\", text)\nprint(astrings)\n\nawords = re.findall(r\"\\ba\\w+\\b\", text)\nprint(awords)\n\n['ago', 'avelled', 'ar', 'ains', 'arid', 'ases', 'and', 'an', 'as', 'air', 'and', 'at']\n['ago', 'arid', 'and', 'and', 'at']\n\n\n\nre.findall(r\"\\w+\", text)\n\nre.findall(r\"\\w+\", text.lower())\n\n['long',\n 'ago',\n 'i',\n 'travelled',\n 'to',\n 'the',\n 'far',\n 'west',\n 'seeking',\n 'my',\n 'fortune',\n 'i',\n 'found',\n 'frosty',\n 'mountains',\n 'arid',\n 'deserts',\n 'lush',\n 'oases',\n 'and',\n 'a',\n 'huge',\n 'ocean',\n 'at',\n 'times',\n 'i',\n 'was',\n 'gripped',\n 'by',\n 'despair',\n 'and',\n 'at',\n 'other',\n 'times',\n 'filled',\n 'with',\n 'joy',\n 'anonymous',\n '1865']"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#match-objects",
    "href": "chapters/99-Resources/regexps.html#match-objects",
    "title": "Python regexps",
    "section": "Match Objects",
    "text": "Match Objects\n\n%%\nfinditer\nmatch objects\nx a match object: x[0] returns the match; x.span() returns (start, end) of the match\n\n\nfor x in re.finditer(r\"\\w+\", text):\n    print(x[0])\n\nLong\nago\nI\ntravelled\nto\nthe\nfar\nwest\nseeking\nmy\nfortune\nI\nfound\nfrosty\nmountains\narid\ndeserts\nlush\noases\nand\na\nhuge\nocean\nAt\ntimes\nI\nwas\ngripped\nby\ndespair\nand\nat\nother\ntimes\nfilled\nwith\nJoy\nAnonymous\n1865"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#counter",
    "href": "chapters/99-Resources/regexps.html#counter",
    "title": "Python regexps",
    "section": "Counter",
    "text": "Counter\nCounter creates a dictionary that counts the number of occurrences of elements of a list.\n\nwords = re.findall(r\"\\b\\w\\w+\\b\", text.lower())\ncounts = Counter(words)\nsorted_words = dict(sorted(counts.items(), key=lambda x: x[0], reverse=True))\nprint(sorted_words)\n\n{'with': 1, 'west': 1, 'was': 1, 'travelled': 1, 'to': 1, 'times': 2, 'the': 1, 'seeking': 1, 'other': 1, 'ocean': 1, 'oases': 1, 'my': 1, 'mountains': 1, 'lush': 1, 'long': 1, 'joy': 1, 'huge': 1, 'gripped': 1, 'frosty': 1, 'found': 1, 'fortune': 1, 'filled': 1, 'far': 1, 'despair': 1, 'deserts': 1, 'by': 1, 'at': 2, 'arid': 1, 'anonymous': 1, 'and': 2, 'ago': 1, '1865': 1}"
  },
  {
    "objectID": "chapters/999-Problems/Distributions.html",
    "href": "chapters/999-Problems/Distributions.html",
    "title": "Notes on Probability in R",
    "section": "",
    "text": "As I mentioned in class, every probability distribution in R comes with 4 functions. In the case of the binomial distribution, they are:\n\nrbinom – draws random samples\ndbinom – computes the probability distribution\npbinom – gives the cumulative distribution\nqbinom – gives the quantile function\n\nAlso, we need ggplot2.\n\nlibrary(ggplot2)\n\nExamples\n\nSuppose that the probability of heads is .3 and we flip a coin 15 times. What’s the chance of getting 6 heads?\n\n\np<-dbinom(6,15,.3)\ncat(\"The chance is \",p)\n\nThe chance is  0.147236\n\n\n\nLet’s find the probabilities of each number of heads.\n\n\nxs<-seq(0,10) # x holds 0,1,...,10\nfs<-dbinom(xs,10,.3)\nprint(fs)\n\n [1] 0.0282475249 0.1210608210 0.2334744405 0.2668279320 0.2001209490\n [6] 0.1029193452 0.0367569090 0.0090016920 0.0014467005 0.0001377810\n[11] 0.0000059049\n\n\n\nLet’s plot this. We’ll use ggplot. This is a very simple use of ggplot to make a bar chart. We’ll talk about ggplot more comprehensively later. For now, you can use this as a “black box”. In the part that says aes(x=?,y=?) you put the data for the x and y coordinates. The scale_x_continous(break=?) says where to put the x-ticks. The xlab(\"?\") labels the x-axis. The ylab labels the y-axis.\n\n\nggplot()+geom_col(aes(x=xs,y=fs))+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Probability\")\n\n\n\n\n\nLet’s sample this distribution. We’ll flip a coin with p=.3 10 times, and we’ll repeat this experiment 100 times, counting how many heads we get each repetition.\n\n\nheads <- rbinom(100,10,.3)\nheads\n\n  [1] 4 2 4 2 2 2 6 0 4 1 2 4 4 3 3 6 4 2 2 2 3 4 3 4 5 3 4 2 2 1 3 2 3 2 1 1 2\n [38] 3 3 3 5 3 6 4 3 3 3 3 4 3 5 2 2 4 4 2 1 3 4 4 3 2 4 2 3 7 2 6 2 2 3 4 0 3\n [75] 4 3 4 1 3 3 3 3 5 2 3 3 2 3 7 1 3 2 2 2 2 1 3 4 3 4\n\n\nNow let’s make a histogram. Again, here is a “black box” command for ggplot. Again, you put the data in aes(x=?) and you put the location for the x-ticks in scale_x_continous(breaks=?).\n\nggplot()+geom_histogram(aes(x=heads),stat='count')+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Count\")\n\nWarning in geom_histogram(aes(x = heads), stat = \"count\"): Ignoring unknown\nparameters: `binwidth`, `bins`, and `pad`\n\n\n\n\n\n\nSuppose we flip the coin 80 times (and p=.3). What’s the chance of getting between 20 and 40 heads? This is what pbinom is for. pbinom(40,80,.3) is the chance of getting fewer than or equal to 40 heads. If we want 20 to 40 inclusive we need to look at pbinom(41,80,.3).\n\n\nchance<-pbinom(40,80,.3)-pbinom(19,80,.3)\ncat(\"Chance  of between 40 and 20 inclusive is \",chance)\n\nChance  of between 40 and 20 inclusive is  0.86472\n\n\n\nAmong the number of heads in 100 flips of a coin with .3, what’s the 25th percentile for the number of heads? That’s what qbinom is for.\n\n\ntwentyFifth<-qbinom(.25,100,.3)\npaste(\"The 25th percentile is \",twentyFifth)\n\n[1] \"The 25th percentile is  27\"\n\n\nLet’s check.\n\ncheck<-pbinom(twentyFifth,100,.3)\ncheck\n\n[1] 0.2963662\n\n\nThis says that the chance of fewer than 27 heads is actually a bit more than .25 but the chance of fewer than 26 heads is less than .25.\n\nAn experiment\n\nLet’s sample from the binomial 10000 times and look at the 25th percentile.\n\ndata<-rbinom(10000,100,.3)\nt1<-sum(data<twentyFifth)\nt2<-sum(data<twentyFifth+1)\ncat(\"Number less than \",twentyFifth, \"is \",t1,\"\\n\")\n\nNumber less than  27 is  2281 \n\ncat(\"Number less than \",twentyFifth+1,\"is\",t2)\n\nNumber less than  28 is 3013\n\n\nThese numbers show that the 25th percentile (2500 heads) is somewhere between these two values."
  },
  {
    "objectID": "chapters/999-Problems/Distributions.html#practice-note-these-are-now-assigned-in-hw-2",
    "href": "chapters/999-Problems/Distributions.html#practice-note-these-are-now-assigned-in-hw-2",
    "title": "Notes on Probability in R",
    "section": "Practice (note: these are now assigned in HW 2)",
    "text": "Practice (note: these are now assigned in HW 2)\n\nLet X be a binomial random variable with n=50 and p=.7.\n\n\n\nDraw 1000 samples from X. How many of your sampled values are less than 30?\nBased on the probability distribution, how many sampled values would you expect to see that are less than 30?\nPlot a histogram of your sampled values.\n\n\nThe poisson distribution is a discrete probability distribution that arises in queuing theory (and many other places). For example, imagine that customers arrive at a server at a rate so that, in a typical one hour period, 20 customers come. But the intervals between customers are random and independent of one another. Then in a randomly chosen hour, the probability of k customers arriving is dpois(k,20).\n\n\n\nSample this distribution 1000 times (hint: use rpois). What is the largest number of people who arrive in an one of these random hours? What is the smallest?\nSuppose you want to design your system so that it can handle the number of arriving customers 95% of the time. How many people should you design for? (Hint: use qpois).\nWhat’s the chance that between 18 and 22 people arrive in a given hour? (Hint: use ppois).\nPlot the Poisson distribution probabilities. (Hint: use dpois)."
  },
  {
    "objectID": "chapters/999-Problems/HW1.html",
    "href": "chapters/999-Problems/HW1.html",
    "title": "Homework One",
    "section": "",
    "text": "This assignment is due Sunday, September 10th by midnight. Please submit it using HuskyCT. Follow the instructions below.\n\nCreate a project directory named Homework_One, and inside it create a subdirectory called python.\nIn the python directory, create a jupyter notebook named Homework_One.ipynb.\nUsing a markdown cell, add text at the beginning of your notebook that yields text following this template:\nHeader: First Homework Assignment for Grad 5100\nText: Submitted by [your name] on [the date]\nTopic: Some features of the python language.\n\n(Hint: you can get the word python formatted this way by using backticks: `python`) 3. Using a code cell, create the following variables:\n\nfirst_name = # your first name (a string)\nlast_name = # your last name (a string)\nyear = # current year, an integer\nstates = # a list of strings containing the names of the New England states (look them up)\n\nWorking in code cells, complete the following\n\nfirst_name_345 = first_name[] # fill in the [] to extract the third, fourth, and fifth letters of your first name (note this could be an empty string, or shorter than three letters)\nprint() # complete the print statement to show your answer\n\n\nlast_name_last = last_name[] # fill in the [] to extract the last letter of your last name. Do not assume you know how many letters are in your last name. \nprint() # complete the print statement to show your answer\n\n\nyear_5 = # compute the year multipled by 5\nprint() # print the answer\n\nThe sorted command takes a list and returns it sorted.\n\nstates_sorted = sorted(states) # sort your list of states\nmid = states+_sorted[][] # complete the []'s to find the last letter of the third New England state in alphabetical order. \nprint() # print the answer\n\n\nExport your jupyter notebook as a pdffile and submit it using HuskyCT.\nGo back to your project directory and create a subdirectory called R. In that directory, start Rstudio.\nCreate an RMD file called Homework_One.rmd and repeat the steps above, but working in R and Rstudio. Notice that you’ll have to make some small modifications to the syntax:\n\nchange “Python” to “R”\nreplace “=” by “<-”\nin R, you use sort not sorted\n\nExport your RMD file as a pdf file and submit it using HuskyCT."
  },
  {
    "objectID": "chapters/999-Problems/HW2-Iteration.html",
    "href": "chapters/999-Problems/HW2-Iteration.html",
    "title": "Comments on HW2 - iteration",
    "section": "",
    "text": "def sq(n, threshold=1e-6, max_iter=1000):\n    x = 1\n    tol = 1 + threshold  # make sure the tolerance starts bigger than the threshold\n    iterations = 0\n\n    while tol > threshold and iterations < max_iter:\n        xnew = 0.5 * (x + n / x)\n        tol = np.abs(xnew - x)\n        x = xnew\n        iterations = iterations + 1\n\n    if iterations >= max_iter:\n        print(\"Failed to converge\")\n        return None\n    else:\n        return x\n\n\ndef sq(n, tol=1e-6, max_iter=1000):\n    x = 1\n    tol = 1\n    iterations = 0\n\n    while tol > threshold:\n        xnew = 0.5 * (x + n / x)\n        tol = np.abs(xnew - x)\n        x = xnew\n        iterations = iterations + 1\n        if iterations > max_iter:\n            print(\"Failed to converge\")\n            return None\n    return x"
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html",
    "href": "chapters/999-Problems/HW2-Poisson.html",
    "title": "HW2 - Comments on Poisson",
    "section": "",
    "text": "The Poisson distribution measures the probability of \\(k\\) events occurring in a given time interval, assuming:\n\nthe interarrival times are independent of one another\nthe mean number of arrivals in any interval is a constant \\(\\lambda\\).\n\n\n\n\n\npdata <- tibble(\n    x = seq(0, 20),\n)\nplts <- list()\ni <- 1\n\nfor (n in seq(1, 10, 2)) {\n    cname <- paste0(\"y\", n)\n    pdata <- pdata |> mutate({{ cname }} := dpois(`x`, n))\n}\n\np1 <- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y1)) +\n    ggtitle(\"mean=1\")\np3 <- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y3)) +\n    ggtitle(\"mean=3\")\np5 <- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y5)) +\n    ggtitle(\"mean=5\")\np7 <- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y7)) +\n    ggtitle(\"mean=7\")\np9 <- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y9)) +\n    ggtitle(\"mean=9\")\ngrid.arrange(p1, p3, p5, p7, p9)"
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html#the-exponential-distribution",
    "href": "chapters/999-Problems/HW2-Poisson.html#the-exponential-distribution",
    "title": "HW2 - Comments on Poisson",
    "section": "The Exponential Distribution",
    "text": "The Exponential Distribution\nThe exponential distribution is a continuous probability distribution given by an exponential function with a fixed rate \\(\\lambda\\).\n\nx <- seq(0, 3, .01)\ny <- dexp(x, 1)\nggplot() +\n    geom_line(aes(x = x, y = y)) +\n    ggtitle(\"Exponential Distribution with parameter 1\")"
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html#poisson-process",
    "href": "chapters/999-Problems/HW2-Poisson.html#poisson-process",
    "title": "HW2 - Comments on Poisson",
    "section": "Poisson Process",
    "text": "Poisson Process\nIn a “Poisson Process”, events occur randomly in time. The interval between two consecutive events is chosen (independently) from an exponential distribution.\n\nt <- rexp(100, 1)\narrivals <- cumsum(t)\nggplot() +\n    geom_col(aes(x = arrivals, y = 1), width = .015, color = \"black\") +\n    ggtitle(\"Arrival Times in a Poisson Process\")\n\n\n\n\n\nsum(arrivals < 25)\n\n[1] 20\n\nsum(arrivals < 50)\n\n[1] 31\n\nsum(arrivals > 25 & arrivals < 50)\n\n[1] 11"
  },
  {
    "objectID": "chapters/999-Problems/HW2-clean_up_function.html",
    "href": "chapters/999-Problems/HW2-clean_up_function.html",
    "title": "Comments on HW2 - String Clean Up",
    "section": "",
    "text": "4 Sample Solutions\n\ndef clean_up(s):\n    new_s = \"\"\n    for x in s:\n        if x in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \":\n            if x == \" \":\n                new_s = new_s + \"_\"\n            else:\n                new_s = new_s + x\n    return new_s.lower()\n\n\n\n\ndef clean_string(input_string):\n    # Remove characters that are not numbers, letters, or spaces\n    cleaned_string = \"\".join(\n        char for char in input_string if char.isalnum() or char == \" \"\n    )\n    # Convert to lowercase\n    cleaned_string = cleaned_string.lower()\n    # Convert spaces to underscores\n    cleaned_string = cleaned_string.replace(\" \", \"_\")\n\n    return cleaned_string\n\n\ndef editing_2(x):\n    text_2 = \"\"\n    for char in x:\n        if char.isalnum() or char.isspace() or char.isalpha():\n            text_2 = text_2 + char\n    text_2 = text_2.lower()\n    text_2 = text_2.replace(\" \", \"_\")\n    return text_2\n\n\nimport re\n\n\ndef p4(s):\n    s = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", s)\n    s = s.replace(\" \", \"_\")\n    return s.lower()"
  },
  {
    "objectID": "chapters/999-Problems/HW2-clean_up_function.html#r",
    "href": "chapters/999-Problems/HW2-clean_up_function.html#r",
    "title": "Comments on HW2 - String Clean Up",
    "section": "R",
    "text": "R\n\nclean_up <- function(s) {\n    valid <- c(letters, LETTERS, \" \", seq(0, 9)) # a vector of the things I want to keep\n    split_string <- strsplit(s, \"\")[[1]]\n    keepers <- split_string[split_string %in% valid]\n    keepers <- tolower(gsub(\" \", \"_\", keepers))\n    paste(keepers, collapse = \"\")\n}\n\n\nstring_edit <- function(string) {\n    acceptable_characters <- c(letters, LETTERS, as.character(seq(0, 9)), \" \")\n    unacceptable_characters <- paste(\"[^\", paste0(acceptable_characters, collapse = \"\"), \"]\", sep = \"\")\n\n    cleaned_string <- string\n\n    for (character in unacceptable_characters) {\n        cleaned_string <- gsub(character, \"\", cleaned_string)\n    }\n\n    cleaned_string <- tolower(cleaned_string)\n\n    cleaned_string <- gsub(\" \", \"_\", cleaned_string)\n\n    return(cleaned_string)\n}\n\n\ni_function <- function(input) {\n    a1 <- gsub(\"[^[:alnum:] ]\", \"\", input)\n    a2 <- gsub(\" \", \"_\", a1)\n    tolower(a2)\n}\n\n\nclean_and_format_string <- function(input_string) {\n    cleaned_string <- gsub(\"[^0-9a-zA-Z[:space:]]\", \"\", input_string)\n\n    cleaned_string <- tolower(cleaned_string)\n\n    cleaned_string <- gsub(\" \", \"_\", cleaned_string)\n\n    return(cleaned_string)\n}"
  },
  {
    "objectID": "chapters/999-Problems/HW2.html",
    "href": "chapters/999-Problems/HW2.html",
    "title": "Homework Two",
    "section": "",
    "text": "This homework is due Sunday, September 24th at midnight. Please submit it using HuskyCT.\nThere are two files you need to submit (one for R, one for python). For the R part of the homework (problems 1-3), you submit a QMD file with the following YAML material at the top. For the Python part (problem 4-5) submit an ipynb file.\n\n---\ntitle: \"Homework Two - R\"\nauthor: [your name]\nformat: html\n---\n\n\nProblem 1\nLet X be a binomial random variable with n=50 and p=.7.\n\nDraw 1000 samples from X. How many of your sampled values are less than 30?\nBased on the probability distribution, how many sampled values would you expect to see that are less than 30?\n\nPlot a histogram of your sampled values.\n\nYour answer should be in the form of an r code block in your qmd file.\n\nXsamples <- #\nless_than_30_observed <- #\nless_than_30_predicted <- #\n# code to plot histogram of Xsamples\n\n\n\nProblem 2\nThe poisson distribution is a discrete probability distribution that arises in queuing theory (and many other places). For example, imagine that customers arrive at a server at a rate so that, in a typical one hour period, 20 customers come. But the intervals between customers are random and independent of one another. Then in a randomly chosen hour, the probability of k customers arriving is dpois(k,20).\n\nSample this distribution 1000 times (hint: use rpois). What is the largest number of people who arrive in an one of these random hours? What is the smallest?\nSuppose you want to design your system so that it can handle the number of arriving customers 95% of the time. How many people should you design for? (Hint: use qpois).\nWhat’s the chance that between 18 and 22 people arrive in a given hour? (Hint: use ppois).\nPlot the Poisson distribution probabilities. (Hint: use dpois).\n\n\n  poisson_samples <- #\n  max_arrivals <- #\n  min_arrivals <- #\n  threshold_95 <-#\n  # code to plot the distribution\n\n\n\nProblem 3\nWrite an R function that takes a string as input, removes all characters that are not numbers, letters, or spaces, makes all the letters lower case, converts all the spaces to ’_’, and returns the result.\nHints:\n\nthe gsub function replaces things in a string.\nthe tolower function makes things lower case\nthe builtin variable letters (resp LETTERS) is a vector of all lower (resp upper) case letters.\n\n\n\nProblem 4\nDo problem 3 in Python.\nHints:\n\nthe python string method replace() replaces thngs in a string. So if x is a string, x.replace(\"a\",\"b\") replaces all a’s by b.\nthe python string method lower() makes a string lower case. So if x is a string, x.lower() is x in lower case.\n\n\n\nProblem 5\nIf \\(x_0=1\\) and \\(n\\) is a positive real number, the iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\nconverges to the square root of \\(n\\). Write a Python function that runs this iteration until the difference between \\(x_{k+1}\\) and \\(x_{k}\\) is less than a tolerance.\n\ndef sq(n):\n    x=1\n    tol = 1\n    while(tol>1e-6):\n        xnew = # fill this in\n        tol = np.abs(xnew - x)\n        x = xnew\n    return x\n\nNow improve the function above so that:\n\none can optionally provide a threshold to replace 1e-6\nif the code runs for more than max_iter iterations of the while loop, it quits while printing “Failed to converge”. max_iter is by default 1000 but can be modified when the function is called."
  },
  {
    "objectID": "chapters/999-Problems/HW3Assignment.html",
    "href": "chapters/999-Problems/HW3Assignment.html",
    "title": "Homework 3",
    "section": "",
    "text": "The third homework assignment is due at midnight, October 15th. Submit it on HuskyCT.\nYou may do this assignment using either R or Python, your choice.\nWe will work with this file containing Amazon Books. Load this file into a tibble (for R) or a pandas dataframe (for Python) and then carry out the following steps. READ THE INSTRUCTIONS CAREFULLY!\nYour solution should come in the form of a report that shows the steps you carried out to achieve each goal. You should submit a jupyter notebook or a qmd file that I can execute to verify each of the steps.\n\nThere are a rows in this dataframe with missing titles and there are a bunch of extra columns at the end of the dataframe. Clean up the dataset by deleting the extra columns and the rows where the title is missing.\nAfter the changes in (1), how many rows have missing authors? Show the titles of the books with missing authors and then delete those from the data frame.\nIn the remaining dataset, the price column mostly consists of strings with a $ and then the price. But a few of the entries don’t have the $ and are already numbers.\n\nDelete any books with missing prices from the data set.\nFix this column so every entry is a number and you can do arithmetic on it.\n\nWhich books are missing a price? Show those books.\n\n\nHint: In python, you can determine if something is a string by using the isinstance command. So isinstance(x,str) is Trueif x is of type string, and False otherwise. You can convert a string to a number using float: float(x) converts a string x to a number, assuming x is in a valid form to be a number.\nHint: in R, you can convert a string to a number using the as.numeric function.\n\nOf the remaining books, which ones are missing a rating?\n\nshow the books that are missing a rating\ndelete these books from the data set.\n\nThe ratings are entered as strings, and, for some reason, a few of the ratings are entered with a $. (So it says $4.40 instead of 4.4). How many of these are there? Fix this column so that all of the entries are numbers, and get rid of the $. Drop any rows where the rating is missing.\nMake a new column ‘quality’ where the entry is “Excellent” if the rating is >=4.5, “Good” if it is between >=3.8 and <4.5, and “Fair” if it is <3.8.\nMake a table with rows “Excellent”, “Good” and “Fair” and Columns “count” and “mean” where the entries are the number of books with each class of ratings and the mean value of the price of the books within each rating class.\nMake a new column called “python” which has a one if the title of the book includes the word “Python” or “python” and a zero if it doesn’t.\n\nHint: In R, the function grepl detects the presence of a substring. So grepl(\"Python\",x) is TRUE if Python is a substring of x, and false otherwise.\nHint: In python, you can use in: \"Python\" in x is true if “Python” is a substring.\n\nMake a pivot table with rows the rating classes, columns the yes/no values for Python, and entries the average price within each class."
  },
  {
    "objectID": "chapters/999-Problems/HW4Assignment.html",
    "href": "chapters/999-Problems/HW4Assignment.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please submit your solution to this problem on Husky CT by Monday, October 30th at 8:00 AM.\nThis zip file contains the first few chapters of “The Hitchiker’s Guide to the Galaxy” by Douglas Adams in text format in a file called hhg.txt.\n\nWhat shell command will tell you if the word “adorable” occurs in this file? (does it?)\nWhat shell command will tell you how many lines are in the file? (how many are there?)\n\nNext, using whatever tools you prefer, create 26 text files called hhgX.txt where X runs from A to Z. Each file should contain all of the words from hhg.txt that begin with the corresponding letter, one word per line, in alphabetical order, in lower case. Each word should occur only once in hhgX.txt regardless of how many times it occurs in the original text.\nNext, answer the following questions:\n\nWhat shell command would combine all of the hhgX.txt files into a single file called hhgwords.txt?\nWhat shell commands would carry out the following:\n\ncreate a directory called orig\nmove the original files hhg.zip and hhg.txt into this directory.\n\n\nCreate a file that contains your answers to a,b,c,d called shell_answers.sh. This file should contain only four lines.\nCreate a single zip file called hhg-exploded.zip which, when uncompressed, yields:\n\na directory called first_last where first and last are your first and last names. Inside that directory, there should be:\na file report.txt that explains your method for creating the hhgX.txt files (briefly)\nthe file shell_answers.sh\na subdirectory whose name is hhg-exploded, and whose contents are the 26 files described above.\na subdirectory called bkup which contains the original text file hhg.txt as well as the original zip file hhg.zip.\n\nTo illustrate (although I’ve only put the ABC files in hhg-exploded) your zip file should unpack to this:\njeremy_teitelbaum\n├── bkup\n│   ├── hhg.txt\n│   └── hhg.zip\n├── hhg-exploded\n│   ├── hhgA.txt\n│   ├── hhgB.txt\n│   ├── hhgC.txt\n│   \n├── report.txt\n└── shell_answers.sh"
  }
]