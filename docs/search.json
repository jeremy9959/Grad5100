[
  {
    "objectID": "chapters/9999-Miscellaneous/R-Missing-Values.html",
    "href": "chapters/9999-Miscellaneous/R-Missing-Values.html",
    "title": "Missing Values",
    "section": "",
    "text": "Missing values are a common challenge in datasets. Let’s look at some examples for ways to work with them.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\ndf&lt;-data.frame(penguins)\ndf\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen           39.1          18.7               181\n2      Adelie Torgersen           39.5          17.4               186\n3      Adelie Torgersen           40.3          18.0               195\n4      Adelie Torgersen             NA            NA                NA\n5      Adelie Torgersen           36.7          19.3               193\n6      Adelie Torgersen           39.3          20.6               190\n7      Adelie Torgersen           38.9          17.8               181\n8      Adelie Torgersen           39.2          19.6               195\n9      Adelie Torgersen           34.1          18.1               193\n10     Adelie Torgersen           42.0          20.2               190\n11     Adelie Torgersen           37.8          17.1               186\n12     Adelie Torgersen           37.8          17.3               180\n13     Adelie Torgersen           41.1          17.6               182\n14     Adelie Torgersen           38.6          21.2               191\n15     Adelie Torgersen           34.6          21.1               198\n16     Adelie Torgersen           36.6          17.8               185\n17     Adelie Torgersen           38.7          19.0               195\n18     Adelie Torgersen           42.5          20.7               197\n19     Adelie Torgersen           34.4          18.4               184\n20     Adelie Torgersen           46.0          21.5               194\n21     Adelie    Biscoe           37.8          18.3               174\n22     Adelie    Biscoe           37.7          18.7               180\n23     Adelie    Biscoe           35.9          19.2               189\n24     Adelie    Biscoe           38.2          18.1               185\n25     Adelie    Biscoe           38.8          17.2               180\n26     Adelie    Biscoe           35.3          18.9               187\n27     Adelie    Biscoe           40.6          18.6               183\n28     Adelie    Biscoe           40.5          17.9               187\n29     Adelie    Biscoe           37.9          18.6               172\n30     Adelie    Biscoe           40.5          18.9               180\n31     Adelie     Dream           39.5          16.7               178\n32     Adelie     Dream           37.2          18.1               178\n33     Adelie     Dream           39.5          17.8               188\n34     Adelie     Dream           40.9          18.9               184\n35     Adelie     Dream           36.4          17.0               195\n36     Adelie     Dream           39.2          21.1               196\n37     Adelie     Dream           38.8          20.0               190\n38     Adelie     Dream           42.2          18.5               180\n39     Adelie     Dream           37.6          19.3               181\n40     Adelie     Dream           39.8          19.1               184\n41     Adelie     Dream           36.5          18.0               182\n42     Adelie     Dream           40.8          18.4               195\n43     Adelie     Dream           36.0          18.5               186\n44     Adelie     Dream           44.1          19.7               196\n45     Adelie     Dream           37.0          16.9               185\n46     Adelie     Dream           39.6          18.8               190\n47     Adelie     Dream           41.1          19.0               182\n48     Adelie     Dream           37.5          18.9               179\n49     Adelie     Dream           36.0          17.9               190\n50     Adelie     Dream           42.3          21.2               191\n51     Adelie    Biscoe           39.6          17.7               186\n52     Adelie    Biscoe           40.1          18.9               188\n53     Adelie    Biscoe           35.0          17.9               190\n54     Adelie    Biscoe           42.0          19.5               200\n55     Adelie    Biscoe           34.5          18.1               187\n56     Adelie    Biscoe           41.4          18.6               191\n57     Adelie    Biscoe           39.0          17.5               186\n58     Adelie    Biscoe           40.6          18.8               193\n59     Adelie    Biscoe           36.5          16.6               181\n60     Adelie    Biscoe           37.6          19.1               194\n61     Adelie    Biscoe           35.7          16.9               185\n62     Adelie    Biscoe           41.3          21.1               195\n63     Adelie    Biscoe           37.6          17.0               185\n64     Adelie    Biscoe           41.1          18.2               192\n65     Adelie    Biscoe           36.4          17.1               184\n66     Adelie    Biscoe           41.6          18.0               192\n67     Adelie    Biscoe           35.5          16.2               195\n68     Adelie    Biscoe           41.1          19.1               188\n69     Adelie Torgersen           35.9          16.6               190\n70     Adelie Torgersen           41.8          19.4               198\n71     Adelie Torgersen           33.5          19.0               190\n72     Adelie Torgersen           39.7          18.4               190\n73     Adelie Torgersen           39.6          17.2               196\n74     Adelie Torgersen           45.8          18.9               197\n75     Adelie Torgersen           35.5          17.5               190\n76     Adelie Torgersen           42.8          18.5               195\n77     Adelie Torgersen           40.9          16.8               191\n78     Adelie Torgersen           37.2          19.4               184\n79     Adelie Torgersen           36.2          16.1               187\n80     Adelie Torgersen           42.1          19.1               195\n81     Adelie Torgersen           34.6          17.2               189\n82     Adelie Torgersen           42.9          17.6               196\n83     Adelie Torgersen           36.7          18.8               187\n84     Adelie Torgersen           35.1          19.4               193\n85     Adelie     Dream           37.3          17.8               191\n86     Adelie     Dream           41.3          20.3               194\n87     Adelie     Dream           36.3          19.5               190\n88     Adelie     Dream           36.9          18.6               189\n89     Adelie     Dream           38.3          19.2               189\n90     Adelie     Dream           38.9          18.8               190\n91     Adelie     Dream           35.7          18.0               202\n92     Adelie     Dream           41.1          18.1               205\n93     Adelie     Dream           34.0          17.1               185\n94     Adelie     Dream           39.6          18.1               186\n95     Adelie     Dream           36.2          17.3               187\n96     Adelie     Dream           40.8          18.9               208\n97     Adelie     Dream           38.1          18.6               190\n98     Adelie     Dream           40.3          18.5               196\n99     Adelie     Dream           33.1          16.1               178\n100    Adelie     Dream           43.2          18.5               192\n101    Adelie    Biscoe           35.0          17.9               192\n102    Adelie    Biscoe           41.0          20.0               203\n103    Adelie    Biscoe           37.7          16.0               183\n104    Adelie    Biscoe           37.8          20.0               190\n105    Adelie    Biscoe           37.9          18.6               193\n106    Adelie    Biscoe           39.7          18.9               184\n107    Adelie    Biscoe           38.6          17.2               199\n108    Adelie    Biscoe           38.2          20.0               190\n109    Adelie    Biscoe           38.1          17.0               181\n110    Adelie    Biscoe           43.2          19.0               197\n111    Adelie    Biscoe           38.1          16.5               198\n112    Adelie    Biscoe           45.6          20.3               191\n113    Adelie    Biscoe           39.7          17.7               193\n114    Adelie    Biscoe           42.2          19.5               197\n115    Adelie    Biscoe           39.6          20.7               191\n116    Adelie    Biscoe           42.7          18.3               196\n117    Adelie Torgersen           38.6          17.0               188\n118    Adelie Torgersen           37.3          20.5               199\n119    Adelie Torgersen           35.7          17.0               189\n120    Adelie Torgersen           41.1          18.6               189\n121    Adelie Torgersen           36.2          17.2               187\n122    Adelie Torgersen           37.7          19.8               198\n123    Adelie Torgersen           40.2          17.0               176\n124    Adelie Torgersen           41.4          18.5               202\n125    Adelie Torgersen           35.2          15.9               186\n126    Adelie Torgersen           40.6          19.0               199\n127    Adelie Torgersen           38.8          17.6               191\n128    Adelie Torgersen           41.5          18.3               195\n129    Adelie Torgersen           39.0          17.1               191\n130    Adelie Torgersen           44.1          18.0               210\n131    Adelie Torgersen           38.5          17.9               190\n132    Adelie Torgersen           43.1          19.2               197\n133    Adelie     Dream           36.8          18.5               193\n134    Adelie     Dream           37.5          18.5               199\n135    Adelie     Dream           38.1          17.6               187\n136    Adelie     Dream           41.1          17.5               190\n137    Adelie     Dream           35.6          17.5               191\n138    Adelie     Dream           40.2          20.1               200\n139    Adelie     Dream           37.0          16.5               185\n140    Adelie     Dream           39.7          17.9               193\n141    Adelie     Dream           40.2          17.1               193\n142    Adelie     Dream           40.6          17.2               187\n143    Adelie     Dream           32.1          15.5               188\n144    Adelie     Dream           40.7          17.0               190\n145    Adelie     Dream           37.3          16.8               192\n146    Adelie     Dream           39.0          18.7               185\n147    Adelie     Dream           39.2          18.6               190\n148    Adelie     Dream           36.6          18.4               184\n149    Adelie     Dream           36.0          17.8               195\n150    Adelie     Dream           37.8          18.1               193\n151    Adelie     Dream           36.0          17.1               187\n152    Adelie     Dream           41.5          18.5               201\n153    Gentoo    Biscoe           46.1          13.2               211\n154    Gentoo    Biscoe           50.0          16.3               230\n155    Gentoo    Biscoe           48.7          14.1               210\n156    Gentoo    Biscoe           50.0          15.2               218\n157    Gentoo    Biscoe           47.6          14.5               215\n158    Gentoo    Biscoe           46.5          13.5               210\n159    Gentoo    Biscoe           45.4          14.6               211\n160    Gentoo    Biscoe           46.7          15.3               219\n161    Gentoo    Biscoe           43.3          13.4               209\n162    Gentoo    Biscoe           46.8          15.4               215\n163    Gentoo    Biscoe           40.9          13.7               214\n164    Gentoo    Biscoe           49.0          16.1               216\n165    Gentoo    Biscoe           45.5          13.7               214\n166    Gentoo    Biscoe           48.4          14.6               213\n167    Gentoo    Biscoe           45.8          14.6               210\n168    Gentoo    Biscoe           49.3          15.7               217\n169    Gentoo    Biscoe           42.0          13.5               210\n170    Gentoo    Biscoe           49.2          15.2               221\n171    Gentoo    Biscoe           46.2          14.5               209\n172    Gentoo    Biscoe           48.7          15.1               222\n173    Gentoo    Biscoe           50.2          14.3               218\n174    Gentoo    Biscoe           45.1          14.5               215\n175    Gentoo    Biscoe           46.5          14.5               213\n176    Gentoo    Biscoe           46.3          15.8               215\n177    Gentoo    Biscoe           42.9          13.1               215\n178    Gentoo    Biscoe           46.1          15.1               215\n179    Gentoo    Biscoe           44.5          14.3               216\n180    Gentoo    Biscoe           47.8          15.0               215\n181    Gentoo    Biscoe           48.2          14.3               210\n182    Gentoo    Biscoe           50.0          15.3               220\n183    Gentoo    Biscoe           47.3          15.3               222\n184    Gentoo    Biscoe           42.8          14.2               209\n185    Gentoo    Biscoe           45.1          14.5               207\n186    Gentoo    Biscoe           59.6          17.0               230\n187    Gentoo    Biscoe           49.1          14.8               220\n188    Gentoo    Biscoe           48.4          16.3               220\n189    Gentoo    Biscoe           42.6          13.7               213\n190    Gentoo    Biscoe           44.4          17.3               219\n191    Gentoo    Biscoe           44.0          13.6               208\n192    Gentoo    Biscoe           48.7          15.7               208\n193    Gentoo    Biscoe           42.7          13.7               208\n194    Gentoo    Biscoe           49.6          16.0               225\n195    Gentoo    Biscoe           45.3          13.7               210\n196    Gentoo    Biscoe           49.6          15.0               216\n197    Gentoo    Biscoe           50.5          15.9               222\n198    Gentoo    Biscoe           43.6          13.9               217\n199    Gentoo    Biscoe           45.5          13.9               210\n200    Gentoo    Biscoe           50.5          15.9               225\n201    Gentoo    Biscoe           44.9          13.3               213\n202    Gentoo    Biscoe           45.2          15.8               215\n203    Gentoo    Biscoe           46.6          14.2               210\n204    Gentoo    Biscoe           48.5          14.1               220\n205    Gentoo    Biscoe           45.1          14.4               210\n206    Gentoo    Biscoe           50.1          15.0               225\n207    Gentoo    Biscoe           46.5          14.4               217\n208    Gentoo    Biscoe           45.0          15.4               220\n209    Gentoo    Biscoe           43.8          13.9               208\n210    Gentoo    Biscoe           45.5          15.0               220\n211    Gentoo    Biscoe           43.2          14.5               208\n212    Gentoo    Biscoe           50.4          15.3               224\n213    Gentoo    Biscoe           45.3          13.8               208\n214    Gentoo    Biscoe           46.2          14.9               221\n215    Gentoo    Biscoe           45.7          13.9               214\n216    Gentoo    Biscoe           54.3          15.7               231\n217    Gentoo    Biscoe           45.8          14.2               219\n218    Gentoo    Biscoe           49.8          16.8               230\n219    Gentoo    Biscoe           46.2          14.4               214\n220    Gentoo    Biscoe           49.5          16.2               229\n221    Gentoo    Biscoe           43.5          14.2               220\n222    Gentoo    Biscoe           50.7          15.0               223\n223    Gentoo    Biscoe           47.7          15.0               216\n224    Gentoo    Biscoe           46.4          15.6               221\n225    Gentoo    Biscoe           48.2          15.6               221\n226    Gentoo    Biscoe           46.5          14.8               217\n227    Gentoo    Biscoe           46.4          15.0               216\n228    Gentoo    Biscoe           48.6          16.0               230\n229    Gentoo    Biscoe           47.5          14.2               209\n230    Gentoo    Biscoe           51.1          16.3               220\n231    Gentoo    Biscoe           45.2          13.8               215\n232    Gentoo    Biscoe           45.2          16.4               223\n233    Gentoo    Biscoe           49.1          14.5               212\n234    Gentoo    Biscoe           52.5          15.6               221\n235    Gentoo    Biscoe           47.4          14.6               212\n236    Gentoo    Biscoe           50.0          15.9               224\n237    Gentoo    Biscoe           44.9          13.8               212\n238    Gentoo    Biscoe           50.8          17.3               228\n239    Gentoo    Biscoe           43.4          14.4               218\n240    Gentoo    Biscoe           51.3          14.2               218\n241    Gentoo    Biscoe           47.5          14.0               212\n242    Gentoo    Biscoe           52.1          17.0               230\n243    Gentoo    Biscoe           47.5          15.0               218\n244    Gentoo    Biscoe           52.2          17.1               228\n245    Gentoo    Biscoe           45.5          14.5               212\n246    Gentoo    Biscoe           49.5          16.1               224\n247    Gentoo    Biscoe           44.5          14.7               214\n248    Gentoo    Biscoe           50.8          15.7               226\n249    Gentoo    Biscoe           49.4          15.8               216\n250    Gentoo    Biscoe           46.9          14.6               222\n251    Gentoo    Biscoe           48.4          14.4               203\n252    Gentoo    Biscoe           51.1          16.5               225\n253    Gentoo    Biscoe           48.5          15.0               219\n254    Gentoo    Biscoe           55.9          17.0               228\n255    Gentoo    Biscoe           47.2          15.5               215\n256    Gentoo    Biscoe           49.1          15.0               228\n257    Gentoo    Biscoe           47.3          13.8               216\n258    Gentoo    Biscoe           46.8          16.1               215\n259    Gentoo    Biscoe           41.7          14.7               210\n260    Gentoo    Biscoe           53.4          15.8               219\n261    Gentoo    Biscoe           43.3          14.0               208\n262    Gentoo    Biscoe           48.1          15.1               209\n263    Gentoo    Biscoe           50.5          15.2               216\n264    Gentoo    Biscoe           49.8          15.9               229\n265    Gentoo    Biscoe           43.5          15.2               213\n266    Gentoo    Biscoe           51.5          16.3               230\n267    Gentoo    Biscoe           46.2          14.1               217\n268    Gentoo    Biscoe           55.1          16.0               230\n269    Gentoo    Biscoe           44.5          15.7               217\n270    Gentoo    Biscoe           48.8          16.2               222\n271    Gentoo    Biscoe           47.2          13.7               214\n272    Gentoo    Biscoe             NA            NA                NA\n273    Gentoo    Biscoe           46.8          14.3               215\n274    Gentoo    Biscoe           50.4          15.7               222\n275    Gentoo    Biscoe           45.2          14.8               212\n276    Gentoo    Biscoe           49.9          16.1               213\n277 Chinstrap     Dream           46.5          17.9               192\n278 Chinstrap     Dream           50.0          19.5               196\n279 Chinstrap     Dream           51.3          19.2               193\n280 Chinstrap     Dream           45.4          18.7               188\n281 Chinstrap     Dream           52.7          19.8               197\n282 Chinstrap     Dream           45.2          17.8               198\n283 Chinstrap     Dream           46.1          18.2               178\n284 Chinstrap     Dream           51.3          18.2               197\n285 Chinstrap     Dream           46.0          18.9               195\n286 Chinstrap     Dream           51.3          19.9               198\n287 Chinstrap     Dream           46.6          17.8               193\n288 Chinstrap     Dream           51.7          20.3               194\n289 Chinstrap     Dream           47.0          17.3               185\n290 Chinstrap     Dream           52.0          18.1               201\n291 Chinstrap     Dream           45.9          17.1               190\n292 Chinstrap     Dream           50.5          19.6               201\n293 Chinstrap     Dream           50.3          20.0               197\n294 Chinstrap     Dream           58.0          17.8               181\n295 Chinstrap     Dream           46.4          18.6               190\n296 Chinstrap     Dream           49.2          18.2               195\n297 Chinstrap     Dream           42.4          17.3               181\n298 Chinstrap     Dream           48.5          17.5               191\n299 Chinstrap     Dream           43.2          16.6               187\n300 Chinstrap     Dream           50.6          19.4               193\n301 Chinstrap     Dream           46.7          17.9               195\n302 Chinstrap     Dream           52.0          19.0               197\n303 Chinstrap     Dream           50.5          18.4               200\n304 Chinstrap     Dream           49.5          19.0               200\n305 Chinstrap     Dream           46.4          17.8               191\n306 Chinstrap     Dream           52.8          20.0               205\n307 Chinstrap     Dream           40.9          16.6               187\n308 Chinstrap     Dream           54.2          20.8               201\n309 Chinstrap     Dream           42.5          16.7               187\n310 Chinstrap     Dream           51.0          18.8               203\n311 Chinstrap     Dream           49.7          18.6               195\n312 Chinstrap     Dream           47.5          16.8               199\n313 Chinstrap     Dream           47.6          18.3               195\n314 Chinstrap     Dream           52.0          20.7               210\n315 Chinstrap     Dream           46.9          16.6               192\n316 Chinstrap     Dream           53.5          19.9               205\n317 Chinstrap     Dream           49.0          19.5               210\n318 Chinstrap     Dream           46.2          17.5               187\n319 Chinstrap     Dream           50.9          19.1               196\n320 Chinstrap     Dream           45.5          17.0               196\n321 Chinstrap     Dream           50.9          17.9               196\n322 Chinstrap     Dream           50.8          18.5               201\n323 Chinstrap     Dream           50.1          17.9               190\n324 Chinstrap     Dream           49.0          19.6               212\n325 Chinstrap     Dream           51.5          18.7               187\n326 Chinstrap     Dream           49.8          17.3               198\n327 Chinstrap     Dream           48.1          16.4               199\n328 Chinstrap     Dream           51.4          19.0               201\n329 Chinstrap     Dream           45.7          17.3               193\n330 Chinstrap     Dream           50.7          19.7               203\n331 Chinstrap     Dream           42.5          17.3               187\n332 Chinstrap     Dream           52.2          18.8               197\n333 Chinstrap     Dream           45.2          16.6               191\n334 Chinstrap     Dream           49.3          19.9               203\n335 Chinstrap     Dream           50.2          18.8               202\n336 Chinstrap     Dream           45.6          19.4               194\n337 Chinstrap     Dream           51.9          19.5               206\n338 Chinstrap     Dream           46.8          16.5               189\n339 Chinstrap     Dream           45.7          17.0               195\n340 Chinstrap     Dream           55.8          19.8               207\n341 Chinstrap     Dream           43.5          18.1               202\n342 Chinstrap     Dream           49.6          18.2               193\n343 Chinstrap     Dream           50.8          19.0               210\n344 Chinstrap     Dream           50.2          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009\n\n\nFirst, let’s see how many NA values are in each column.\n\ncolSums(is.na(df))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\nNA values affect numerical calculations\n\nmean(df$bill_length_mm)\n\n[1] NA\n\n\nWe can tell the mean function (and other functions) how to handle NA.\n\nmean(df$bill_length_mm,na.rm=T)\n\n[1] 43.92193\n\n\nWe can leave out rows with NA values.\n\ndf_no_na &lt;- na.omit(df)\ncolSums(is.na(df_no_na))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 0                 0 \nflipper_length_mm       body_mass_g               sex              year \n                0                 0                 0                 0 \n\n\nWe can also replace NA with something. This function comes from the tidyverse library which we added above.\n\nreplace_na(df,list(bill_length_mm=mean(df$bill_length_mm,na.rm=T)))\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen       39.10000          18.7               181\n2      Adelie Torgersen       39.50000          17.4               186\n3      Adelie Torgersen       40.30000          18.0               195\n4      Adelie Torgersen       43.92193            NA                NA\n5      Adelie Torgersen       36.70000          19.3               193\n6      Adelie Torgersen       39.30000          20.6               190\n7      Adelie Torgersen       38.90000          17.8               181\n8      Adelie Torgersen       39.20000          19.6               195\n9      Adelie Torgersen       34.10000          18.1               193\n10     Adelie Torgersen       42.00000          20.2               190\n11     Adelie Torgersen       37.80000          17.1               186\n12     Adelie Torgersen       37.80000          17.3               180\n13     Adelie Torgersen       41.10000          17.6               182\n14     Adelie Torgersen       38.60000          21.2               191\n15     Adelie Torgersen       34.60000          21.1               198\n16     Adelie Torgersen       36.60000          17.8               185\n17     Adelie Torgersen       38.70000          19.0               195\n18     Adelie Torgersen       42.50000          20.7               197\n19     Adelie Torgersen       34.40000          18.4               184\n20     Adelie Torgersen       46.00000          21.5               194\n21     Adelie    Biscoe       37.80000          18.3               174\n22     Adelie    Biscoe       37.70000          18.7               180\n23     Adelie    Biscoe       35.90000          19.2               189\n24     Adelie    Biscoe       38.20000          18.1               185\n25     Adelie    Biscoe       38.80000          17.2               180\n26     Adelie    Biscoe       35.30000          18.9               187\n27     Adelie    Biscoe       40.60000          18.6               183\n28     Adelie    Biscoe       40.50000          17.9               187\n29     Adelie    Biscoe       37.90000          18.6               172\n30     Adelie    Biscoe       40.50000          18.9               180\n31     Adelie     Dream       39.50000          16.7               178\n32     Adelie     Dream       37.20000          18.1               178\n33     Adelie     Dream       39.50000          17.8               188\n34     Adelie     Dream       40.90000          18.9               184\n35     Adelie     Dream       36.40000          17.0               195\n36     Adelie     Dream       39.20000          21.1               196\n37     Adelie     Dream       38.80000          20.0               190\n38     Adelie     Dream       42.20000          18.5               180\n39     Adelie     Dream       37.60000          19.3               181\n40     Adelie     Dream       39.80000          19.1               184\n41     Adelie     Dream       36.50000          18.0               182\n42     Adelie     Dream       40.80000          18.4               195\n43     Adelie     Dream       36.00000          18.5               186\n44     Adelie     Dream       44.10000          19.7               196\n45     Adelie     Dream       37.00000          16.9               185\n46     Adelie     Dream       39.60000          18.8               190\n47     Adelie     Dream       41.10000          19.0               182\n48     Adelie     Dream       37.50000          18.9               179\n49     Adelie     Dream       36.00000          17.9               190\n50     Adelie     Dream       42.30000          21.2               191\n51     Adelie    Biscoe       39.60000          17.7               186\n52     Adelie    Biscoe       40.10000          18.9               188\n53     Adelie    Biscoe       35.00000          17.9               190\n54     Adelie    Biscoe       42.00000          19.5               200\n55     Adelie    Biscoe       34.50000          18.1               187\n56     Adelie    Biscoe       41.40000          18.6               191\n57     Adelie    Biscoe       39.00000          17.5               186\n58     Adelie    Biscoe       40.60000          18.8               193\n59     Adelie    Biscoe       36.50000          16.6               181\n60     Adelie    Biscoe       37.60000          19.1               194\n61     Adelie    Biscoe       35.70000          16.9               185\n62     Adelie    Biscoe       41.30000          21.1               195\n63     Adelie    Biscoe       37.60000          17.0               185\n64     Adelie    Biscoe       41.10000          18.2               192\n65     Adelie    Biscoe       36.40000          17.1               184\n66     Adelie    Biscoe       41.60000          18.0               192\n67     Adelie    Biscoe       35.50000          16.2               195\n68     Adelie    Biscoe       41.10000          19.1               188\n69     Adelie Torgersen       35.90000          16.6               190\n70     Adelie Torgersen       41.80000          19.4               198\n71     Adelie Torgersen       33.50000          19.0               190\n72     Adelie Torgersen       39.70000          18.4               190\n73     Adelie Torgersen       39.60000          17.2               196\n74     Adelie Torgersen       45.80000          18.9               197\n75     Adelie Torgersen       35.50000          17.5               190\n76     Adelie Torgersen       42.80000          18.5               195\n77     Adelie Torgersen       40.90000          16.8               191\n78     Adelie Torgersen       37.20000          19.4               184\n79     Adelie Torgersen       36.20000          16.1               187\n80     Adelie Torgersen       42.10000          19.1               195\n81     Adelie Torgersen       34.60000          17.2               189\n82     Adelie Torgersen       42.90000          17.6               196\n83     Adelie Torgersen       36.70000          18.8               187\n84     Adelie Torgersen       35.10000          19.4               193\n85     Adelie     Dream       37.30000          17.8               191\n86     Adelie     Dream       41.30000          20.3               194\n87     Adelie     Dream       36.30000          19.5               190\n88     Adelie     Dream       36.90000          18.6               189\n89     Adelie     Dream       38.30000          19.2               189\n90     Adelie     Dream       38.90000          18.8               190\n91     Adelie     Dream       35.70000          18.0               202\n92     Adelie     Dream       41.10000          18.1               205\n93     Adelie     Dream       34.00000          17.1               185\n94     Adelie     Dream       39.60000          18.1               186\n95     Adelie     Dream       36.20000          17.3               187\n96     Adelie     Dream       40.80000          18.9               208\n97     Adelie     Dream       38.10000          18.6               190\n98     Adelie     Dream       40.30000          18.5               196\n99     Adelie     Dream       33.10000          16.1               178\n100    Adelie     Dream       43.20000          18.5               192\n101    Adelie    Biscoe       35.00000          17.9               192\n102    Adelie    Biscoe       41.00000          20.0               203\n103    Adelie    Biscoe       37.70000          16.0               183\n104    Adelie    Biscoe       37.80000          20.0               190\n105    Adelie    Biscoe       37.90000          18.6               193\n106    Adelie    Biscoe       39.70000          18.9               184\n107    Adelie    Biscoe       38.60000          17.2               199\n108    Adelie    Biscoe       38.20000          20.0               190\n109    Adelie    Biscoe       38.10000          17.0               181\n110    Adelie    Biscoe       43.20000          19.0               197\n111    Adelie    Biscoe       38.10000          16.5               198\n112    Adelie    Biscoe       45.60000          20.3               191\n113    Adelie    Biscoe       39.70000          17.7               193\n114    Adelie    Biscoe       42.20000          19.5               197\n115    Adelie    Biscoe       39.60000          20.7               191\n116    Adelie    Biscoe       42.70000          18.3               196\n117    Adelie Torgersen       38.60000          17.0               188\n118    Adelie Torgersen       37.30000          20.5               199\n119    Adelie Torgersen       35.70000          17.0               189\n120    Adelie Torgersen       41.10000          18.6               189\n121    Adelie Torgersen       36.20000          17.2               187\n122    Adelie Torgersen       37.70000          19.8               198\n123    Adelie Torgersen       40.20000          17.0               176\n124    Adelie Torgersen       41.40000          18.5               202\n125    Adelie Torgersen       35.20000          15.9               186\n126    Adelie Torgersen       40.60000          19.0               199\n127    Adelie Torgersen       38.80000          17.6               191\n128    Adelie Torgersen       41.50000          18.3               195\n129    Adelie Torgersen       39.00000          17.1               191\n130    Adelie Torgersen       44.10000          18.0               210\n131    Adelie Torgersen       38.50000          17.9               190\n132    Adelie Torgersen       43.10000          19.2               197\n133    Adelie     Dream       36.80000          18.5               193\n134    Adelie     Dream       37.50000          18.5               199\n135    Adelie     Dream       38.10000          17.6               187\n136    Adelie     Dream       41.10000          17.5               190\n137    Adelie     Dream       35.60000          17.5               191\n138    Adelie     Dream       40.20000          20.1               200\n139    Adelie     Dream       37.00000          16.5               185\n140    Adelie     Dream       39.70000          17.9               193\n141    Adelie     Dream       40.20000          17.1               193\n142    Adelie     Dream       40.60000          17.2               187\n143    Adelie     Dream       32.10000          15.5               188\n144    Adelie     Dream       40.70000          17.0               190\n145    Adelie     Dream       37.30000          16.8               192\n146    Adelie     Dream       39.00000          18.7               185\n147    Adelie     Dream       39.20000          18.6               190\n148    Adelie     Dream       36.60000          18.4               184\n149    Adelie     Dream       36.00000          17.8               195\n150    Adelie     Dream       37.80000          18.1               193\n151    Adelie     Dream       36.00000          17.1               187\n152    Adelie     Dream       41.50000          18.5               201\n153    Gentoo    Biscoe       46.10000          13.2               211\n154    Gentoo    Biscoe       50.00000          16.3               230\n155    Gentoo    Biscoe       48.70000          14.1               210\n156    Gentoo    Biscoe       50.00000          15.2               218\n157    Gentoo    Biscoe       47.60000          14.5               215\n158    Gentoo    Biscoe       46.50000          13.5               210\n159    Gentoo    Biscoe       45.40000          14.6               211\n160    Gentoo    Biscoe       46.70000          15.3               219\n161    Gentoo    Biscoe       43.30000          13.4               209\n162    Gentoo    Biscoe       46.80000          15.4               215\n163    Gentoo    Biscoe       40.90000          13.7               214\n164    Gentoo    Biscoe       49.00000          16.1               216\n165    Gentoo    Biscoe       45.50000          13.7               214\n166    Gentoo    Biscoe       48.40000          14.6               213\n167    Gentoo    Biscoe       45.80000          14.6               210\n168    Gentoo    Biscoe       49.30000          15.7               217\n169    Gentoo    Biscoe       42.00000          13.5               210\n170    Gentoo    Biscoe       49.20000          15.2               221\n171    Gentoo    Biscoe       46.20000          14.5               209\n172    Gentoo    Biscoe       48.70000          15.1               222\n173    Gentoo    Biscoe       50.20000          14.3               218\n174    Gentoo    Biscoe       45.10000          14.5               215\n175    Gentoo    Biscoe       46.50000          14.5               213\n176    Gentoo    Biscoe       46.30000          15.8               215\n177    Gentoo    Biscoe       42.90000          13.1               215\n178    Gentoo    Biscoe       46.10000          15.1               215\n179    Gentoo    Biscoe       44.50000          14.3               216\n180    Gentoo    Biscoe       47.80000          15.0               215\n181    Gentoo    Biscoe       48.20000          14.3               210\n182    Gentoo    Biscoe       50.00000          15.3               220\n183    Gentoo    Biscoe       47.30000          15.3               222\n184    Gentoo    Biscoe       42.80000          14.2               209\n185    Gentoo    Biscoe       45.10000          14.5               207\n186    Gentoo    Biscoe       59.60000          17.0               230\n187    Gentoo    Biscoe       49.10000          14.8               220\n188    Gentoo    Biscoe       48.40000          16.3               220\n189    Gentoo    Biscoe       42.60000          13.7               213\n190    Gentoo    Biscoe       44.40000          17.3               219\n191    Gentoo    Biscoe       44.00000          13.6               208\n192    Gentoo    Biscoe       48.70000          15.7               208\n193    Gentoo    Biscoe       42.70000          13.7               208\n194    Gentoo    Biscoe       49.60000          16.0               225\n195    Gentoo    Biscoe       45.30000          13.7               210\n196    Gentoo    Biscoe       49.60000          15.0               216\n197    Gentoo    Biscoe       50.50000          15.9               222\n198    Gentoo    Biscoe       43.60000          13.9               217\n199    Gentoo    Biscoe       45.50000          13.9               210\n200    Gentoo    Biscoe       50.50000          15.9               225\n201    Gentoo    Biscoe       44.90000          13.3               213\n202    Gentoo    Biscoe       45.20000          15.8               215\n203    Gentoo    Biscoe       46.60000          14.2               210\n204    Gentoo    Biscoe       48.50000          14.1               220\n205    Gentoo    Biscoe       45.10000          14.4               210\n206    Gentoo    Biscoe       50.10000          15.0               225\n207    Gentoo    Biscoe       46.50000          14.4               217\n208    Gentoo    Biscoe       45.00000          15.4               220\n209    Gentoo    Biscoe       43.80000          13.9               208\n210    Gentoo    Biscoe       45.50000          15.0               220\n211    Gentoo    Biscoe       43.20000          14.5               208\n212    Gentoo    Biscoe       50.40000          15.3               224\n213    Gentoo    Biscoe       45.30000          13.8               208\n214    Gentoo    Biscoe       46.20000          14.9               221\n215    Gentoo    Biscoe       45.70000          13.9               214\n216    Gentoo    Biscoe       54.30000          15.7               231\n217    Gentoo    Biscoe       45.80000          14.2               219\n218    Gentoo    Biscoe       49.80000          16.8               230\n219    Gentoo    Biscoe       46.20000          14.4               214\n220    Gentoo    Biscoe       49.50000          16.2               229\n221    Gentoo    Biscoe       43.50000          14.2               220\n222    Gentoo    Biscoe       50.70000          15.0               223\n223    Gentoo    Biscoe       47.70000          15.0               216\n224    Gentoo    Biscoe       46.40000          15.6               221\n225    Gentoo    Biscoe       48.20000          15.6               221\n226    Gentoo    Biscoe       46.50000          14.8               217\n227    Gentoo    Biscoe       46.40000          15.0               216\n228    Gentoo    Biscoe       48.60000          16.0               230\n229    Gentoo    Biscoe       47.50000          14.2               209\n230    Gentoo    Biscoe       51.10000          16.3               220\n231    Gentoo    Biscoe       45.20000          13.8               215\n232    Gentoo    Biscoe       45.20000          16.4               223\n233    Gentoo    Biscoe       49.10000          14.5               212\n234    Gentoo    Biscoe       52.50000          15.6               221\n235    Gentoo    Biscoe       47.40000          14.6               212\n236    Gentoo    Biscoe       50.00000          15.9               224\n237    Gentoo    Biscoe       44.90000          13.8               212\n238    Gentoo    Biscoe       50.80000          17.3               228\n239    Gentoo    Biscoe       43.40000          14.4               218\n240    Gentoo    Biscoe       51.30000          14.2               218\n241    Gentoo    Biscoe       47.50000          14.0               212\n242    Gentoo    Biscoe       52.10000          17.0               230\n243    Gentoo    Biscoe       47.50000          15.0               218\n244    Gentoo    Biscoe       52.20000          17.1               228\n245    Gentoo    Biscoe       45.50000          14.5               212\n246    Gentoo    Biscoe       49.50000          16.1               224\n247    Gentoo    Biscoe       44.50000          14.7               214\n248    Gentoo    Biscoe       50.80000          15.7               226\n249    Gentoo    Biscoe       49.40000          15.8               216\n250    Gentoo    Biscoe       46.90000          14.6               222\n251    Gentoo    Biscoe       48.40000          14.4               203\n252    Gentoo    Biscoe       51.10000          16.5               225\n253    Gentoo    Biscoe       48.50000          15.0               219\n254    Gentoo    Biscoe       55.90000          17.0               228\n255    Gentoo    Biscoe       47.20000          15.5               215\n256    Gentoo    Biscoe       49.10000          15.0               228\n257    Gentoo    Biscoe       47.30000          13.8               216\n258    Gentoo    Biscoe       46.80000          16.1               215\n259    Gentoo    Biscoe       41.70000          14.7               210\n260    Gentoo    Biscoe       53.40000          15.8               219\n261    Gentoo    Biscoe       43.30000          14.0               208\n262    Gentoo    Biscoe       48.10000          15.1               209\n263    Gentoo    Biscoe       50.50000          15.2               216\n264    Gentoo    Biscoe       49.80000          15.9               229\n265    Gentoo    Biscoe       43.50000          15.2               213\n266    Gentoo    Biscoe       51.50000          16.3               230\n267    Gentoo    Biscoe       46.20000          14.1               217\n268    Gentoo    Biscoe       55.10000          16.0               230\n269    Gentoo    Biscoe       44.50000          15.7               217\n270    Gentoo    Biscoe       48.80000          16.2               222\n271    Gentoo    Biscoe       47.20000          13.7               214\n272    Gentoo    Biscoe       43.92193            NA                NA\n273    Gentoo    Biscoe       46.80000          14.3               215\n274    Gentoo    Biscoe       50.40000          15.7               222\n275    Gentoo    Biscoe       45.20000          14.8               212\n276    Gentoo    Biscoe       49.90000          16.1               213\n277 Chinstrap     Dream       46.50000          17.9               192\n278 Chinstrap     Dream       50.00000          19.5               196\n279 Chinstrap     Dream       51.30000          19.2               193\n280 Chinstrap     Dream       45.40000          18.7               188\n281 Chinstrap     Dream       52.70000          19.8               197\n282 Chinstrap     Dream       45.20000          17.8               198\n283 Chinstrap     Dream       46.10000          18.2               178\n284 Chinstrap     Dream       51.30000          18.2               197\n285 Chinstrap     Dream       46.00000          18.9               195\n286 Chinstrap     Dream       51.30000          19.9               198\n287 Chinstrap     Dream       46.60000          17.8               193\n288 Chinstrap     Dream       51.70000          20.3               194\n289 Chinstrap     Dream       47.00000          17.3               185\n290 Chinstrap     Dream       52.00000          18.1               201\n291 Chinstrap     Dream       45.90000          17.1               190\n292 Chinstrap     Dream       50.50000          19.6               201\n293 Chinstrap     Dream       50.30000          20.0               197\n294 Chinstrap     Dream       58.00000          17.8               181\n295 Chinstrap     Dream       46.40000          18.6               190\n296 Chinstrap     Dream       49.20000          18.2               195\n297 Chinstrap     Dream       42.40000          17.3               181\n298 Chinstrap     Dream       48.50000          17.5               191\n299 Chinstrap     Dream       43.20000          16.6               187\n300 Chinstrap     Dream       50.60000          19.4               193\n301 Chinstrap     Dream       46.70000          17.9               195\n302 Chinstrap     Dream       52.00000          19.0               197\n303 Chinstrap     Dream       50.50000          18.4               200\n304 Chinstrap     Dream       49.50000          19.0               200\n305 Chinstrap     Dream       46.40000          17.8               191\n306 Chinstrap     Dream       52.80000          20.0               205\n307 Chinstrap     Dream       40.90000          16.6               187\n308 Chinstrap     Dream       54.20000          20.8               201\n309 Chinstrap     Dream       42.50000          16.7               187\n310 Chinstrap     Dream       51.00000          18.8               203\n311 Chinstrap     Dream       49.70000          18.6               195\n312 Chinstrap     Dream       47.50000          16.8               199\n313 Chinstrap     Dream       47.60000          18.3               195\n314 Chinstrap     Dream       52.00000          20.7               210\n315 Chinstrap     Dream       46.90000          16.6               192\n316 Chinstrap     Dream       53.50000          19.9               205\n317 Chinstrap     Dream       49.00000          19.5               210\n318 Chinstrap     Dream       46.20000          17.5               187\n319 Chinstrap     Dream       50.90000          19.1               196\n320 Chinstrap     Dream       45.50000          17.0               196\n321 Chinstrap     Dream       50.90000          17.9               196\n322 Chinstrap     Dream       50.80000          18.5               201\n323 Chinstrap     Dream       50.10000          17.9               190\n324 Chinstrap     Dream       49.00000          19.6               212\n325 Chinstrap     Dream       51.50000          18.7               187\n326 Chinstrap     Dream       49.80000          17.3               198\n327 Chinstrap     Dream       48.10000          16.4               199\n328 Chinstrap     Dream       51.40000          19.0               201\n329 Chinstrap     Dream       45.70000          17.3               193\n330 Chinstrap     Dream       50.70000          19.7               203\n331 Chinstrap     Dream       42.50000          17.3               187\n332 Chinstrap     Dream       52.20000          18.8               197\n333 Chinstrap     Dream       45.20000          16.6               191\n334 Chinstrap     Dream       49.30000          19.9               203\n335 Chinstrap     Dream       50.20000          18.8               202\n336 Chinstrap     Dream       45.60000          19.4               194\n337 Chinstrap     Dream       51.90000          19.5               206\n338 Chinstrap     Dream       46.80000          16.5               189\n339 Chinstrap     Dream       45.70000          17.0               195\n340 Chinstrap     Dream       55.80000          19.8               207\n341 Chinstrap     Dream       43.50000          18.1               202\n342 Chinstrap     Dream       49.60000          18.2               193\n343 Chinstrap     Dream       50.80000          19.0               210\n344 Chinstrap     Dream       50.20000          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009"
  },
  {
    "objectID": "chapters/9999-Miscellaneous/R-Missing-Values.html#dealing-with-na-values",
    "href": "chapters/9999-Miscellaneous/R-Missing-Values.html#dealing-with-na-values",
    "title": "Missing Values",
    "section": "",
    "text": "Missing values are a common challenge in datasets. Let’s look at some examples for ways to work with them.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\ndf&lt;-data.frame(penguins)\ndf\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen           39.1          18.7               181\n2      Adelie Torgersen           39.5          17.4               186\n3      Adelie Torgersen           40.3          18.0               195\n4      Adelie Torgersen             NA            NA                NA\n5      Adelie Torgersen           36.7          19.3               193\n6      Adelie Torgersen           39.3          20.6               190\n7      Adelie Torgersen           38.9          17.8               181\n8      Adelie Torgersen           39.2          19.6               195\n9      Adelie Torgersen           34.1          18.1               193\n10     Adelie Torgersen           42.0          20.2               190\n11     Adelie Torgersen           37.8          17.1               186\n12     Adelie Torgersen           37.8          17.3               180\n13     Adelie Torgersen           41.1          17.6               182\n14     Adelie Torgersen           38.6          21.2               191\n15     Adelie Torgersen           34.6          21.1               198\n16     Adelie Torgersen           36.6          17.8               185\n17     Adelie Torgersen           38.7          19.0               195\n18     Adelie Torgersen           42.5          20.7               197\n19     Adelie Torgersen           34.4          18.4               184\n20     Adelie Torgersen           46.0          21.5               194\n21     Adelie    Biscoe           37.8          18.3               174\n22     Adelie    Biscoe           37.7          18.7               180\n23     Adelie    Biscoe           35.9          19.2               189\n24     Adelie    Biscoe           38.2          18.1               185\n25     Adelie    Biscoe           38.8          17.2               180\n26     Adelie    Biscoe           35.3          18.9               187\n27     Adelie    Biscoe           40.6          18.6               183\n28     Adelie    Biscoe           40.5          17.9               187\n29     Adelie    Biscoe           37.9          18.6               172\n30     Adelie    Biscoe           40.5          18.9               180\n31     Adelie     Dream           39.5          16.7               178\n32     Adelie     Dream           37.2          18.1               178\n33     Adelie     Dream           39.5          17.8               188\n34     Adelie     Dream           40.9          18.9               184\n35     Adelie     Dream           36.4          17.0               195\n36     Adelie     Dream           39.2          21.1               196\n37     Adelie     Dream           38.8          20.0               190\n38     Adelie     Dream           42.2          18.5               180\n39     Adelie     Dream           37.6          19.3               181\n40     Adelie     Dream           39.8          19.1               184\n41     Adelie     Dream           36.5          18.0               182\n42     Adelie     Dream           40.8          18.4               195\n43     Adelie     Dream           36.0          18.5               186\n44     Adelie     Dream           44.1          19.7               196\n45     Adelie     Dream           37.0          16.9               185\n46     Adelie     Dream           39.6          18.8               190\n47     Adelie     Dream           41.1          19.0               182\n48     Adelie     Dream           37.5          18.9               179\n49     Adelie     Dream           36.0          17.9               190\n50     Adelie     Dream           42.3          21.2               191\n51     Adelie    Biscoe           39.6          17.7               186\n52     Adelie    Biscoe           40.1          18.9               188\n53     Adelie    Biscoe           35.0          17.9               190\n54     Adelie    Biscoe           42.0          19.5               200\n55     Adelie    Biscoe           34.5          18.1               187\n56     Adelie    Biscoe           41.4          18.6               191\n57     Adelie    Biscoe           39.0          17.5               186\n58     Adelie    Biscoe           40.6          18.8               193\n59     Adelie    Biscoe           36.5          16.6               181\n60     Adelie    Biscoe           37.6          19.1               194\n61     Adelie    Biscoe           35.7          16.9               185\n62     Adelie    Biscoe           41.3          21.1               195\n63     Adelie    Biscoe           37.6          17.0               185\n64     Adelie    Biscoe           41.1          18.2               192\n65     Adelie    Biscoe           36.4          17.1               184\n66     Adelie    Biscoe           41.6          18.0               192\n67     Adelie    Biscoe           35.5          16.2               195\n68     Adelie    Biscoe           41.1          19.1               188\n69     Adelie Torgersen           35.9          16.6               190\n70     Adelie Torgersen           41.8          19.4               198\n71     Adelie Torgersen           33.5          19.0               190\n72     Adelie Torgersen           39.7          18.4               190\n73     Adelie Torgersen           39.6          17.2               196\n74     Adelie Torgersen           45.8          18.9               197\n75     Adelie Torgersen           35.5          17.5               190\n76     Adelie Torgersen           42.8          18.5               195\n77     Adelie Torgersen           40.9          16.8               191\n78     Adelie Torgersen           37.2          19.4               184\n79     Adelie Torgersen           36.2          16.1               187\n80     Adelie Torgersen           42.1          19.1               195\n81     Adelie Torgersen           34.6          17.2               189\n82     Adelie Torgersen           42.9          17.6               196\n83     Adelie Torgersen           36.7          18.8               187\n84     Adelie Torgersen           35.1          19.4               193\n85     Adelie     Dream           37.3          17.8               191\n86     Adelie     Dream           41.3          20.3               194\n87     Adelie     Dream           36.3          19.5               190\n88     Adelie     Dream           36.9          18.6               189\n89     Adelie     Dream           38.3          19.2               189\n90     Adelie     Dream           38.9          18.8               190\n91     Adelie     Dream           35.7          18.0               202\n92     Adelie     Dream           41.1          18.1               205\n93     Adelie     Dream           34.0          17.1               185\n94     Adelie     Dream           39.6          18.1               186\n95     Adelie     Dream           36.2          17.3               187\n96     Adelie     Dream           40.8          18.9               208\n97     Adelie     Dream           38.1          18.6               190\n98     Adelie     Dream           40.3          18.5               196\n99     Adelie     Dream           33.1          16.1               178\n100    Adelie     Dream           43.2          18.5               192\n101    Adelie    Biscoe           35.0          17.9               192\n102    Adelie    Biscoe           41.0          20.0               203\n103    Adelie    Biscoe           37.7          16.0               183\n104    Adelie    Biscoe           37.8          20.0               190\n105    Adelie    Biscoe           37.9          18.6               193\n106    Adelie    Biscoe           39.7          18.9               184\n107    Adelie    Biscoe           38.6          17.2               199\n108    Adelie    Biscoe           38.2          20.0               190\n109    Adelie    Biscoe           38.1          17.0               181\n110    Adelie    Biscoe           43.2          19.0               197\n111    Adelie    Biscoe           38.1          16.5               198\n112    Adelie    Biscoe           45.6          20.3               191\n113    Adelie    Biscoe           39.7          17.7               193\n114    Adelie    Biscoe           42.2          19.5               197\n115    Adelie    Biscoe           39.6          20.7               191\n116    Adelie    Biscoe           42.7          18.3               196\n117    Adelie Torgersen           38.6          17.0               188\n118    Adelie Torgersen           37.3          20.5               199\n119    Adelie Torgersen           35.7          17.0               189\n120    Adelie Torgersen           41.1          18.6               189\n121    Adelie Torgersen           36.2          17.2               187\n122    Adelie Torgersen           37.7          19.8               198\n123    Adelie Torgersen           40.2          17.0               176\n124    Adelie Torgersen           41.4          18.5               202\n125    Adelie Torgersen           35.2          15.9               186\n126    Adelie Torgersen           40.6          19.0               199\n127    Adelie Torgersen           38.8          17.6               191\n128    Adelie Torgersen           41.5          18.3               195\n129    Adelie Torgersen           39.0          17.1               191\n130    Adelie Torgersen           44.1          18.0               210\n131    Adelie Torgersen           38.5          17.9               190\n132    Adelie Torgersen           43.1          19.2               197\n133    Adelie     Dream           36.8          18.5               193\n134    Adelie     Dream           37.5          18.5               199\n135    Adelie     Dream           38.1          17.6               187\n136    Adelie     Dream           41.1          17.5               190\n137    Adelie     Dream           35.6          17.5               191\n138    Adelie     Dream           40.2          20.1               200\n139    Adelie     Dream           37.0          16.5               185\n140    Adelie     Dream           39.7          17.9               193\n141    Adelie     Dream           40.2          17.1               193\n142    Adelie     Dream           40.6          17.2               187\n143    Adelie     Dream           32.1          15.5               188\n144    Adelie     Dream           40.7          17.0               190\n145    Adelie     Dream           37.3          16.8               192\n146    Adelie     Dream           39.0          18.7               185\n147    Adelie     Dream           39.2          18.6               190\n148    Adelie     Dream           36.6          18.4               184\n149    Adelie     Dream           36.0          17.8               195\n150    Adelie     Dream           37.8          18.1               193\n151    Adelie     Dream           36.0          17.1               187\n152    Adelie     Dream           41.5          18.5               201\n153    Gentoo    Biscoe           46.1          13.2               211\n154    Gentoo    Biscoe           50.0          16.3               230\n155    Gentoo    Biscoe           48.7          14.1               210\n156    Gentoo    Biscoe           50.0          15.2               218\n157    Gentoo    Biscoe           47.6          14.5               215\n158    Gentoo    Biscoe           46.5          13.5               210\n159    Gentoo    Biscoe           45.4          14.6               211\n160    Gentoo    Biscoe           46.7          15.3               219\n161    Gentoo    Biscoe           43.3          13.4               209\n162    Gentoo    Biscoe           46.8          15.4               215\n163    Gentoo    Biscoe           40.9          13.7               214\n164    Gentoo    Biscoe           49.0          16.1               216\n165    Gentoo    Biscoe           45.5          13.7               214\n166    Gentoo    Biscoe           48.4          14.6               213\n167    Gentoo    Biscoe           45.8          14.6               210\n168    Gentoo    Biscoe           49.3          15.7               217\n169    Gentoo    Biscoe           42.0          13.5               210\n170    Gentoo    Biscoe           49.2          15.2               221\n171    Gentoo    Biscoe           46.2          14.5               209\n172    Gentoo    Biscoe           48.7          15.1               222\n173    Gentoo    Biscoe           50.2          14.3               218\n174    Gentoo    Biscoe           45.1          14.5               215\n175    Gentoo    Biscoe           46.5          14.5               213\n176    Gentoo    Biscoe           46.3          15.8               215\n177    Gentoo    Biscoe           42.9          13.1               215\n178    Gentoo    Biscoe           46.1          15.1               215\n179    Gentoo    Biscoe           44.5          14.3               216\n180    Gentoo    Biscoe           47.8          15.0               215\n181    Gentoo    Biscoe           48.2          14.3               210\n182    Gentoo    Biscoe           50.0          15.3               220\n183    Gentoo    Biscoe           47.3          15.3               222\n184    Gentoo    Biscoe           42.8          14.2               209\n185    Gentoo    Biscoe           45.1          14.5               207\n186    Gentoo    Biscoe           59.6          17.0               230\n187    Gentoo    Biscoe           49.1          14.8               220\n188    Gentoo    Biscoe           48.4          16.3               220\n189    Gentoo    Biscoe           42.6          13.7               213\n190    Gentoo    Biscoe           44.4          17.3               219\n191    Gentoo    Biscoe           44.0          13.6               208\n192    Gentoo    Biscoe           48.7          15.7               208\n193    Gentoo    Biscoe           42.7          13.7               208\n194    Gentoo    Biscoe           49.6          16.0               225\n195    Gentoo    Biscoe           45.3          13.7               210\n196    Gentoo    Biscoe           49.6          15.0               216\n197    Gentoo    Biscoe           50.5          15.9               222\n198    Gentoo    Biscoe           43.6          13.9               217\n199    Gentoo    Biscoe           45.5          13.9               210\n200    Gentoo    Biscoe           50.5          15.9               225\n201    Gentoo    Biscoe           44.9          13.3               213\n202    Gentoo    Biscoe           45.2          15.8               215\n203    Gentoo    Biscoe           46.6          14.2               210\n204    Gentoo    Biscoe           48.5          14.1               220\n205    Gentoo    Biscoe           45.1          14.4               210\n206    Gentoo    Biscoe           50.1          15.0               225\n207    Gentoo    Biscoe           46.5          14.4               217\n208    Gentoo    Biscoe           45.0          15.4               220\n209    Gentoo    Biscoe           43.8          13.9               208\n210    Gentoo    Biscoe           45.5          15.0               220\n211    Gentoo    Biscoe           43.2          14.5               208\n212    Gentoo    Biscoe           50.4          15.3               224\n213    Gentoo    Biscoe           45.3          13.8               208\n214    Gentoo    Biscoe           46.2          14.9               221\n215    Gentoo    Biscoe           45.7          13.9               214\n216    Gentoo    Biscoe           54.3          15.7               231\n217    Gentoo    Biscoe           45.8          14.2               219\n218    Gentoo    Biscoe           49.8          16.8               230\n219    Gentoo    Biscoe           46.2          14.4               214\n220    Gentoo    Biscoe           49.5          16.2               229\n221    Gentoo    Biscoe           43.5          14.2               220\n222    Gentoo    Biscoe           50.7          15.0               223\n223    Gentoo    Biscoe           47.7          15.0               216\n224    Gentoo    Biscoe           46.4          15.6               221\n225    Gentoo    Biscoe           48.2          15.6               221\n226    Gentoo    Biscoe           46.5          14.8               217\n227    Gentoo    Biscoe           46.4          15.0               216\n228    Gentoo    Biscoe           48.6          16.0               230\n229    Gentoo    Biscoe           47.5          14.2               209\n230    Gentoo    Biscoe           51.1          16.3               220\n231    Gentoo    Biscoe           45.2          13.8               215\n232    Gentoo    Biscoe           45.2          16.4               223\n233    Gentoo    Biscoe           49.1          14.5               212\n234    Gentoo    Biscoe           52.5          15.6               221\n235    Gentoo    Biscoe           47.4          14.6               212\n236    Gentoo    Biscoe           50.0          15.9               224\n237    Gentoo    Biscoe           44.9          13.8               212\n238    Gentoo    Biscoe           50.8          17.3               228\n239    Gentoo    Biscoe           43.4          14.4               218\n240    Gentoo    Biscoe           51.3          14.2               218\n241    Gentoo    Biscoe           47.5          14.0               212\n242    Gentoo    Biscoe           52.1          17.0               230\n243    Gentoo    Biscoe           47.5          15.0               218\n244    Gentoo    Biscoe           52.2          17.1               228\n245    Gentoo    Biscoe           45.5          14.5               212\n246    Gentoo    Biscoe           49.5          16.1               224\n247    Gentoo    Biscoe           44.5          14.7               214\n248    Gentoo    Biscoe           50.8          15.7               226\n249    Gentoo    Biscoe           49.4          15.8               216\n250    Gentoo    Biscoe           46.9          14.6               222\n251    Gentoo    Biscoe           48.4          14.4               203\n252    Gentoo    Biscoe           51.1          16.5               225\n253    Gentoo    Biscoe           48.5          15.0               219\n254    Gentoo    Biscoe           55.9          17.0               228\n255    Gentoo    Biscoe           47.2          15.5               215\n256    Gentoo    Biscoe           49.1          15.0               228\n257    Gentoo    Biscoe           47.3          13.8               216\n258    Gentoo    Biscoe           46.8          16.1               215\n259    Gentoo    Biscoe           41.7          14.7               210\n260    Gentoo    Biscoe           53.4          15.8               219\n261    Gentoo    Biscoe           43.3          14.0               208\n262    Gentoo    Biscoe           48.1          15.1               209\n263    Gentoo    Biscoe           50.5          15.2               216\n264    Gentoo    Biscoe           49.8          15.9               229\n265    Gentoo    Biscoe           43.5          15.2               213\n266    Gentoo    Biscoe           51.5          16.3               230\n267    Gentoo    Biscoe           46.2          14.1               217\n268    Gentoo    Biscoe           55.1          16.0               230\n269    Gentoo    Biscoe           44.5          15.7               217\n270    Gentoo    Biscoe           48.8          16.2               222\n271    Gentoo    Biscoe           47.2          13.7               214\n272    Gentoo    Biscoe             NA            NA                NA\n273    Gentoo    Biscoe           46.8          14.3               215\n274    Gentoo    Biscoe           50.4          15.7               222\n275    Gentoo    Biscoe           45.2          14.8               212\n276    Gentoo    Biscoe           49.9          16.1               213\n277 Chinstrap     Dream           46.5          17.9               192\n278 Chinstrap     Dream           50.0          19.5               196\n279 Chinstrap     Dream           51.3          19.2               193\n280 Chinstrap     Dream           45.4          18.7               188\n281 Chinstrap     Dream           52.7          19.8               197\n282 Chinstrap     Dream           45.2          17.8               198\n283 Chinstrap     Dream           46.1          18.2               178\n284 Chinstrap     Dream           51.3          18.2               197\n285 Chinstrap     Dream           46.0          18.9               195\n286 Chinstrap     Dream           51.3          19.9               198\n287 Chinstrap     Dream           46.6          17.8               193\n288 Chinstrap     Dream           51.7          20.3               194\n289 Chinstrap     Dream           47.0          17.3               185\n290 Chinstrap     Dream           52.0          18.1               201\n291 Chinstrap     Dream           45.9          17.1               190\n292 Chinstrap     Dream           50.5          19.6               201\n293 Chinstrap     Dream           50.3          20.0               197\n294 Chinstrap     Dream           58.0          17.8               181\n295 Chinstrap     Dream           46.4          18.6               190\n296 Chinstrap     Dream           49.2          18.2               195\n297 Chinstrap     Dream           42.4          17.3               181\n298 Chinstrap     Dream           48.5          17.5               191\n299 Chinstrap     Dream           43.2          16.6               187\n300 Chinstrap     Dream           50.6          19.4               193\n301 Chinstrap     Dream           46.7          17.9               195\n302 Chinstrap     Dream           52.0          19.0               197\n303 Chinstrap     Dream           50.5          18.4               200\n304 Chinstrap     Dream           49.5          19.0               200\n305 Chinstrap     Dream           46.4          17.8               191\n306 Chinstrap     Dream           52.8          20.0               205\n307 Chinstrap     Dream           40.9          16.6               187\n308 Chinstrap     Dream           54.2          20.8               201\n309 Chinstrap     Dream           42.5          16.7               187\n310 Chinstrap     Dream           51.0          18.8               203\n311 Chinstrap     Dream           49.7          18.6               195\n312 Chinstrap     Dream           47.5          16.8               199\n313 Chinstrap     Dream           47.6          18.3               195\n314 Chinstrap     Dream           52.0          20.7               210\n315 Chinstrap     Dream           46.9          16.6               192\n316 Chinstrap     Dream           53.5          19.9               205\n317 Chinstrap     Dream           49.0          19.5               210\n318 Chinstrap     Dream           46.2          17.5               187\n319 Chinstrap     Dream           50.9          19.1               196\n320 Chinstrap     Dream           45.5          17.0               196\n321 Chinstrap     Dream           50.9          17.9               196\n322 Chinstrap     Dream           50.8          18.5               201\n323 Chinstrap     Dream           50.1          17.9               190\n324 Chinstrap     Dream           49.0          19.6               212\n325 Chinstrap     Dream           51.5          18.7               187\n326 Chinstrap     Dream           49.8          17.3               198\n327 Chinstrap     Dream           48.1          16.4               199\n328 Chinstrap     Dream           51.4          19.0               201\n329 Chinstrap     Dream           45.7          17.3               193\n330 Chinstrap     Dream           50.7          19.7               203\n331 Chinstrap     Dream           42.5          17.3               187\n332 Chinstrap     Dream           52.2          18.8               197\n333 Chinstrap     Dream           45.2          16.6               191\n334 Chinstrap     Dream           49.3          19.9               203\n335 Chinstrap     Dream           50.2          18.8               202\n336 Chinstrap     Dream           45.6          19.4               194\n337 Chinstrap     Dream           51.9          19.5               206\n338 Chinstrap     Dream           46.8          16.5               189\n339 Chinstrap     Dream           45.7          17.0               195\n340 Chinstrap     Dream           55.8          19.8               207\n341 Chinstrap     Dream           43.5          18.1               202\n342 Chinstrap     Dream           49.6          18.2               193\n343 Chinstrap     Dream           50.8          19.0               210\n344 Chinstrap     Dream           50.2          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009\n\n\nFirst, let’s see how many NA values are in each column.\n\ncolSums(is.na(df))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\nNA values affect numerical calculations\n\nmean(df$bill_length_mm)\n\n[1] NA\n\n\nWe can tell the mean function (and other functions) how to handle NA.\n\nmean(df$bill_length_mm,na.rm=T)\n\n[1] 43.92193\n\n\nWe can leave out rows with NA values.\n\ndf_no_na &lt;- na.omit(df)\ncolSums(is.na(df_no_na))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 0                 0 \nflipper_length_mm       body_mass_g               sex              year \n                0                 0                 0                 0 \n\n\nWe can also replace NA with something. This function comes from the tidyverse library which we added above.\n\nreplace_na(df,list(bill_length_mm=mean(df$bill_length_mm,na.rm=T)))\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen       39.10000          18.7               181\n2      Adelie Torgersen       39.50000          17.4               186\n3      Adelie Torgersen       40.30000          18.0               195\n4      Adelie Torgersen       43.92193            NA                NA\n5      Adelie Torgersen       36.70000          19.3               193\n6      Adelie Torgersen       39.30000          20.6               190\n7      Adelie Torgersen       38.90000          17.8               181\n8      Adelie Torgersen       39.20000          19.6               195\n9      Adelie Torgersen       34.10000          18.1               193\n10     Adelie Torgersen       42.00000          20.2               190\n11     Adelie Torgersen       37.80000          17.1               186\n12     Adelie Torgersen       37.80000          17.3               180\n13     Adelie Torgersen       41.10000          17.6               182\n14     Adelie Torgersen       38.60000          21.2               191\n15     Adelie Torgersen       34.60000          21.1               198\n16     Adelie Torgersen       36.60000          17.8               185\n17     Adelie Torgersen       38.70000          19.0               195\n18     Adelie Torgersen       42.50000          20.7               197\n19     Adelie Torgersen       34.40000          18.4               184\n20     Adelie Torgersen       46.00000          21.5               194\n21     Adelie    Biscoe       37.80000          18.3               174\n22     Adelie    Biscoe       37.70000          18.7               180\n23     Adelie    Biscoe       35.90000          19.2               189\n24     Adelie    Biscoe       38.20000          18.1               185\n25     Adelie    Biscoe       38.80000          17.2               180\n26     Adelie    Biscoe       35.30000          18.9               187\n27     Adelie    Biscoe       40.60000          18.6               183\n28     Adelie    Biscoe       40.50000          17.9               187\n29     Adelie    Biscoe       37.90000          18.6               172\n30     Adelie    Biscoe       40.50000          18.9               180\n31     Adelie     Dream       39.50000          16.7               178\n32     Adelie     Dream       37.20000          18.1               178\n33     Adelie     Dream       39.50000          17.8               188\n34     Adelie     Dream       40.90000          18.9               184\n35     Adelie     Dream       36.40000          17.0               195\n36     Adelie     Dream       39.20000          21.1               196\n37     Adelie     Dream       38.80000          20.0               190\n38     Adelie     Dream       42.20000          18.5               180\n39     Adelie     Dream       37.60000          19.3               181\n40     Adelie     Dream       39.80000          19.1               184\n41     Adelie     Dream       36.50000          18.0               182\n42     Adelie     Dream       40.80000          18.4               195\n43     Adelie     Dream       36.00000          18.5               186\n44     Adelie     Dream       44.10000          19.7               196\n45     Adelie     Dream       37.00000          16.9               185\n46     Adelie     Dream       39.60000          18.8               190\n47     Adelie     Dream       41.10000          19.0               182\n48     Adelie     Dream       37.50000          18.9               179\n49     Adelie     Dream       36.00000          17.9               190\n50     Adelie     Dream       42.30000          21.2               191\n51     Adelie    Biscoe       39.60000          17.7               186\n52     Adelie    Biscoe       40.10000          18.9               188\n53     Adelie    Biscoe       35.00000          17.9               190\n54     Adelie    Biscoe       42.00000          19.5               200\n55     Adelie    Biscoe       34.50000          18.1               187\n56     Adelie    Biscoe       41.40000          18.6               191\n57     Adelie    Biscoe       39.00000          17.5               186\n58     Adelie    Biscoe       40.60000          18.8               193\n59     Adelie    Biscoe       36.50000          16.6               181\n60     Adelie    Biscoe       37.60000          19.1               194\n61     Adelie    Biscoe       35.70000          16.9               185\n62     Adelie    Biscoe       41.30000          21.1               195\n63     Adelie    Biscoe       37.60000          17.0               185\n64     Adelie    Biscoe       41.10000          18.2               192\n65     Adelie    Biscoe       36.40000          17.1               184\n66     Adelie    Biscoe       41.60000          18.0               192\n67     Adelie    Biscoe       35.50000          16.2               195\n68     Adelie    Biscoe       41.10000          19.1               188\n69     Adelie Torgersen       35.90000          16.6               190\n70     Adelie Torgersen       41.80000          19.4               198\n71     Adelie Torgersen       33.50000          19.0               190\n72     Adelie Torgersen       39.70000          18.4               190\n73     Adelie Torgersen       39.60000          17.2               196\n74     Adelie Torgersen       45.80000          18.9               197\n75     Adelie Torgersen       35.50000          17.5               190\n76     Adelie Torgersen       42.80000          18.5               195\n77     Adelie Torgersen       40.90000          16.8               191\n78     Adelie Torgersen       37.20000          19.4               184\n79     Adelie Torgersen       36.20000          16.1               187\n80     Adelie Torgersen       42.10000          19.1               195\n81     Adelie Torgersen       34.60000          17.2               189\n82     Adelie Torgersen       42.90000          17.6               196\n83     Adelie Torgersen       36.70000          18.8               187\n84     Adelie Torgersen       35.10000          19.4               193\n85     Adelie     Dream       37.30000          17.8               191\n86     Adelie     Dream       41.30000          20.3               194\n87     Adelie     Dream       36.30000          19.5               190\n88     Adelie     Dream       36.90000          18.6               189\n89     Adelie     Dream       38.30000          19.2               189\n90     Adelie     Dream       38.90000          18.8               190\n91     Adelie     Dream       35.70000          18.0               202\n92     Adelie     Dream       41.10000          18.1               205\n93     Adelie     Dream       34.00000          17.1               185\n94     Adelie     Dream       39.60000          18.1               186\n95     Adelie     Dream       36.20000          17.3               187\n96     Adelie     Dream       40.80000          18.9               208\n97     Adelie     Dream       38.10000          18.6               190\n98     Adelie     Dream       40.30000          18.5               196\n99     Adelie     Dream       33.10000          16.1               178\n100    Adelie     Dream       43.20000          18.5               192\n101    Adelie    Biscoe       35.00000          17.9               192\n102    Adelie    Biscoe       41.00000          20.0               203\n103    Adelie    Biscoe       37.70000          16.0               183\n104    Adelie    Biscoe       37.80000          20.0               190\n105    Adelie    Biscoe       37.90000          18.6               193\n106    Adelie    Biscoe       39.70000          18.9               184\n107    Adelie    Biscoe       38.60000          17.2               199\n108    Adelie    Biscoe       38.20000          20.0               190\n109    Adelie    Biscoe       38.10000          17.0               181\n110    Adelie    Biscoe       43.20000          19.0               197\n111    Adelie    Biscoe       38.10000          16.5               198\n112    Adelie    Biscoe       45.60000          20.3               191\n113    Adelie    Biscoe       39.70000          17.7               193\n114    Adelie    Biscoe       42.20000          19.5               197\n115    Adelie    Biscoe       39.60000          20.7               191\n116    Adelie    Biscoe       42.70000          18.3               196\n117    Adelie Torgersen       38.60000          17.0               188\n118    Adelie Torgersen       37.30000          20.5               199\n119    Adelie Torgersen       35.70000          17.0               189\n120    Adelie Torgersen       41.10000          18.6               189\n121    Adelie Torgersen       36.20000          17.2               187\n122    Adelie Torgersen       37.70000          19.8               198\n123    Adelie Torgersen       40.20000          17.0               176\n124    Adelie Torgersen       41.40000          18.5               202\n125    Adelie Torgersen       35.20000          15.9               186\n126    Adelie Torgersen       40.60000          19.0               199\n127    Adelie Torgersen       38.80000          17.6               191\n128    Adelie Torgersen       41.50000          18.3               195\n129    Adelie Torgersen       39.00000          17.1               191\n130    Adelie Torgersen       44.10000          18.0               210\n131    Adelie Torgersen       38.50000          17.9               190\n132    Adelie Torgersen       43.10000          19.2               197\n133    Adelie     Dream       36.80000          18.5               193\n134    Adelie     Dream       37.50000          18.5               199\n135    Adelie     Dream       38.10000          17.6               187\n136    Adelie     Dream       41.10000          17.5               190\n137    Adelie     Dream       35.60000          17.5               191\n138    Adelie     Dream       40.20000          20.1               200\n139    Adelie     Dream       37.00000          16.5               185\n140    Adelie     Dream       39.70000          17.9               193\n141    Adelie     Dream       40.20000          17.1               193\n142    Adelie     Dream       40.60000          17.2               187\n143    Adelie     Dream       32.10000          15.5               188\n144    Adelie     Dream       40.70000          17.0               190\n145    Adelie     Dream       37.30000          16.8               192\n146    Adelie     Dream       39.00000          18.7               185\n147    Adelie     Dream       39.20000          18.6               190\n148    Adelie     Dream       36.60000          18.4               184\n149    Adelie     Dream       36.00000          17.8               195\n150    Adelie     Dream       37.80000          18.1               193\n151    Adelie     Dream       36.00000          17.1               187\n152    Adelie     Dream       41.50000          18.5               201\n153    Gentoo    Biscoe       46.10000          13.2               211\n154    Gentoo    Biscoe       50.00000          16.3               230\n155    Gentoo    Biscoe       48.70000          14.1               210\n156    Gentoo    Biscoe       50.00000          15.2               218\n157    Gentoo    Biscoe       47.60000          14.5               215\n158    Gentoo    Biscoe       46.50000          13.5               210\n159    Gentoo    Biscoe       45.40000          14.6               211\n160    Gentoo    Biscoe       46.70000          15.3               219\n161    Gentoo    Biscoe       43.30000          13.4               209\n162    Gentoo    Biscoe       46.80000          15.4               215\n163    Gentoo    Biscoe       40.90000          13.7               214\n164    Gentoo    Biscoe       49.00000          16.1               216\n165    Gentoo    Biscoe       45.50000          13.7               214\n166    Gentoo    Biscoe       48.40000          14.6               213\n167    Gentoo    Biscoe       45.80000          14.6               210\n168    Gentoo    Biscoe       49.30000          15.7               217\n169    Gentoo    Biscoe       42.00000          13.5               210\n170    Gentoo    Biscoe       49.20000          15.2               221\n171    Gentoo    Biscoe       46.20000          14.5               209\n172    Gentoo    Biscoe       48.70000          15.1               222\n173    Gentoo    Biscoe       50.20000          14.3               218\n174    Gentoo    Biscoe       45.10000          14.5               215\n175    Gentoo    Biscoe       46.50000          14.5               213\n176    Gentoo    Biscoe       46.30000          15.8               215\n177    Gentoo    Biscoe       42.90000          13.1               215\n178    Gentoo    Biscoe       46.10000          15.1               215\n179    Gentoo    Biscoe       44.50000          14.3               216\n180    Gentoo    Biscoe       47.80000          15.0               215\n181    Gentoo    Biscoe       48.20000          14.3               210\n182    Gentoo    Biscoe       50.00000          15.3               220\n183    Gentoo    Biscoe       47.30000          15.3               222\n184    Gentoo    Biscoe       42.80000          14.2               209\n185    Gentoo    Biscoe       45.10000          14.5               207\n186    Gentoo    Biscoe       59.60000          17.0               230\n187    Gentoo    Biscoe       49.10000          14.8               220\n188    Gentoo    Biscoe       48.40000          16.3               220\n189    Gentoo    Biscoe       42.60000          13.7               213\n190    Gentoo    Biscoe       44.40000          17.3               219\n191    Gentoo    Biscoe       44.00000          13.6               208\n192    Gentoo    Biscoe       48.70000          15.7               208\n193    Gentoo    Biscoe       42.70000          13.7               208\n194    Gentoo    Biscoe       49.60000          16.0               225\n195    Gentoo    Biscoe       45.30000          13.7               210\n196    Gentoo    Biscoe       49.60000          15.0               216\n197    Gentoo    Biscoe       50.50000          15.9               222\n198    Gentoo    Biscoe       43.60000          13.9               217\n199    Gentoo    Biscoe       45.50000          13.9               210\n200    Gentoo    Biscoe       50.50000          15.9               225\n201    Gentoo    Biscoe       44.90000          13.3               213\n202    Gentoo    Biscoe       45.20000          15.8               215\n203    Gentoo    Biscoe       46.60000          14.2               210\n204    Gentoo    Biscoe       48.50000          14.1               220\n205    Gentoo    Biscoe       45.10000          14.4               210\n206    Gentoo    Biscoe       50.10000          15.0               225\n207    Gentoo    Biscoe       46.50000          14.4               217\n208    Gentoo    Biscoe       45.00000          15.4               220\n209    Gentoo    Biscoe       43.80000          13.9               208\n210    Gentoo    Biscoe       45.50000          15.0               220\n211    Gentoo    Biscoe       43.20000          14.5               208\n212    Gentoo    Biscoe       50.40000          15.3               224\n213    Gentoo    Biscoe       45.30000          13.8               208\n214    Gentoo    Biscoe       46.20000          14.9               221\n215    Gentoo    Biscoe       45.70000          13.9               214\n216    Gentoo    Biscoe       54.30000          15.7               231\n217    Gentoo    Biscoe       45.80000          14.2               219\n218    Gentoo    Biscoe       49.80000          16.8               230\n219    Gentoo    Biscoe       46.20000          14.4               214\n220    Gentoo    Biscoe       49.50000          16.2               229\n221    Gentoo    Biscoe       43.50000          14.2               220\n222    Gentoo    Biscoe       50.70000          15.0               223\n223    Gentoo    Biscoe       47.70000          15.0               216\n224    Gentoo    Biscoe       46.40000          15.6               221\n225    Gentoo    Biscoe       48.20000          15.6               221\n226    Gentoo    Biscoe       46.50000          14.8               217\n227    Gentoo    Biscoe       46.40000          15.0               216\n228    Gentoo    Biscoe       48.60000          16.0               230\n229    Gentoo    Biscoe       47.50000          14.2               209\n230    Gentoo    Biscoe       51.10000          16.3               220\n231    Gentoo    Biscoe       45.20000          13.8               215\n232    Gentoo    Biscoe       45.20000          16.4               223\n233    Gentoo    Biscoe       49.10000          14.5               212\n234    Gentoo    Biscoe       52.50000          15.6               221\n235    Gentoo    Biscoe       47.40000          14.6               212\n236    Gentoo    Biscoe       50.00000          15.9               224\n237    Gentoo    Biscoe       44.90000          13.8               212\n238    Gentoo    Biscoe       50.80000          17.3               228\n239    Gentoo    Biscoe       43.40000          14.4               218\n240    Gentoo    Biscoe       51.30000          14.2               218\n241    Gentoo    Biscoe       47.50000          14.0               212\n242    Gentoo    Biscoe       52.10000          17.0               230\n243    Gentoo    Biscoe       47.50000          15.0               218\n244    Gentoo    Biscoe       52.20000          17.1               228\n245    Gentoo    Biscoe       45.50000          14.5               212\n246    Gentoo    Biscoe       49.50000          16.1               224\n247    Gentoo    Biscoe       44.50000          14.7               214\n248    Gentoo    Biscoe       50.80000          15.7               226\n249    Gentoo    Biscoe       49.40000          15.8               216\n250    Gentoo    Biscoe       46.90000          14.6               222\n251    Gentoo    Biscoe       48.40000          14.4               203\n252    Gentoo    Biscoe       51.10000          16.5               225\n253    Gentoo    Biscoe       48.50000          15.0               219\n254    Gentoo    Biscoe       55.90000          17.0               228\n255    Gentoo    Biscoe       47.20000          15.5               215\n256    Gentoo    Biscoe       49.10000          15.0               228\n257    Gentoo    Biscoe       47.30000          13.8               216\n258    Gentoo    Biscoe       46.80000          16.1               215\n259    Gentoo    Biscoe       41.70000          14.7               210\n260    Gentoo    Biscoe       53.40000          15.8               219\n261    Gentoo    Biscoe       43.30000          14.0               208\n262    Gentoo    Biscoe       48.10000          15.1               209\n263    Gentoo    Biscoe       50.50000          15.2               216\n264    Gentoo    Biscoe       49.80000          15.9               229\n265    Gentoo    Biscoe       43.50000          15.2               213\n266    Gentoo    Biscoe       51.50000          16.3               230\n267    Gentoo    Biscoe       46.20000          14.1               217\n268    Gentoo    Biscoe       55.10000          16.0               230\n269    Gentoo    Biscoe       44.50000          15.7               217\n270    Gentoo    Biscoe       48.80000          16.2               222\n271    Gentoo    Biscoe       47.20000          13.7               214\n272    Gentoo    Biscoe       43.92193            NA                NA\n273    Gentoo    Biscoe       46.80000          14.3               215\n274    Gentoo    Biscoe       50.40000          15.7               222\n275    Gentoo    Biscoe       45.20000          14.8               212\n276    Gentoo    Biscoe       49.90000          16.1               213\n277 Chinstrap     Dream       46.50000          17.9               192\n278 Chinstrap     Dream       50.00000          19.5               196\n279 Chinstrap     Dream       51.30000          19.2               193\n280 Chinstrap     Dream       45.40000          18.7               188\n281 Chinstrap     Dream       52.70000          19.8               197\n282 Chinstrap     Dream       45.20000          17.8               198\n283 Chinstrap     Dream       46.10000          18.2               178\n284 Chinstrap     Dream       51.30000          18.2               197\n285 Chinstrap     Dream       46.00000          18.9               195\n286 Chinstrap     Dream       51.30000          19.9               198\n287 Chinstrap     Dream       46.60000          17.8               193\n288 Chinstrap     Dream       51.70000          20.3               194\n289 Chinstrap     Dream       47.00000          17.3               185\n290 Chinstrap     Dream       52.00000          18.1               201\n291 Chinstrap     Dream       45.90000          17.1               190\n292 Chinstrap     Dream       50.50000          19.6               201\n293 Chinstrap     Dream       50.30000          20.0               197\n294 Chinstrap     Dream       58.00000          17.8               181\n295 Chinstrap     Dream       46.40000          18.6               190\n296 Chinstrap     Dream       49.20000          18.2               195\n297 Chinstrap     Dream       42.40000          17.3               181\n298 Chinstrap     Dream       48.50000          17.5               191\n299 Chinstrap     Dream       43.20000          16.6               187\n300 Chinstrap     Dream       50.60000          19.4               193\n301 Chinstrap     Dream       46.70000          17.9               195\n302 Chinstrap     Dream       52.00000          19.0               197\n303 Chinstrap     Dream       50.50000          18.4               200\n304 Chinstrap     Dream       49.50000          19.0               200\n305 Chinstrap     Dream       46.40000          17.8               191\n306 Chinstrap     Dream       52.80000          20.0               205\n307 Chinstrap     Dream       40.90000          16.6               187\n308 Chinstrap     Dream       54.20000          20.8               201\n309 Chinstrap     Dream       42.50000          16.7               187\n310 Chinstrap     Dream       51.00000          18.8               203\n311 Chinstrap     Dream       49.70000          18.6               195\n312 Chinstrap     Dream       47.50000          16.8               199\n313 Chinstrap     Dream       47.60000          18.3               195\n314 Chinstrap     Dream       52.00000          20.7               210\n315 Chinstrap     Dream       46.90000          16.6               192\n316 Chinstrap     Dream       53.50000          19.9               205\n317 Chinstrap     Dream       49.00000          19.5               210\n318 Chinstrap     Dream       46.20000          17.5               187\n319 Chinstrap     Dream       50.90000          19.1               196\n320 Chinstrap     Dream       45.50000          17.0               196\n321 Chinstrap     Dream       50.90000          17.9               196\n322 Chinstrap     Dream       50.80000          18.5               201\n323 Chinstrap     Dream       50.10000          17.9               190\n324 Chinstrap     Dream       49.00000          19.6               212\n325 Chinstrap     Dream       51.50000          18.7               187\n326 Chinstrap     Dream       49.80000          17.3               198\n327 Chinstrap     Dream       48.10000          16.4               199\n328 Chinstrap     Dream       51.40000          19.0               201\n329 Chinstrap     Dream       45.70000          17.3               193\n330 Chinstrap     Dream       50.70000          19.7               203\n331 Chinstrap     Dream       42.50000          17.3               187\n332 Chinstrap     Dream       52.20000          18.8               197\n333 Chinstrap     Dream       45.20000          16.6               191\n334 Chinstrap     Dream       49.30000          19.9               203\n335 Chinstrap     Dream       50.20000          18.8               202\n336 Chinstrap     Dream       45.60000          19.4               194\n337 Chinstrap     Dream       51.90000          19.5               206\n338 Chinstrap     Dream       46.80000          16.5               189\n339 Chinstrap     Dream       45.70000          17.0               195\n340 Chinstrap     Dream       55.80000          19.8               207\n341 Chinstrap     Dream       43.50000          18.1               202\n342 Chinstrap     Dream       49.60000          18.2               193\n343 Chinstrap     Dream       50.80000          19.0               210\n344 Chinstrap     Dream       50.20000          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009"
  },
  {
    "objectID": "chapters/999-Problems/HW5Assignment.html",
    "href": "chapters/999-Problems/HW5Assignment.html",
    "title": "Homework 5",
    "section": "",
    "text": "This homework is due by the end of the day on November 20th. You should submit an ipynb or qmd file. At the top of the file you should provide a link to your github repo where the first question is answered; the rest of the file should be your answers to the second problem.\n\n\nI have created a github repository called Grad5100-HW5. It (currently) contains two files and was built with four commits. It is public, so you can clone it to your home machine.\nYour assignment is to make your own github repository called Grad5100-HW5 in your github account that is an exact duplicate of my repository, with the exception that whenever my name appears, you should substitute yours.\nSo for example, in the file current version of the README.md file, there is a line that reads “This is HW5 for Grad5100. My name is Jeremy Teitelbaum.” Your version should say “This is HW5 for Grad5100. My name is [your name].”\nNotice that when I say exact duplicate I mean that, not only must you reproduce the current state of my repository, but your repository should also:\n\nhave 4 commits\neach commit should match the corresponding one in my repo, with the name change mentioned above\nthe state of the directory should be the same for each commit\nthe commit messages should be identical Of course, the commit labels will be different since those are unique and can’t be changed.\n\nTo accomplish this, you will not be able to copy my repo and edit it, because the result will be to add more commits. Instead, you’ll need to reverse engineer my repo and build yours from scratch to match it.\nYou will submit the URL of your repository to complete this assignment.\n\n\n\nYou may do this assignment in either python or R, your choice. Ultimately you will submit an ipynb or a qmd file that I can execute to make sure that it works.\n\nMake a connection to the Amazon RDS database that we used in class.\nUse an appropriate SQL query (or dbplyr construction) to retrieve the id, first, and last name of all the actors in the sakila database, sorted by last name, as a dataframe or tibble.\nHow many languages are there in the language table?\nHow many different languages appear in the film table?\nThe SQL function substring returns a part of a string, so that for example substring(last_name, 1,5) retrieves the first five letters of the last name. Retrieve all actors whose last name begins with B in a dataframe or tibble. (Hint: you can do where substring(....)=...)\nMake a dataframe or tibble that shows the number of actors whose last name starts with a given letter. (Hint: you can group by substring...)\nMake a dataframe or tibble that shows all of the customers customer_id, first_name, last_name and phone number. To get the phone number you will have to do a join with the address table.",
    "crumbs": [
      "Problems",
      "Homework 5"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW5Assignment.html#homework-5",
    "href": "chapters/999-Problems/HW5Assignment.html#homework-5",
    "title": "Homework 5",
    "section": "",
    "text": "This homework is due by the end of the day on November 20th. You should submit an ipynb or qmd file. At the top of the file you should provide a link to your github repo where the first question is answered; the rest of the file should be your answers to the second problem.\n\n\nI have created a github repository called Grad5100-HW5. It (currently) contains two files and was built with four commits. It is public, so you can clone it to your home machine.\nYour assignment is to make your own github repository called Grad5100-HW5 in your github account that is an exact duplicate of my repository, with the exception that whenever my name appears, you should substitute yours.\nSo for example, in the file current version of the README.md file, there is a line that reads “This is HW5 for Grad5100. My name is Jeremy Teitelbaum.” Your version should say “This is HW5 for Grad5100. My name is [your name].”\nNotice that when I say exact duplicate I mean that, not only must you reproduce the current state of my repository, but your repository should also:\n\nhave 4 commits\neach commit should match the corresponding one in my repo, with the name change mentioned above\nthe state of the directory should be the same for each commit\nthe commit messages should be identical Of course, the commit labels will be different since those are unique and can’t be changed.\n\nTo accomplish this, you will not be able to copy my repo and edit it, because the result will be to add more commits. Instead, you’ll need to reverse engineer my repo and build yours from scratch to match it.\nYou will submit the URL of your repository to complete this assignment.\n\n\n\nYou may do this assignment in either python or R, your choice. Ultimately you will submit an ipynb or a qmd file that I can execute to make sure that it works.\n\nMake a connection to the Amazon RDS database that we used in class.\nUse an appropriate SQL query (or dbplyr construction) to retrieve the id, first, and last name of all the actors in the sakila database, sorted by last name, as a dataframe or tibble.\nHow many languages are there in the language table?\nHow many different languages appear in the film table?\nThe SQL function substring returns a part of a string, so that for example substring(last_name, 1,5) retrieves the first five letters of the last name. Retrieve all actors whose last name begins with B in a dataframe or tibble. (Hint: you can do where substring(....)=...)\nMake a dataframe or tibble that shows the number of actors whose last name starts with a given letter. (Hint: you can group by substring...)\nMake a dataframe or tibble that shows all of the customers customer_id, first_name, last_name and phone number. To get the phone number you will have to do a join with the address table.",
    "crumbs": [
      "Problems",
      "Homework 5"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW3Assignment.html",
    "href": "chapters/999-Problems/HW3Assignment.html",
    "title": "Homework 3",
    "section": "",
    "text": "The third homework assignment is due at midnight, October 15th. Submit it on HuskyCT.\nYou may do this assignment using either R or Python, your choice.\nWe will work with this file containing Amazon Books. Load this file into a tibble (for R) or a pandas dataframe (for Python) and then carry out the following steps. READ THE INSTRUCTIONS CAREFULLY!\nYour solution should come in the form of a report that shows the steps you carried out to achieve each goal. You should submit a jupyter notebook or a qmd file that I can execute to verify each of the steps.\n\nThere are a rows in this dataframe with missing titles and there are a bunch of extra columns at the end of the dataframe. Clean up the dataset by deleting the extra columns and the rows where the title is missing.\nAfter the changes in (1), how many rows have missing authors? Show the titles of the books with missing authors and then delete those from the data frame.\nIn the remaining dataset, the price column mostly consists of strings with a $ and then the price. But a few of the entries don’t have the $ and are already numbers.\n\nDelete any books with missing prices from the data set.\nFix this column so every entry is a number and you can do arithmetic on it.\n\nWhich books are missing a price? Show those books.\n\n\nHint: In python, you can determine if something is a string by using the isinstance command. So isinstance(x,str) is Trueif x is of type string, and False otherwise. You can convert a string to a number using float: float(x) converts a string x to a number, assuming x is in a valid form to be a number.\nHint: in R, you can convert a string to a number using the as.numeric function.\n\nOf the remaining books, which ones are missing a rating?\n\nshow the books that are missing a rating\ndelete these books from the data set.\n\nThe ratings are entered as strings, and, for some reason, a few of the ratings are entered with a $. (So it says $4.40 instead of 4.4). How many of these are there? Fix this column so that all of the entries are numbers, and get rid of the $. Drop any rows where the rating is missing.\nMake a new column ‘quality’ where the entry is “Excellent” if the rating is &gt;=4.5, “Good” if it is between &gt;=3.8 and &lt;4.5, and “Fair” if it is &lt;3.8.\nMake a table with rows “Excellent”, “Good” and “Fair” and Columns “count” and “mean” where the entries are the number of books with each class of ratings and the mean value of the price of the books within each rating class.\nMake a new column called “python” which has a one if the title of the book includes the word “Python” or “python” and a zero if it doesn’t.\n\nHint: In R, the function grepl detects the presence of a substring. So grepl(\"Python\",x) is TRUE if Python is a substring of x, and false otherwise.\nHint: In python, you can use in: \"Python\" in x is true if “Python” is a substring.\n\nMake a pivot table with rows the rating classes, columns the yes/no values for Python, and entries the average price within each class.",
    "crumbs": [
      "Problems",
      "Homework 3"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-clean_up_function.html",
    "href": "chapters/999-Problems/HW2-clean_up_function.html",
    "title": "Comments on HW2 - String Clean Up",
    "section": "",
    "text": "4 Sample Solutions\n\ndef clean_up(s):\n    new_s = \"\"\n    for x in s:\n        if x in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \":\n            if x == \" \":\n                new_s = new_s + \"_\"\n            else:\n                new_s = new_s + x\n    return new_s.lower()\n\n\n\n\ndef clean_string(input_string):\n    # Remove characters that are not numbers, letters, or spaces\n    cleaned_string = \"\".join(\n        char for char in input_string if char.isalnum() or char == \" \"\n    )\n    # Convert to lowercase\n    cleaned_string = cleaned_string.lower()\n    # Convert spaces to underscores\n    cleaned_string = cleaned_string.replace(\" \", \"_\")\n\n    return cleaned_string\n\n\ndef editing_2(x):\n    text_2 = \"\"\n    for char in x:\n        if char.isalnum() or char.isspace() or char.isalpha():\n            text_2 = text_2 + char\n    text_2 = text_2.lower()\n    text_2 = text_2.replace(\" \", \"_\")\n    return text_2\n\n\nimport re\n\n\ndef p4(s):\n    s = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", s)\n    s = s.replace(\" \", \"_\")\n    return s.lower()",
    "crumbs": [
      "Problems",
      "Comments on HW2 - String Clean Up"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-clean_up_function.html#python",
    "href": "chapters/999-Problems/HW2-clean_up_function.html#python",
    "title": "Comments on HW2 - String Clean Up",
    "section": "",
    "text": "4 Sample Solutions\n\ndef clean_up(s):\n    new_s = \"\"\n    for x in s:\n        if x in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \":\n            if x == \" \":\n                new_s = new_s + \"_\"\n            else:\n                new_s = new_s + x\n    return new_s.lower()\n\n\n\n\ndef clean_string(input_string):\n    # Remove characters that are not numbers, letters, or spaces\n    cleaned_string = \"\".join(\n        char for char in input_string if char.isalnum() or char == \" \"\n    )\n    # Convert to lowercase\n    cleaned_string = cleaned_string.lower()\n    # Convert spaces to underscores\n    cleaned_string = cleaned_string.replace(\" \", \"_\")\n\n    return cleaned_string\n\n\ndef editing_2(x):\n    text_2 = \"\"\n    for char in x:\n        if char.isalnum() or char.isspace() or char.isalpha():\n            text_2 = text_2 + char\n    text_2 = text_2.lower()\n    text_2 = text_2.replace(\" \", \"_\")\n    return text_2\n\n\nimport re\n\n\ndef p4(s):\n    s = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", s)\n    s = s.replace(\" \", \"_\")\n    return s.lower()",
    "crumbs": [
      "Problems",
      "Comments on HW2 - String Clean Up"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-clean_up_function.html#r",
    "href": "chapters/999-Problems/HW2-clean_up_function.html#r",
    "title": "Comments on HW2 - String Clean Up",
    "section": "R",
    "text": "R\n\nclean_up &lt;- function(s) {\n    valid &lt;- c(letters, LETTERS, \" \", seq(0, 9)) # a vector of the things I want to keep\n    split_string &lt;- strsplit(s, \"\")[[1]]\n    keepers &lt;- split_string[split_string %in% valid]\n    keepers &lt;- tolower(gsub(\" \", \"_\", keepers))\n    paste(keepers, collapse = \"\")\n}\n\n\nstring_edit &lt;- function(string) {\n    acceptable_characters &lt;- c(letters, LETTERS, as.character(seq(0, 9)), \" \")\n    unacceptable_characters &lt;- paste(\"[^\", paste0(acceptable_characters, collapse = \"\"), \"]\", sep = \"\")\n\n    cleaned_string &lt;- string\n\n    for (character in unacceptable_characters) {\n        cleaned_string &lt;- gsub(character, \"\", cleaned_string)\n    }\n\n    cleaned_string &lt;- tolower(cleaned_string)\n\n    cleaned_string &lt;- gsub(\" \", \"_\", cleaned_string)\n\n    return(cleaned_string)\n}\n\n\ni_function &lt;- function(input) {\n    a1 &lt;- gsub(\"[^[:alnum:] ]\", \"\", input)\n    a2 &lt;- gsub(\" \", \"_\", a1)\n    tolower(a2)\n}\n\n\nclean_and_format_string &lt;- function(input_string) {\n    cleaned_string &lt;- gsub(\"[^0-9a-zA-Z[:space:]]\", \"\", input_string)\n\n    cleaned_string &lt;- tolower(cleaned_string)\n\n    cleaned_string &lt;- gsub(\" \", \"_\", cleaned_string)\n\n    return(cleaned_string)\n}",
    "crumbs": [
      "Problems",
      "Comments on HW2 - String Clean Up"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-Iteration.html",
    "href": "chapters/999-Problems/HW2-Iteration.html",
    "title": "Comments on HW2 - iteration",
    "section": "",
    "text": "def sq(n, threshold=1e-6, max_iter=1000):\n    x = 1\n    tol = 1 + threshold  # make sure the tolerance starts bigger than the threshold\n    iterations = 0\n\n    while tol &gt; threshold and iterations &lt; max_iter:\n        xnew = 0.5 * (x + n / x)\n        tol = np.abs(xnew - x)\n        x = xnew\n        iterations = iterations + 1\n\n    if iterations &gt;= max_iter:\n        print(\"Failed to converge\")\n        return None\n    else:\n        return x\n\n\ndef sq(n, tol=1e-6, max_iter=1000):\n    x = 1\n    tol = 1\n    iterations = 0\n\n    while tol &gt; threshold:\n        xnew = 0.5 * (x + n / x)\n        tol = np.abs(xnew - x)\n        x = xnew\n        iterations = iterations + 1\n        if iterations &gt; max_iter:\n            print(\"Failed to converge\")\n            return None\n    return x",
    "crumbs": [
      "Problems",
      "Comments on HW2 - iteration"
    ]
  },
  {
    "objectID": "chapters/999-Problems/Distributions.html",
    "href": "chapters/999-Problems/Distributions.html",
    "title": "Notes on Probability in R",
    "section": "",
    "text": "As I mentioned in class, every probability distribution in R comes with 4 functions. In the case of the binomial distribution, they are:\n\nrbinom – draws random samples\ndbinom – computes the probability distribution\npbinom – gives the cumulative distribution\nqbinom – gives the quantile function\n\nAlso, we need ggplot2.\n\nlibrary(ggplot2)\n\nExamples\n\nSuppose that the probability of heads is .3 and we flip a coin 15 times. What’s the chance of getting 6 heads?\n\n\np&lt;-dbinom(6,15,.3)\ncat(\"The chance is \",p)\n\nThe chance is  0.147236\n\n\n\nLet’s find the probabilities of each number of heads.\n\n\nxs&lt;-seq(0,10) # x holds 0,1,...,10\nfs&lt;-dbinom(xs,10,.3)\nprint(fs)\n\n [1] 0.0282475249 0.1210608210 0.2334744405 0.2668279320 0.2001209490\n [6] 0.1029193452 0.0367569090 0.0090016920 0.0014467005 0.0001377810\n[11] 0.0000059049\n\n\n\nLet’s plot this. We’ll use ggplot. This is a very simple use of ggplot to make a bar chart. We’ll talk about ggplot more comprehensively later. For now, you can use this as a “black box”. In the part that says aes(x=?,y=?) you put the data for the x and y coordinates. The scale_x_continous(break=?) says where to put the x-ticks. The xlab(\"?\") labels the x-axis. The ylab labels the y-axis.\n\n\nggplot()+geom_col(aes(x=xs,y=fs))+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Probability\")\n\n\n\n\n\n\n\n\n\nLet’s sample this distribution. We’ll flip a coin with p=.3 10 times, and we’ll repeat this experiment 100 times, counting how many heads we get each repetition.\n\n\nheads &lt;- rbinom(100,10,.3)\nheads\n\n  [1] 5 4 0 1 2 1 2 5 0 3 1 3 4 3 5 2 4 5 4 1 3 4 3 4 2 2 2 5 1 3 4 4 2 3 7 1 0\n [38] 5 1 3 4 1 1 2 8 2 3 4 2 1 2 4 1 1 2 3 2 1 4 3 2 2 5 2 3 3 3 3 2 6 5 4 1 5\n [75] 3 3 2 1 0 7 4 4 1 3 2 4 4 3 1 3 2 1 4 2 3 5 4 5 3 1\n\n\nNow let’s make a histogram. Again, here is a “black box” command for ggplot. Again, you put the data in aes(x=?) and you put the location for the x-ticks in scale_x_continous(breaks=?).\n\nggplot()+geom_histogram(aes(x=heads),stat='count')+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Count\")\n\nWarning in geom_histogram(aes(x = heads), stat = \"count\"): Ignoring unknown\nparameters: `binwidth`, `bins`, and `pad`\n\n\n\n\n\n\n\n\n\n\nSuppose we flip the coin 80 times (and p=.3). What’s the chance of getting between 20 and 40 heads? This is what pbinom is for. pbinom(40,80,.3) is the chance of getting fewer than or equal to 40 heads. If we want 20 to 40 inclusive we need to look at pbinom(41,80,.3).\n\n\nchance&lt;-pbinom(40,80,.3)-pbinom(19,80,.3)\ncat(\"Chance  of between 40 and 20 inclusive is \",chance)\n\nChance  of between 40 and 20 inclusive is  0.86472\n\n\n\nAmong the number of heads in 100 flips of a coin with .3, what’s the 25th percentile for the number of heads? That’s what qbinom is for.\n\n\ntwentyFifth&lt;-qbinom(.25,100,.3)\npaste(\"The 25th percentile is \",twentyFifth)\n\n[1] \"The 25th percentile is  27\"\n\n\nLet’s check.\n\ncheck&lt;-pbinom(twentyFifth,100,.3)\ncheck\n\n[1] 0.2963662\n\n\nThis says that the chance of fewer than 27 heads is actually a bit more than .25 but the chance of fewer than 26 heads is less than .25.\n\nAn experiment\n\nLet’s sample from the binomial 10000 times and look at the 25th percentile.\n\ndata&lt;-rbinom(10000,100,.3)\nt1&lt;-sum(data&lt;twentyFifth)\nt2&lt;-sum(data&lt;twentyFifth+1)\ncat(\"Number less than \",twentyFifth, \"is \",t1,\"\\n\")\n\nNumber less than  27 is  2259 \n\ncat(\"Number less than \",twentyFifth+1,\"is\",t2)\n\nNumber less than  28 is 2944\n\n\nThese numbers show that the 25th percentile (2500 heads) is somewhere between these two values.",
    "crumbs": [
      "Problems",
      "Notes on Probability in R"
    ]
  },
  {
    "objectID": "chapters/999-Problems/Distributions.html#things-i-did-in-class-on-friday-september-1.",
    "href": "chapters/999-Problems/Distributions.html#things-i-did-in-class-on-friday-september-1.",
    "title": "Notes on Probability in R",
    "section": "",
    "text": "As I mentioned in class, every probability distribution in R comes with 4 functions. In the case of the binomial distribution, they are:\n\nrbinom – draws random samples\ndbinom – computes the probability distribution\npbinom – gives the cumulative distribution\nqbinom – gives the quantile function\n\nAlso, we need ggplot2.\n\nlibrary(ggplot2)\n\nExamples\n\nSuppose that the probability of heads is .3 and we flip a coin 15 times. What’s the chance of getting 6 heads?\n\n\np&lt;-dbinom(6,15,.3)\ncat(\"The chance is \",p)\n\nThe chance is  0.147236\n\n\n\nLet’s find the probabilities of each number of heads.\n\n\nxs&lt;-seq(0,10) # x holds 0,1,...,10\nfs&lt;-dbinom(xs,10,.3)\nprint(fs)\n\n [1] 0.0282475249 0.1210608210 0.2334744405 0.2668279320 0.2001209490\n [6] 0.1029193452 0.0367569090 0.0090016920 0.0014467005 0.0001377810\n[11] 0.0000059049\n\n\n\nLet’s plot this. We’ll use ggplot. This is a very simple use of ggplot to make a bar chart. We’ll talk about ggplot more comprehensively later. For now, you can use this as a “black box”. In the part that says aes(x=?,y=?) you put the data for the x and y coordinates. The scale_x_continous(break=?) says where to put the x-ticks. The xlab(\"?\") labels the x-axis. The ylab labels the y-axis.\n\n\nggplot()+geom_col(aes(x=xs,y=fs))+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Probability\")\n\n\n\n\n\n\n\n\n\nLet’s sample this distribution. We’ll flip a coin with p=.3 10 times, and we’ll repeat this experiment 100 times, counting how many heads we get each repetition.\n\n\nheads &lt;- rbinom(100,10,.3)\nheads\n\n  [1] 5 4 0 1 2 1 2 5 0 3 1 3 4 3 5 2 4 5 4 1 3 4 3 4 2 2 2 5 1 3 4 4 2 3 7 1 0\n [38] 5 1 3 4 1 1 2 8 2 3 4 2 1 2 4 1 1 2 3 2 1 4 3 2 2 5 2 3 3 3 3 2 6 5 4 1 5\n [75] 3 3 2 1 0 7 4 4 1 3 2 4 4 3 1 3 2 1 4 2 3 5 4 5 3 1\n\n\nNow let’s make a histogram. Again, here is a “black box” command for ggplot. Again, you put the data in aes(x=?) and you put the location for the x-ticks in scale_x_continous(breaks=?).\n\nggplot()+geom_histogram(aes(x=heads),stat='count')+scale_x_continuous(breaks=seq(0,10))+xlab(\"Number of Heads\")+ylab(\"Count\")\n\nWarning in geom_histogram(aes(x = heads), stat = \"count\"): Ignoring unknown\nparameters: `binwidth`, `bins`, and `pad`\n\n\n\n\n\n\n\n\n\n\nSuppose we flip the coin 80 times (and p=.3). What’s the chance of getting between 20 and 40 heads? This is what pbinom is for. pbinom(40,80,.3) is the chance of getting fewer than or equal to 40 heads. If we want 20 to 40 inclusive we need to look at pbinom(41,80,.3).\n\n\nchance&lt;-pbinom(40,80,.3)-pbinom(19,80,.3)\ncat(\"Chance  of between 40 and 20 inclusive is \",chance)\n\nChance  of between 40 and 20 inclusive is  0.86472\n\n\n\nAmong the number of heads in 100 flips of a coin with .3, what’s the 25th percentile for the number of heads? That’s what qbinom is for.\n\n\ntwentyFifth&lt;-qbinom(.25,100,.3)\npaste(\"The 25th percentile is \",twentyFifth)\n\n[1] \"The 25th percentile is  27\"\n\n\nLet’s check.\n\ncheck&lt;-pbinom(twentyFifth,100,.3)\ncheck\n\n[1] 0.2963662\n\n\nThis says that the chance of fewer than 27 heads is actually a bit more than .25 but the chance of fewer than 26 heads is less than .25.\n\nAn experiment\n\nLet’s sample from the binomial 10000 times and look at the 25th percentile.\n\ndata&lt;-rbinom(10000,100,.3)\nt1&lt;-sum(data&lt;twentyFifth)\nt2&lt;-sum(data&lt;twentyFifth+1)\ncat(\"Number less than \",twentyFifth, \"is \",t1,\"\\n\")\n\nNumber less than  27 is  2259 \n\ncat(\"Number less than \",twentyFifth+1,\"is\",t2)\n\nNumber less than  28 is 2944\n\n\nThese numbers show that the 25th percentile (2500 heads) is somewhere between these two values.",
    "crumbs": [
      "Problems",
      "Notes on Probability in R"
    ]
  },
  {
    "objectID": "chapters/999-Problems/Distributions.html#practice-note-these-are-now-assigned-in-hw-2",
    "href": "chapters/999-Problems/Distributions.html#practice-note-these-are-now-assigned-in-hw-2",
    "title": "Notes on Probability in R",
    "section": "Practice (note: these are now assigned in HW 2)",
    "text": "Practice (note: these are now assigned in HW 2)\n\nLet X be a binomial random variable with n=50 and p=.7.\n\n\n\nDraw 1000 samples from X. How many of your sampled values are less than 30?\nBased on the probability distribution, how many sampled values would you expect to see that are less than 30?\nPlot a histogram of your sampled values.\n\n\nThe poisson distribution is a discrete probability distribution that arises in queuing theory (and many other places). For example, imagine that customers arrive at a server at a rate so that, in a typical one hour period, 20 customers come. But the intervals between customers are random and independent of one another. Then in a randomly chosen hour, the probability of k customers arriving is dpois(k,20).\n\n\n\nSample this distribution 1000 times (hint: use rpois). What is the largest number of people who arrive in an one of these random hours? What is the smallest?\nSuppose you want to design your system so that it can handle the number of arriving customers 95% of the time. How many people should you design for? (Hint: use qpois).\nWhat’s the chance that between 18 and 22 people arrive in a given hour? (Hint: use ppois).\nPlot the Poisson distribution probabilities. (Hint: use dpois).",
    "crumbs": [
      "Problems",
      "Notes on Probability in R"
    ]
  },
  {
    "objectID": "chapters/99-Resources/Cheatsheets.html",
    "href": "chapters/99-Resources/Cheatsheets.html",
    "title": "Cheatsheets and other References",
    "section": "",
    "text": "This is a compilation of resources from various sites on the web.\n\n\nFrom the pandas home page.\n\npandas cheatsheet\n\n\n\n\nThanks to the matplotlib home page.\n\nbeginner cheatsheet\nintermediate cheatsheet\ntip sheet\ncomplete (front)\ncomplete (back)\nstyles\n\n\n\n\nSeaborn is a fancier interface to matplotlib that offers high quality statistical plots of various types.\n\nseaborn cheatsheet\n\n\n\n\nFrom the posit home page\n\nbase r cheatsheet\ntidyverse cheatsheet\nr markdown cheatsheet\n\n\n\n\nFrom the posit home page\n\nggplot cheatsheet\n\n\n\n\nFrom the vscode home page\n\nwindows keybindings\nmac keybindings\nlinux keybindings\n\n\n\n\n\nMarkdown Cheat Sheet",
    "crumbs": [
      "Resources",
      "Cheatsheets and other References"
    ]
  },
  {
    "objectID": "chapters/99-Resources/Cheatsheets.html#cheatsheets",
    "href": "chapters/99-Resources/Cheatsheets.html#cheatsheets",
    "title": "Cheatsheets and other References",
    "section": "",
    "text": "This is a compilation of resources from various sites on the web.\n\n\nFrom the pandas home page.\n\npandas cheatsheet\n\n\n\n\nThanks to the matplotlib home page.\n\nbeginner cheatsheet\nintermediate cheatsheet\ntip sheet\ncomplete (front)\ncomplete (back)\nstyles\n\n\n\n\nSeaborn is a fancier interface to matplotlib that offers high quality statistical plots of various types.\n\nseaborn cheatsheet\n\n\n\n\nFrom the posit home page\n\nbase r cheatsheet\ntidyverse cheatsheet\nr markdown cheatsheet\n\n\n\n\nFrom the posit home page\n\nggplot cheatsheet\n\n\n\n\nFrom the vscode home page\n\nwindows keybindings\nmac keybindings\nlinux keybindings\n\n\n\n\n\nMarkdown Cheat Sheet",
    "crumbs": [
      "Resources",
      "Cheatsheets and other References"
    ]
  },
  {
    "objectID": "chapters/11-Git/Git.html",
    "href": "chapters/11-Git/Git.html",
    "title": "Version Control and Git",
    "section": "",
    "text": "We will be following the Software Carpentries Lesson on Git.\nTo prepare for this lesson, you should have installed git for windows if you are on a Windows machine.\nOn MacOS, git is typically available by default, but if you want the most recent version you can download it using one of the package managers for Mac (like homebrew). See this web page.\nYou will also need an account on github.com. If you have not created one, do so now.",
    "crumbs": [
      "Contents",
      "Version Control and Git"
    ]
  },
  {
    "objectID": "chapters/11-Git/Git.html#using-git",
    "href": "chapters/11-Git/Git.html#using-git",
    "title": "Version Control and Git",
    "section": "",
    "text": "We will be following the Software Carpentries Lesson on Git.\nTo prepare for this lesson, you should have installed git for windows if you are on a Windows machine.\nOn MacOS, git is typically available by default, but if you want the most recent version you can download it using one of the package managers for Mac (like homebrew). See this web page.\nYou will also need an account on github.com. If you have not created one, do so now.",
    "crumbs": [
      "Contents",
      "Version Control and Git"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsR.html",
    "href": "chapters/09-Regexps/regexpsR.html",
    "title": "Regexps in R",
    "section": "",
    "text": "The language is the same, but the wrapper functions are different.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"Hel\")\n\n[1] │ &lt;Hel&gt;p\n[3] │ &lt;Hel&gt;lo\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"He.*l\")\n\n[1] │ &lt;Hel&gt;p\n[3] │ &lt;Hell&gt;o\n\n\n\nstr_view(c(\"Now is the time for us to rise up\"), \"[A-Za-z]+[a-z]?\")\n\n[1] │ &lt;Now&gt; &lt;is&gt; &lt;the&gt; &lt;time&gt; &lt;for&gt; &lt;us&gt; &lt;to&gt; &lt;rise&gt; &lt;up&gt;\n\n\n\nstr_detect(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] TRUE TRUE\n\nstr_view(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] │ &lt;Now&gt; &lt;is&gt; &lt;the&gt;\n[2] │ &lt;time&gt; &lt;to&gt; &lt;rise&gt; &lt;up&gt;\n\n\n\nstr_count(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] 3 4\n\n\n\ngettysburg &lt;- read_lines(\"data/gettysburg.txt\")\nstr_extract(gettysburg, \"\\\\b(\\\\w+)\\\\b\")\n\n[1] \"Four\" NA     \"Now\"  NA     \"But\" \n\n\n\n# str_match_all is inconvenient -- output is a list\nwords &lt;- str_match_all(gettysburg[1], \"\\\\b\\\\w+\\\\b\")\n\n\nfilenames &lt;- read_lines(\"data/filenames.txt\")\nmatches &lt;- str_match_all(filenames, \".*_([a-z]{3}[0-9]{5})_.*\\\\.(qmd|Rmd|pdf)\")\n\n\n# separate_wider_regex works with tibbles\n# note also separate_wider_delim\n\nfilenames &lt;- read_lines(\"data/filenames.txt\")\nfilenames &lt;- tibble(names = filenames)\nfilenames &lt;- filenames |&gt; separate_wider_regex(names, patterns = c(\n    \".*_\",\n    netid = \"[a-z]{3}[0-9]{5}\",\n    \"_.*\\\\.\",\n    extension = \"qmd|Rmd|pdf\"\n), cols_remove = FALSE)\n# matches have to fill the line\n# use too_few = \"debug\" to get extra info if this fails (omit pdf from extension for example)\nfilenames |&gt; mutate(new_name = str_c(netid, \".\", extension))\n\n# A tibble: 40 × 4\n   netid    extension names                                             new_name\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                                             &lt;chr&gt;   \n 1 aft85126 qmd       HW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-… aft8512…\n 2 pez35105 qmd       HW2 - R - QMD_pez35105_attempt_2023-09-23-23-21-… pez3510…\n 3 qty84085 pdf       HW2 - R - QMD_qty84085_attempt_2023-09-23-23-21-… qty8408…\n 4 min29847 qmd       HW2 - R - QMD_min29847_attempt_2023-09-24-00-57-… min2984…\n 5 imk48906 qmd       HW2 - R - QMD_imk48906_attempt_2023-09-24-13-30-… imk4890…\n 6 uwc08078 qmd       HW2 - R - QMD_uwc08078_attempt_2023-09-24-00-03-… uwc0807…\n 7 kld62064 Rmd       HW2 - R - QMD_kld62064_attempt_2023-09-24-18-53-… kld6206…\n 8 mnr42924 qmd       HW2 - R - QMD_mnr42924_attempt_2023-09-24-22-44-… mnr4292…\n 9 kzs45796 qmd       HW2 - R - QMD_kzs45796_attempt_2023-09-12-11-29-… kzs4579…\n10 vhy10473 qmd       HW2 - R - QMD_vhy10473_attempt_2023-09-24-22-34-… vhy1047…\n# ℹ 30 more rows",
    "crumbs": [
      "Contents",
      "Regexps in R"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsR.html#regexps-in-r",
    "href": "chapters/09-Regexps/regexpsR.html#regexps-in-r",
    "title": "Regexps in R",
    "section": "",
    "text": "The language is the same, but the wrapper functions are different.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"Hel\")\n\n[1] │ &lt;Hel&gt;p\n[3] │ &lt;Hel&gt;lo\n\n\n\nstr_view(c(\"Help\", \"Hero\", \"Hello\", \"Friend\"), \"He.*l\")\n\n[1] │ &lt;Hel&gt;p\n[3] │ &lt;Hell&gt;o\n\n\n\nstr_view(c(\"Now is the time for us to rise up\"), \"[A-Za-z]+[a-z]?\")\n\n[1] │ &lt;Now&gt; &lt;is&gt; &lt;the&gt; &lt;time&gt; &lt;for&gt; &lt;us&gt; &lt;to&gt; &lt;rise&gt; &lt;up&gt;\n\n\n\nstr_detect(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] TRUE TRUE\n\nstr_view(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] │ &lt;Now&gt; &lt;is&gt; &lt;the&gt;\n[2] │ &lt;time&gt; &lt;to&gt; &lt;rise&gt; &lt;up&gt;\n\n\n\nstr_count(c(\"Now is the\", \"time to rise up\"), \"\\\\b\\\\w+\\\\b\")\n\n[1] 3 4\n\n\n\ngettysburg &lt;- read_lines(\"data/gettysburg.txt\")\nstr_extract(gettysburg, \"\\\\b(\\\\w+)\\\\b\")\n\n[1] \"Four\" NA     \"Now\"  NA     \"But\" \n\n\n\n# str_match_all is inconvenient -- output is a list\nwords &lt;- str_match_all(gettysburg[1], \"\\\\b\\\\w+\\\\b\")\n\n\nfilenames &lt;- read_lines(\"data/filenames.txt\")\nmatches &lt;- str_match_all(filenames, \".*_([a-z]{3}[0-9]{5})_.*\\\\.(qmd|Rmd|pdf)\")\n\n\n# separate_wider_regex works with tibbles\n# note also separate_wider_delim\n\nfilenames &lt;- read_lines(\"data/filenames.txt\")\nfilenames &lt;- tibble(names = filenames)\nfilenames &lt;- filenames |&gt; separate_wider_regex(names, patterns = c(\n    \".*_\",\n    netid = \"[a-z]{3}[0-9]{5}\",\n    \"_.*\\\\.\",\n    extension = \"qmd|Rmd|pdf\"\n), cols_remove = FALSE)\n# matches have to fill the line\n# use too_few = \"debug\" to get extra info if this fails (omit pdf from extension for example)\nfilenames |&gt; mutate(new_name = str_c(netid, \".\", extension))\n\n# A tibble: 40 × 4\n   netid    extension names                                             new_name\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                                             &lt;chr&gt;   \n 1 aft85126 qmd       HW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-… aft8512…\n 2 pez35105 qmd       HW2 - R - QMD_pez35105_attempt_2023-09-23-23-21-… pez3510…\n 3 qty84085 pdf       HW2 - R - QMD_qty84085_attempt_2023-09-23-23-21-… qty8408…\n 4 min29847 qmd       HW2 - R - QMD_min29847_attempt_2023-09-24-00-57-… min2984…\n 5 imk48906 qmd       HW2 - R - QMD_imk48906_attempt_2023-09-24-13-30-… imk4890…\n 6 uwc08078 qmd       HW2 - R - QMD_uwc08078_attempt_2023-09-24-00-03-… uwc0807…\n 7 kld62064 Rmd       HW2 - R - QMD_kld62064_attempt_2023-09-24-18-53-… kld6206…\n 8 mnr42924 qmd       HW2 - R - QMD_mnr42924_attempt_2023-09-24-22-44-… mnr4292…\n 9 kzs45796 qmd       HW2 - R - QMD_kzs45796_attempt_2023-09-12-11-29-… kzs4579…\n10 vhy10473 qmd       HW2 - R - QMD_vhy10473_attempt_2023-09-24-22-34-… vhy1047…\n# ℹ 30 more rows",
    "crumbs": [
      "Contents",
      "Regexps in R"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html",
    "href": "chapters/09-Regexps/pythonFiles.html",
    "title": "Reading and Writing to Files in Python",
    "section": "",
    "text": "We have already seen how to use the read_csv commands (in R and python/pandas) to read data from files into dataframes/tibbles. But sometimes we need to work directly with text files.",
    "crumbs": [
      "Contents",
      "Reading and Writing to Files in Python"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#the-basics",
    "href": "chapters/09-Regexps/pythonFiles.html#the-basics",
    "title": "Reading and Writing to Files in Python",
    "section": "The basics",
    "text": "The basics\n\n#with open(\"path\",\"r\") as f:\n#    (put logic to read file here)\n\nThis structure guarantees that the file will be properly closed when you’re done.\n\nSlurp up the whole file into a string.\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    data = f.read()\nlen(data)\n\n1477\n\n\n\nlines = data.split('\\n')\nfor x in lines[:10]:\n    print(x)\n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\nNow we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n\nBut, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\n\n\n\n\n\nRead the file line by line\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    for line in f:\n        print(line) \n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\n\n\nNow we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n\n\n\nBut, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\n\n\n\n\n\nRead a line from the file\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    line = f.readline()\n    print(line)\n\n Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n\n\n\n\n\nSlurp the file into a list\n\nwith open(\"data/gettysburg.txt\",\"r\") as f:\n    line_list = f.readlines()\n\nlowercase = [x.lower() for x in line_list]\nlowercase\n\n[' four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.\\n',\n '\\n',\n 'now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. we are met on a great battle-field of that war. we have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. it is altogether fitting and proper that we should do this.\\n',\n '\\n',\n 'but, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. the brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. the world will little note, nor long remember what we say here, but it can never forget what they did here. it is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. it is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under god, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\\n']",
    "crumbs": [
      "Contents",
      "Reading and Writing to Files in Python"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#writing-to-a-file",
    "href": "chapters/09-Regexps/pythonFiles.html#writing-to-a-file",
    "title": "Reading and Writing to Files in Python",
    "section": "Writing to a file",
    "text": "Writing to a file\nAn entire string to the file. This will overwrite what is in the file.\n\nwith open(\"data/gettysburg_lower.txt\",\"w\") as f:\n    f.write('\\n'.join(lowercase))\n\nOne line at a time. This will overwrite what is in the file.\n\nwith open(\"data/gettysburg_lower.txt\",\"w\") as f:\n    for x in lowercase:\n        f.write(x+\"\\n\")",
    "crumbs": [
      "Contents",
      "Reading and Writing to Files in Python"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#appending-to-a-file",
    "href": "chapters/09-Regexps/pythonFiles.html#appending-to-a-file",
    "title": "Reading and Writing to Files in Python",
    "section": "Appending to a file",
    "text": "Appending to a file\n\nwith open(\"data/gettysburg_lower.txt\",\"a\") as f:\n    f.write(\"This goes at the end\\n\")",
    "crumbs": [
      "Contents",
      "Reading and Writing to Files in Python"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/pythonFiles.html#working-with-directories-folders",
    "href": "chapters/09-Regexps/pythonFiles.html#working-with-directories-folders",
    "title": "Reading and Writing to Files in Python",
    "section": "Working with directories (folders)",
    "text": "Working with directories (folders)\n\nimport os\nimport shutil\n#os.getcwd()\n#os.chdir('/home/jet08013')\n#os.getcwd()\n#files = os.listdir('.')\n#os.rename()\n#shutil.copy()",
    "crumbs": [
      "Contents",
      "Reading and Writing to Files in Python"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html",
    "href": "chapters/09-Regexps/RegexProblems.html",
    "title": "Exercises with Regexps",
    "section": "",
    "text": "The following exercises were taken from Chapter 15 of R for Data Science by Wickham, et. al. See the online version.",
    "crumbs": [
      "Contents",
      "Exercises with Regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#first-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#first-batch",
    "title": "Exercises with Regexps",
    "section": "First Batch",
    "text": "First Batch\nYou can use either R or Python to approach these problems. The file words.txt contains about 1000 common English words. You can read that file into Python or, in R, use the variable stringr::words to get them.\n\nFind all the words that start with “y”.\nFind all the words that end with “x”.\nFind all the words that are exactly 3 letters long.\nContain a vowel followed by a consonant.\nContain at least two vowel-consonant pairs in a row.",
    "crumbs": [
      "Contents",
      "Exercises with Regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#second-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#second-batch",
    "title": "Exercises with Regexps",
    "section": "Second Batch",
    "text": "Second Batch\nUse the filenames.txt file. We saw how to extract the netid and the file extension from these files. Now extract the date/time info.\nSuppose the we want to obscure the netids by making up “fake” netids and substituting those into the filenames. How do you do that?",
    "crumbs": [
      "Contents",
      "Exercises with Regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/RegexProblems.html#third-batch",
    "href": "chapters/09-Regexps/RegexProblems.html#third-batch",
    "title": "Exercises with Regexps",
    "section": "Third batch",
    "text": "Third batch\nUse the pandas pd.read_csv function or the tidyverse read_csv function to load the data/aircrashesFullData.csv dataset. Then use one of the file I/O functions from R or python to load the file. Compare the results. For example, how many rows does the dataframe have? How many lines did you read? Why the difference?",
    "crumbs": [
      "Contents",
      "Exercises with Regexps"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/groupingR.html",
    "href": "chapters/08-Summarizing/groupingR.html",
    "title": "Grouping and Summarizing in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npenguins = read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npenguins |&gt; summarise_all(class)\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species   Region    Island    Stage  `Individual ID`\n  &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;          \n1 character numeric         character character character chara… character      \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;chr&gt;,\n#   `Culmen Length (mm)` &lt;chr&gt;, `Culmen Depth (mm)` &lt;chr&gt;,\n#   `Flipper Length (mm)` &lt;chr&gt;, `Body Mass (g)` &lt;chr&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;chr&gt;, `Delta 13 C (o/oo)` &lt;chr&gt;, Comments &lt;chr&gt;\n\n\n\nFocus on the relevant numerical variables\n\n\nfocus &lt;- c('Species','Island','Sex','Culmen Length (mm)','Culmen Depth (mm)','Flipper Length (mm)','Body Mass (g)')\nsimplified &lt;- penguins |&gt; select(all_of(focus))\n\n\nClean up the column names\n\nUsing a named vector\n\nedited_columns &lt;- c(species = \"Species\", island = \"Island\", culmen_length='Culmen Length (mm)', culmen_depth = 'Culmen Depth (mm)', flipper_length = 'Flipper Length (mm)', body_mass = 'Body Mass (g)')\nrename(simplified, all_of(edited_columns))\n\n# A tibble: 344 × 7\n   species      island Sex   culmen_length culmen_depth flipper_length body_mass\n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 Adelie Peng… Torge… MALE           39.1         18.7            181      3750\n 2 Adelie Peng… Torge… FEMA…          39.5         17.4            186      3800\n 3 Adelie Peng… Torge… FEMA…          40.3         18              195      3250\n 4 Adelie Peng… Torge… &lt;NA&gt;           NA           NA               NA        NA\n 5 Adelie Peng… Torge… FEMA…          36.7         19.3            193      3450\n 6 Adelie Peng… Torge… MALE           39.3         20.6            190      3650\n 7 Adelie Peng… Torge… FEMA…          38.9         17.8            181      3625\n 8 Adelie Peng… Torge… MALE           39.2         19.6            195      4675\n 9 Adelie Peng… Torge… &lt;NA&gt;           34.1         18.1            193      3475\n10 Adelie Peng… Torge… &lt;NA&gt;           42           20.2            190      4250\n# ℹ 334 more rows\n\n\nRenaming with a function:. Note the escape codes (double ).\n\nfixer &lt;- function(n) {\n        a &lt;- gsub(\" \\\\(mm\\\\)\",\"\",n)\n        a &lt;- gsub(\" \\\\(g\\\\)\",\"\",a)\n        a &lt;- gsub(\" \",\"_\",a)\n        return(tolower(a))\n}\nsimplified &lt;- rename_with(simplified,fixer)\n\n\nSimplify factor names\n\n\nspecies &lt;- simplified |&gt;\n    select(`species`) |&gt;\n    unique()\nsimplified &lt;- simplified |&gt; mutate(`species` = tolower(word(`species`, 1)))\nsimplified &lt;- simplified |&gt; mutate(`island` = tolower(`island`))\nsimplified &lt;- simplified |&gt; mutate(`sex` = tolower(`sex`))\n\n\nMissing Values\n\nNote use of anonymous function.\n\nsimplified |&gt; summarize_all(\\(x) sum(is.na(x)))\n\n# A tibble: 1 × 7\n  species island   sex culmen_length culmen_depth flipper_length body_mass\n    &lt;int&gt;  &lt;int&gt; &lt;int&gt;         &lt;int&gt;        &lt;int&gt;          &lt;int&gt;     &lt;int&gt;\n1       0      0    11             2            2              2         2\n\n\n\nsimplified |&gt; summarize(across(culmen_length:body_mass,  \\(x) sum(is.na(x))))\n\n# A tibble: 1 × 4\n  culmen_length culmen_depth flipper_length body_mass\n          &lt;int&gt;        &lt;int&gt;          &lt;int&gt;     &lt;int&gt;\n1             2            2              2         2\n\n\n\nsimplified &lt;- simplified |&gt; filter(if_all(names(simplified), \\(x) !is.na(x)))\n\n\nStandardizing\n\nR can do it pretty efficiently using across and mutate.\n\nsimplified |&gt; mutate(across(culmen_length:body_mass, list(std=\\(x) (x-mean(x))/sd(x))))\n\n# A tibble: 333 × 11\n   species island    sex    culmen_length culmen_depth flipper_length body_mass\n   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 adelie  torgersen male            39.1         18.7            181      3750\n 2 adelie  torgersen female          39.5         17.4            186      3800\n 3 adelie  torgersen female          40.3         18              195      3250\n 4 adelie  torgersen female          36.7         19.3            193      3450\n 5 adelie  torgersen male            39.3         20.6            190      3650\n 6 adelie  torgersen female          38.9         17.8            181      3625\n 7 adelie  torgersen male            39.2         19.6            195      4675\n 8 adelie  torgersen female          41.1         17.6            182      3200\n 9 adelie  torgersen male            38.6         21.2            191      3800\n10 adelie  torgersen male            34.6         21.1            198      4400\n# ℹ 323 more rows\n# ℹ 4 more variables: culmen_length_std &lt;dbl&gt;, culmen_depth_std &lt;dbl&gt;,\n#   flipper_length_std &lt;dbl&gt;, body_mass_std &lt;dbl&gt;\n\n\n\nGrouping\n\n\nsimplified |&gt; select(sex:body_mass) |&gt; group_by(sex) |&gt; summarize(across(culmen_length:body_mass,mean))\n\n# A tibble: 2 × 5\n  sex    culmen_length culmen_depth flipper_length body_mass\n  &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 female          42.1         16.4           197.     3862.\n2 male            45.9         17.9           205.     4546.\n\n\n\nby_sex_and_species &lt;- simplified |&gt; group_by(species,sex) |&gt; summarize(across(culmen_length:body_mass,mean))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\nYou can select using filter.\n\nby_sex_and_species |&gt; filter(sex=='male')\n\n# A tibble: 3 × 6\n# Groups:   species [3]\n  species   sex   culmen_length culmen_depth flipper_length body_mass\n  &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 adelie    male           40.4         19.1           192.     4043.\n2 chinstrap male           51.1         19.3           200.     3939.\n3 gentoo    male           49.5         15.7           222.     5485.\n\n\n\nMaking a pivot table.\n\n\nby_sex_and_species |&gt;\n    select(species, sex, culmen_length) |&gt;\n    pivot_wider(names_from = species, values_from = culmen_length)\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   37.3      46.6   45.6\n2 male     40.4      51.1   49.5\n\n\n\nMaking a function for each possibility\n\n\nptable &lt;- function(value) {\n    by_sex_and_species |&gt;\n        select(species, sex, {{ value }}) |&gt;\n        pivot_wider(names_from = species, values_from = {{ value }})\n}\nptable(\"body_mass\")\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female  3369.     3527.  4680.\n2 male    4043.     3939.  5485.",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in R"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/groupingR.html#loading-the-penguins-from-csv",
    "href": "chapters/08-Summarizing/groupingR.html#loading-the-penguins-from-csv",
    "title": "Grouping and Summarizing in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npenguins = read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npenguins |&gt; summarise_all(class)\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species   Region    Island    Stage  `Individual ID`\n  &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;          \n1 character numeric         character character character chara… character      \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;chr&gt;,\n#   `Culmen Length (mm)` &lt;chr&gt;, `Culmen Depth (mm)` &lt;chr&gt;,\n#   `Flipper Length (mm)` &lt;chr&gt;, `Body Mass (g)` &lt;chr&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;chr&gt;, `Delta 13 C (o/oo)` &lt;chr&gt;, Comments &lt;chr&gt;\n\n\n\nFocus on the relevant numerical variables\n\n\nfocus &lt;- c('Species','Island','Sex','Culmen Length (mm)','Culmen Depth (mm)','Flipper Length (mm)','Body Mass (g)')\nsimplified &lt;- penguins |&gt; select(all_of(focus))\n\n\nClean up the column names\n\nUsing a named vector\n\nedited_columns &lt;- c(species = \"Species\", island = \"Island\", culmen_length='Culmen Length (mm)', culmen_depth = 'Culmen Depth (mm)', flipper_length = 'Flipper Length (mm)', body_mass = 'Body Mass (g)')\nrename(simplified, all_of(edited_columns))\n\n# A tibble: 344 × 7\n   species      island Sex   culmen_length culmen_depth flipper_length body_mass\n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 Adelie Peng… Torge… MALE           39.1         18.7            181      3750\n 2 Adelie Peng… Torge… FEMA…          39.5         17.4            186      3800\n 3 Adelie Peng… Torge… FEMA…          40.3         18              195      3250\n 4 Adelie Peng… Torge… &lt;NA&gt;           NA           NA               NA        NA\n 5 Adelie Peng… Torge… FEMA…          36.7         19.3            193      3450\n 6 Adelie Peng… Torge… MALE           39.3         20.6            190      3650\n 7 Adelie Peng… Torge… FEMA…          38.9         17.8            181      3625\n 8 Adelie Peng… Torge… MALE           39.2         19.6            195      4675\n 9 Adelie Peng… Torge… &lt;NA&gt;           34.1         18.1            193      3475\n10 Adelie Peng… Torge… &lt;NA&gt;           42           20.2            190      4250\n# ℹ 334 more rows\n\n\nRenaming with a function:. Note the escape codes (double ).\n\nfixer &lt;- function(n) {\n        a &lt;- gsub(\" \\\\(mm\\\\)\",\"\",n)\n        a &lt;- gsub(\" \\\\(g\\\\)\",\"\",a)\n        a &lt;- gsub(\" \",\"_\",a)\n        return(tolower(a))\n}\nsimplified &lt;- rename_with(simplified,fixer)\n\n\nSimplify factor names\n\n\nspecies &lt;- simplified |&gt;\n    select(`species`) |&gt;\n    unique()\nsimplified &lt;- simplified |&gt; mutate(`species` = tolower(word(`species`, 1)))\nsimplified &lt;- simplified |&gt; mutate(`island` = tolower(`island`))\nsimplified &lt;- simplified |&gt; mutate(`sex` = tolower(`sex`))\n\n\nMissing Values\n\nNote use of anonymous function.\n\nsimplified |&gt; summarize_all(\\(x) sum(is.na(x)))\n\n# A tibble: 1 × 7\n  species island   sex culmen_length culmen_depth flipper_length body_mass\n    &lt;int&gt;  &lt;int&gt; &lt;int&gt;         &lt;int&gt;        &lt;int&gt;          &lt;int&gt;     &lt;int&gt;\n1       0      0    11             2            2              2         2\n\n\n\nsimplified |&gt; summarize(across(culmen_length:body_mass,  \\(x) sum(is.na(x))))\n\n# A tibble: 1 × 4\n  culmen_length culmen_depth flipper_length body_mass\n          &lt;int&gt;        &lt;int&gt;          &lt;int&gt;     &lt;int&gt;\n1             2            2              2         2\n\n\n\nsimplified &lt;- simplified |&gt; filter(if_all(names(simplified), \\(x) !is.na(x)))\n\n\nStandardizing\n\nR can do it pretty efficiently using across and mutate.\n\nsimplified |&gt; mutate(across(culmen_length:body_mass, list(std=\\(x) (x-mean(x))/sd(x))))\n\n# A tibble: 333 × 11\n   species island    sex    culmen_length culmen_depth flipper_length body_mass\n   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 adelie  torgersen male            39.1         18.7            181      3750\n 2 adelie  torgersen female          39.5         17.4            186      3800\n 3 adelie  torgersen female          40.3         18              195      3250\n 4 adelie  torgersen female          36.7         19.3            193      3450\n 5 adelie  torgersen male            39.3         20.6            190      3650\n 6 adelie  torgersen female          38.9         17.8            181      3625\n 7 adelie  torgersen male            39.2         19.6            195      4675\n 8 adelie  torgersen female          41.1         17.6            182      3200\n 9 adelie  torgersen male            38.6         21.2            191      3800\n10 adelie  torgersen male            34.6         21.1            198      4400\n# ℹ 323 more rows\n# ℹ 4 more variables: culmen_length_std &lt;dbl&gt;, culmen_depth_std &lt;dbl&gt;,\n#   flipper_length_std &lt;dbl&gt;, body_mass_std &lt;dbl&gt;\n\n\n\nGrouping\n\n\nsimplified |&gt; select(sex:body_mass) |&gt; group_by(sex) |&gt; summarize(across(culmen_length:body_mass,mean))\n\n# A tibble: 2 × 5\n  sex    culmen_length culmen_depth flipper_length body_mass\n  &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 female          42.1         16.4           197.     3862.\n2 male            45.9         17.9           205.     4546.\n\n\n\nby_sex_and_species &lt;- simplified |&gt; group_by(species,sex) |&gt; summarize(across(culmen_length:body_mass,mean))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\nYou can select using filter.\n\nby_sex_and_species |&gt; filter(sex=='male')\n\n# A tibble: 3 × 6\n# Groups:   species [3]\n  species   sex   culmen_length culmen_depth flipper_length body_mass\n  &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 adelie    male           40.4         19.1           192.     4043.\n2 chinstrap male           51.1         19.3           200.     3939.\n3 gentoo    male           49.5         15.7           222.     5485.\n\n\n\nMaking a pivot table.\n\n\nby_sex_and_species |&gt;\n    select(species, sex, culmen_length) |&gt;\n    pivot_wider(names_from = species, values_from = culmen_length)\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female   37.3      46.6   45.6\n2 male     40.4      51.1   49.5\n\n\n\nMaking a function for each possibility\n\n\nptable &lt;- function(value) {\n    by_sex_and_species |&gt;\n        select(species, sex, {{ value }}) |&gt;\n        pivot_wider(names_from = species, values_from = {{ value }})\n}\nptable(\"body_mass\")\n\n# A tibble: 2 × 4\n  sex    adelie chinstrap gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 female  3369.     3527.  4680.\n2 male    4043.     3939.  5485.",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in R"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html",
    "href": "chapters/07-Calculus/calculus.html",
    "title": "Key ideas from calculus",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-dark')",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#why-calculus-in-data-science",
    "href": "chapters/07-Calculus/calculus.html#why-calculus-in-data-science",
    "title": "Key ideas from calculus",
    "section": "Why Calculus in data science?",
    "text": "Why Calculus in data science?\nThe central application of calculus in data science is in the problem of “optimization.” ML algorithms generally ask for the “best fit” of something, and the “best fit” usually means finding the parameters where a measure of error, a loss function, is as small as possible.\n(Differential) calculus is the most powerful tool we have for finding the minimal (or maximum) values of functions.\nCalculus also plays a key role in Probability and Statistics, because questions about probability in continuous settings relies on the idea of an integral.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#one-variable-differential-calculus",
    "href": "chapters/07-Calculus/calculus.html#one-variable-differential-calculus",
    "title": "Key ideas from calculus",
    "section": "One-variable differential calculus",
    "text": "One-variable differential calculus\n\nSimple function with one input variable and one output variable\nDerivative measures rate of change of output with respect to input\nFamous formula: given a function \\(f:\\mathbf{R}\\to\\mathbf{R}\\), the derivative is defined by \\[\nf'(x) = \\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\n\\]",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#interpretations-of-the-derivative",
    "href": "chapters/07-Calculus/calculus.html#interpretations-of-the-derivative",
    "title": "Key ideas from calculus",
    "section": "Interpretations of the derivative",
    "text": "Interpretations of the derivative\n\n“Slope of the curve”\n“Rate of change”\n\n\nx=np.linspace(0,1, 100)\ny=x**3*(1-x)**5\nplt.plot(x,y)\n1m = (y[41]-y[40])/.01\n2ytan = y[40]+m*(x-x[40])\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('$x^3(1-x)^5$ with tangent line at $x=.4$')\nim = plt.plot(x,ytan)\n\n\n1\n\nHere we compute the (approximate) slope/derivative m at the point (x[40],y[40])\n\n2\n\nThis is the equation of the line through that point with the computed slope.\n\n\n\n\n\n\n\n\n\n\n\nKey facts:\n\nDerivative is positive means function is increasing\nDerivative is negative means function is decreasing\nDerivative is zero means a critical point, often a local maximum or local minimum.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#an-example",
    "href": "chapters/07-Calculus/calculus.html#an-example",
    "title": "Key ideas from calculus",
    "section": "An example",
    "text": "An example\n\nfig, axes = plt.subplots(1, 2, sharey=\"row\")\nfig.set_size_inches(8, 4)\n# ----\nx = np.linspace(0, 1, 100)\ny = x**3 * (1 - x) ** 5\naxes[0].plot(x, y)\nt1 = axes[0].set_title(r\"$f(x)=x^3(1-x)^5$\")\naxes[0].grid()\n# ----\n1yprime = (y[1:] - y[:-1]) / 0.01\naxes[1].plot(x[1:], yprime)\naxes[1].grid()\nt2 = axes[1].set_title(r\"$f'(x)$\")\n\n\n1\n\nThe array y has the y values corresponding to the x values in the array x. So the difference y[1:]-y[:-1] is \\(f(x+h)-f(x)\\). Since there are 100 x values between 0 and 1, \\(h=.01\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#some-key-reminders-from-differential-calculus",
    "href": "chapters/07-Calculus/calculus.html#some-key-reminders-from-differential-calculus",
    "title": "Key ideas from calculus",
    "section": "Some key reminders from differential calculus",
    "text": "Some key reminders from differential calculus\n\nThe derivative is linear, so the derivative of a sum is the sum of the derivatives and the derivative \\((af(x))'\\) is \\(af'(x)\\).\nThe derivative of a constant is zero.\nThe derivative of \\(x^{n}\\) is \\(nx^{n-1}\\).\n\nThe derivative of \\(e^{x}\\) is \\(e^{x}\\).\nThe derivative of \\(\\log(x)\\) is \\(1/x\\) (natural logarithm).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#notation",
    "href": "chapters/07-Calculus/calculus.html#notation",
    "title": "Key ideas from calculus",
    "section": "Notation",
    "text": "Notation\nSometimes we write \\(f'(x)\\), sometimes \\(\\frac{df}{dx}\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-product-rule",
    "href": "chapters/07-Calculus/calculus.html#the-product-rule",
    "title": "Key ideas from calculus",
    "section": "The product rule",
    "text": "The product rule\nThe derivative of a product of functions \\(fg\\) satisfies the product rule \\[\n(fg)'=fg'+f'g\n\\]",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-chain-rule",
    "href": "chapters/07-Calculus/calculus.html#the-chain-rule",
    "title": "Key ideas from calculus",
    "section": "The chain rule",
    "text": "The chain rule\nThe chain rule is a key fact from one variable calculus. Its simple form is\n\\[\n\\frac{d}{dt}f(x+th)|_{t=0}=hf'(x)\n\\]\nand more generally\n\\[\n\\frac{d}{dx}(f(g(x))) = f'(g(x))g'(x)\n\\]",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#functions-of-several-variables",
    "href": "chapters/07-Calculus/calculus.html#functions-of-several-variables",
    "title": "Key ideas from calculus",
    "section": "Functions of several variables",
    "text": "Functions of several variables\nIn data science, we generally want to look at functions that depend on many variables, rather than just one.\nFor example, let us consider the problem of finding the line of best fit to a collection of points \\((x,y)\\).\nFirst we generate some random data to work with.\n\nx=np.linspace(0,5,20)\n1y=3*x+1+np.random.normal(0,2,size=x.shape[0])\nplt.scatter(x,y)\nplt.grid()\nplt.title(\"$y=3+1+\\epsilon$ where $\\epsilon$ is a normal error\")\n\n\n1\n\nHere we find \\(y=3x+1+\\epsilon\\) where \\(\\epsilon\\) is drawn from a normal random variable with standard deviation \\(2\\).\n\n\n\n\nText(0.5, 1.0, '$y=3+1+\\\\epsilon$ where $\\\\epsilon$ is a normal error')\n\n\n\n\n\n\n\n\n\nThe line of best fit has the equation \\(y=mx+b\\) where \\(m\\) and \\(b\\) are the unknowns. The “error” is \\[\nE(m,b) = \\frac{1}{N}\\sum_{i=1}^{N} (y_i-mx_i-b)^2\n\\]\nThe \\(x_i\\) and \\(y_i\\) are the data, and \\(m\\) and \\(b\\) are the things we want to find. So this is a function of two variables.\nIt is a (possibly very big) quadratic function of \\(m\\) and \\(b\\).\nBut in more general regression problems we may have many slopes \\(m_{i}\\) so our error depends on many variables.\nIn neural networks there may be billions of parameters.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#visualization-of-functions-of-two-variables",
    "href": "chapters/07-Calculus/calculus.html#visualization-of-functions-of-two-variables",
    "title": "Key ideas from calculus",
    "section": "Visualization of functions of two variables",
    "text": "Visualization of functions of two variables\nContour plots are a way to represent a function of two variables. For example suppose \\(f(x,y)=3x^2+2xy+5y^22\\).\n\nfig,ax = plt.subplots()\nx=np.linspace(-3,3,40)\ny=np.linspace(-3,3,40)\n1ax.set_aspect('equal')\n2xx,yy = np.meshgrid(x,y)\nz = 3*xx**2+2*xx*yy+5*yy**2\nax.contour(xx,yy,z)\nax.grid()\n\n\n1\n\nWhy do you need this?\n\n2\n\nmeshgrid changes two one-dimensional arrays into two two dimensional arrays - examine them to see what happens.\n\n\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\nfig,ax = plt.subplots()\nx=np.linspace(-10,10,50)\ny=np.linspace(-10,10,50)\nxx,yy = np.meshgrid(x,y)\nz = 3*norm.pdf(np.sqrt((xx-2)**2+(xx-2)*(yy-3)+(yy-3)**2))-5*norm.pdf(np.sqrt((xx+3)**2+(yy+1)**2))\nP=ax.contourf(xx,yy,z,levels=10)\nQ=ax.contour(xx,yy,z,levels=np.linspace(-1,1,19),colors='black')\nt=ax.clabel(Q,inline=True,fontsize=5)\nt=ax.set_title(\"Contour Plot of sum of two Gaussians\")",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#plotting-in-3d",
    "href": "chapters/07-Calculus/calculus.html#plotting-in-3d",
    "title": "Key ideas from calculus",
    "section": "Plotting in 3d",
    "text": "Plotting in 3d\nGenerally 3d plots aren’t that useful, but sometimes you just really want one.\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211,projection='3d')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = norm.pdf(np.sqrt(xx**2+yy**2))\nax.plot_wireframe(xx,yy,z,cmap='gray')\nax = fig.add_subplot(212)\nQ=ax.contour(xx,yy,z)\nax.clabel(Q)\nax.set_aspect('equal')\n\n\n\n\n\n\n\n\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211,projection='3d')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = xx**2-yy**2\nax.plot_wireframe(xx,yy,z,cmap='gray')\nax = fig.add_subplot(212)\nQ=ax.contour(xx,yy,z,levels=10)\nax.clabel(Q)\nax.set_aspect('equal')\nax.grid()",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#vectors-and-functions",
    "href": "chapters/07-Calculus/calculus.html#vectors-and-functions",
    "title": "Key ideas from calculus",
    "section": "Vectors and functions",
    "text": "Vectors and functions\nIt’s useful to think of a function of multiple variables \\(x_1,\\ldots, x_n\\) as a function of a vector \\(\\mathbf{x}=(x_1,\\ldots, x_n)\\).\nIf \\(x_0\\) is a point in \\(\\mathbf{R}^{n}\\) (thought of as a vector) and \\(v\\) is another vector, then the points \\[\n\\ell(t) = x_0+tv\n\\]\ntrace out a line as \\(t\\) varies.\nFor example if \\(x_0=(1,1)\\) and \\(v=(-2,3)\\) then \\[\n\\ell(t) = (1-2t,2+3t)\n\\]\n\n1x = np.array([1,1]).reshape(2,1)\nv = np.array([-2,3]).reshape(2,1)\nt=np.arange(-5,5,1)\npts = x+t*v\nplt.grid()\nplt.plot(pts[0,:],pts[1,:],color='black')\nplt.plot([1],[1],marker=\"*\",markersize=12,color='red')\nplt.arrow(1,1,-2,3,color='blue',width=.4)\nplt.scatter(pts[0,:],pts[1,:])\nplt.title(\"Vector form of a line from (1,1) towards v=(-2,3)\")\nplt.xlabel('x')\n_=plt.ylabel('y')\n\n\n1\n\nTo see why x and v need to be column vectors, try this without the reshape and look at the error you get.\n\n\n\n\n\n\n\n\n\n\n\nIn this version, the vector \\(v\\) represents the velocity of a point travelling along the line. So the dots are the position of the object at different times \\(t\\).\nIf we scale \\(v\\) by a constant:\n\nthe line stays the same\nthe speed is different\n\nThe speed is \\(\\|v\\|\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#directional-derivatives",
    "href": "chapters/07-Calculus/calculus.html#directional-derivatives",
    "title": "Key ideas from calculus",
    "section": "Directional Derivatives",
    "text": "Directional Derivatives\nFor a function of multiple variables, the directional derivative is the rate of change in a particular direction.\n\\[\nD_{v}(f)(\\mathbf{x}) = \\frac{d}{dt}f(\\mathbf{x}+t\\mathbf{v})|_{t=0}\n\\]\nThis means: how fast is \\(f\\) at time zero as you travel through space in a straight line with velocity \\(v\\) passing through point \\(x\\).\nDepends on direction and magnitude of \\(v\\).\nSuppose that \\(f(\\overline{x})=x_1^2-x_0^2\\), that \\(\\mathbf{x}=(1,1)\\) and that \\(v=(-.4,.6)\\) Then\n\\[\n\\mathbf{x}+t\\mathbf{v} = (1-.4t,1+.6t)\n\\]\nand \\[\nf(\\mathbf{x}+t\\mathbf{v}) = (1-.4t)^2-(1+.6t)^2\n\\]\n\nfig = plt.figure()\nfig.set_size_inches(20,10)\nax = fig.add_subplot(211)\nax.set_title('contour plot with path')\nx = np.linspace(-5,5,30)\ny = np.linspace(-5,5,30)\nxx,yy = np.meshgrid(x,y)\nz = xx**2-yy**2\nQ=ax.contour(xx,yy,z,levels=10)\nax.clabel(Q)\nax.set_aspect('equal')\nax.grid()\n\nx = np.array([1,1]).reshape(2,1) \nv = np.array([-.4,.6]).reshape(2,1)\nt=np.arange(-10,10,1)\npts = x+t*v\nax.set_xlim((-5,5))\nax.set_ylim((-5,5))\nax.plot(pts[0,:],pts[1,:],color='black')\nax.plot([1],[1],marker=\"*\",markersize=12,color='red')\nax.arrow(1,1,-.4,.6,color='blue',width=.2)\nax.scatter(pts[0,:],pts[1,:])\n\nax1 = fig.add_subplot(212)\nax1.set_aspect('equal')\nax1.set_xticks(np.arange(-10,11,4))\nax1.set_title('Height vs time along path')\nht = -(1+0.6*t)**2+(1-0.4*t)**2\nax1.plot(np.arange(-10,10,1),ht)\nax1.plot([0],[0],marker='*',markersize=10)\nax1.grid()",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#partial-derivatives",
    "href": "chapters/07-Calculus/calculus.html#partial-derivatives",
    "title": "Key ideas from calculus",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\nThe partial derivatives of a function are the special cases of the directional derivative in the direction of coordinate axes.\nSo if \\(f\\) is a function of \\(\\mathbf{x}=(x_0,\\ldots, x_{n-1})\\) and if \\(\\mathbf{e}_{i}\\) is the vector \\[\ne_{i} = (0,0,\\ldots,0,1,0,\\ldots, 0)\n\\] where the \\(1\\) is in the \\(i^{th}\\) position, then \\[\n\\frac{\\partial f}{\\partial x_{i}}=D_{e_{i}}f.\n\\]\nYou can compute the partial derivatives using calculus rules where you treat all of the variables except \\(x_{i}\\) as constants.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-vector-chain-rule",
    "href": "chapters/07-Calculus/calculus.html#the-vector-chain-rule",
    "title": "Key ideas from calculus",
    "section": "The vector chain rule",
    "text": "The vector chain rule\nThe vector chain rule says that \\[\n\\frac{d}{dt}f(x_1(t),x_2(t),\\ldots, x_n(t))=\\frac{\\partial f}{\\partial x_1}\\frac{d x_1}{d t}+\\frac{\\partial f}{\\partial x_2}\\frac{d x_2}{d t}+\\cdots+\\frac{\\partial f}{\\partial x_n}\\frac{d x_n}{d t}\n\\]\nHere \\((x_1(t),\\ldots,x_n(t))\\) can be thought of as a path where the \\(x_i\\) vary with time \\(t\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-gradient",
    "href": "chapters/07-Calculus/calculus.html#the-gradient",
    "title": "Key ideas from calculus",
    "section": "The gradient",
    "text": "The gradient\nSuppose that \\(f\\) is a function of variables \\(x_1,\\ldots, x_n\\). The gradient of \\(f\\), written \\(\\nabla f\\), is a vector valued function where\n\\[\n\\nabla f (x) = \\left[\\begin{matrix} \\frac{\\partial f}{\\partial x_0} & \\frac{\\partial f}{\\partial x_1} & \\cdots & \\frac{\\partial f}{\\partial x_n} \\end{matrix}\\right]\n\\]\nThe gradient of \\(f\\) gives a vector at each point.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#key-property-of-the-gradient",
    "href": "chapters/07-Calculus/calculus.html#key-property-of-the-gradient",
    "title": "Key ideas from calculus",
    "section": "Key property of the gradient",
    "text": "Key property of the gradient\nTheorem: If \\(v\\) is any vector, then the directional derivative \\(D_{v}(f)=\\nabla f \\cdot v\\). As a result of this fact:\n\nThe gradient points in the direction where \\(f\\) increases most rapidly.\n\\(-\\nabla f\\) points in the direction where \\(f\\) decreases most rapidly.\nThe gradient is perpendicular to the contour lines of the function.\nThe gradient is zero at local minima and maxima of a function (but possibly also at other places)\n\nThese facts follow from the chain rule and properties of the dot product.\nFirst of all, \\[\nD_{v}(f)(\\mathbf{x}) = \\frac{d}{dt}f(\\mathbf{x}+t\\mathbf{v})=f(x_1+tv_1,x_2+tv_2,\\ldots, x_n+tv_n)|_{t=0}\n\\]\nFrom the vector chain rule this is the same as\n\\[\nD_{v}(f)(\\mathbf{x}) = \\frac{\\partial f}{\\partial x_1}v_1+\\frac{\\partial f}{\\partial x_2}v_2+\\cdots+\\frac{\\partial f}{\\partial x_n}v_{n}|_{t=0}\n\\] which is\n\\[\n(\\nabla f)(\\mathbf{x})\\cdot \\mathbf{v}.\n\\]\nBut the dot product satisfies\n\\[\n(\\nabla f)(\\mathbf{x})\\cdot \\mathbf{v} = \\|(\\nabla f)(\\mathbf{x})\\|\\|v\\|\\cos(\\theta)\n\\]\nwhere \\(\\theta\\) is the angle between the gradient and the vector \\(v\\). This is maximum when \\(\\theta=0\\), and minimum when \\(\\theta=\\pi\\).\nTo see the significance of this, check out this page..",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#functions-from-mathbfrm-to-mathbfrn-and-their-derivatives",
    "href": "chapters/07-Calculus/calculus.html#functions-from-mathbfrm-to-mathbfrn-and-their-derivatives",
    "title": "Key ideas from calculus",
    "section": "Functions from \\(\\mathbf{R}^{m}\\) to \\(\\mathbf{R}^{n}\\) and their derivatives",
    "text": "Functions from \\(\\mathbf{R}^{m}\\) to \\(\\mathbf{R}^{n}\\) and their derivatives\nThe most general situation we might want to consider is a function that converts a point in \\(\\mathbf{R}^{m}\\) to a point in \\(\\mathbf{R}^{n}\\):\n\\[\nF:\\mathbf{R}^{m}\\to \\mathbf{R}^{n}\n\\]\nHere is an example. Suppose we have \\(28\\times 28\\) images represented as arrays of pixel values. And suppose that we know that this image is a handwritten number between \\(0\\) and \\(9\\).\nAn image recognition neural network takes such an image an outputs a vector of length \\(10\\) of the form \\((p_0,\\ldots, p_{9})\\) where \\(p_i\\) is the probability that the image represents the digit \\(i\\).\nThis neural network is a function \\(F:\\mathbf{R}^{784}\\to \\mathbf{R}^{10}\\).\nSuch a function is actually given by \\(10\\) (or, more generally, \\(n\\)) “coordinate functions” \\(f_{i}\\), each of which is a function of \\(m\\) variables. So the neural network function \\(F\\) consists of functions \\[\np_{i} = F_{i}(x_0,\\ldots, x_{783})\\quad i=0,\\ldots, 9\n\\]\nEach of these functions has a gradient which measures how \\(p_{i}\\) changes if you modify the \\(x_i\\). The total derivative of \\(F\\) is made up of all of these gradients. You can think of this as a column vector of row vectors: \\[\nDF = \\left[\\begin{matrix} \\nabla F_{0} \\\\ \\nabla F_{1} \\\\  \\cdots \\\\ \\nabla F_{n}\\end{matrix}\\right]\n\\]\nwhere each \\(\\nabla F_{i}\\) is a row with \\(m\\) entries.\nBut this is really a matrix called the total derivative \\(DF\\) of \\(F\\) of size \\(n\\times m\\).\nThe total derivative tells us how a small step in \\(\\mathbf{R}^{m}\\) translates to a step in \\(\\mathbf{R}^{m}\\) when you apply the function \\(F:\\mathbf{R}^{m}\\to mathbf{R}^{n}\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#linear-functions",
    "href": "chapters/07-Calculus/calculus.html#linear-functions",
    "title": "Key ideas from calculus",
    "section": "Linear functions",
    "text": "Linear functions\nA very special case of a function from \\(F:\\mathbf{R}^{m}\\to mathbf{R}^{n}\\) is the situation where \\[\nF(x) = Ax\n\\] for an \\(n\\times m\\) matrix.\nIn this special case, the total derivative \\(DF\\) of \\(F\\) is the matrix \\(A\\).",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/07-Calculus/calculus.html#the-chain-rule-in-the-general-case",
    "href": "chapters/07-Calculus/calculus.html#the-chain-rule-in-the-general-case",
    "title": "Key ideas from calculus",
    "section": "The chain rule in the general case",
    "text": "The chain rule in the general case\nIf \\(F:\\mathbf{R}^{m}\\to\\mathbf{R}^{n}\\) is a function, and \\(G:\\mathbf{R}^{n}\\to\\mathbf{R}^{k}\\) is another function, then it makes sense to compute \\(G(F(x))\\) for \\(x\\in \\mathbf{R}^{m}\\), and the result is in \\(\\mathbf{R}^{k}\\).\nThe chain rule in general says that the derivative of \\(G(F(x))\\) is the product of the matrices corresponding to \\(DG\\) and \\(DF\\). Here \\(DG\\) is \\(k\\times n\\) and \\(DF\\) is \\(n\\times m\\) so \\((DG)(DF)\\) is \\(k\\times m\\) as it should be.",
    "crumbs": [
      "Contents",
      "Key ideas from calculus"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html",
    "title": "Overview of linear algebra operations in python",
    "section": "",
    "text": "The numpy library is the main tool for linear algebra in python.\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#creating-and-shaping-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#creating-and-shaping-arrays",
    "title": "Overview of linear algebra operations in python",
    "section": "Creating and shaping arrays",
    "text": "Creating and shaping arrays\n\nm = np.array([1, 2, 3, 4, 5, 6, 7, 8])\nprint(\"Array {} with shape {} (a row vector)\".format(m, m.shape))\nprint(\"Reshaped array to shape (2,4):\\n {}\".format(m.reshape((2, 4))))\nprint(\"Reshaped array to column vector:\\n {}\".format(m.reshape(8, 1)))\n\nArray [1 2 3 4 5 6 7 8] with shape (8,) (a row vector)\nReshaped array to shape (2,4):\n [[1 2 3 4]\n [5 6 7 8]]\nReshaped array to column vector:\n [[1]\n [2]\n [3]\n [4]\n [5]\n [6]\n [7]\n [8]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#some-special-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#some-special-arrays",
    "title": "Overview of linear algebra operations in python",
    "section": "Some special arrays",
    "text": "Some special arrays\n\none = np.ones(shape=(3, 4))\nprint(one)\nzero = np.zeros(shape=(3, 3))\nprint(zero)\nd = np.diag([1, 2, 3, 4])\nprint(d)\n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]]\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n[[1 0 0 0]\n [0 2 0 0]\n [0 0 3 0]\n [0 0 0 4]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#addition-and-scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#addition-and-scalar-multiplication",
    "title": "Overview of linear algebra operations in python",
    "section": "Addition and scalar multiplication",
    "text": "Addition and scalar multiplication\n\nx = np.random.normal(size=(4,))\ny = np.random.normal(size=(4,))\nprint(x + y)\nu = np.random.normal(size=(2,))\ntry:\n    print(x + u)\nexcept:\n    print(\"Cant Mix These\")\n\n[-2.90839378 -0.01357038  0.96905919 -0.36294849]\nCant Mix These"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#broadcasting",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#broadcasting",
    "title": "Overview of linear algebra operations in python",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nx = np.array([[1, 2], [3, 4]])\nprint(\"x={}\".format(x))\nprint(\"x-1={}\".format(x - 1))\nz = np.array([1, 2])\nprint(\"z={}\".format(z))\nprint(\"x-z={}\".format(x - z))\nz = np.array([[3], [4]])\nprint(\"z={}\".format(z))\nprint(\"x-z={}\".format(x - z))\n\nx=[[1 2]\n [3 4]]\nx-1=[[0 1]\n [2 3]]\nz=[1 2]\nx-z=[[0 0]\n [2 2]]\nz=[[3]\n [4]]\nx-z=[[-2 -1]\n [-1  0]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#element-by-element",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#element-by-element",
    "title": "Overview of linear algebra operations in python",
    "section": "Element by Element",
    "text": "Element by Element\n\nx = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\nprint(1 / x)\nprint(np.log(x))\n\n[[1.         0.5        0.33333333]\n [0.5        0.33333333 0.25      ]\n [0.25       0.2        0.16666667]]\n[[0.         0.69314718 1.09861229]\n [0.69314718 1.09861229 1.38629436]\n [1.38629436 1.60943791 1.79175947]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#multiplication",
    "title": "Overview of linear algebra operations in python",
    "section": "Multiplication",
    "text": "Multiplication\n\nx = np.random.normal(size=(3, 4))\nprint(x)\ny = np.random.normal(size=(4, 1))\nprint(y)\nprint(x @ y)\n\n[[-0.58914788 -0.90874101 -0.91231867  1.00597242]\n [ 0.21335758 -0.83408568  0.44346377 -0.41042791]\n [ 0.94887172  0.56755109  0.15327776 -1.01755127]]\n[[-0.49361085]\n [-0.96601883]\n [ 0.08485529]\n [ 0.31113705]]\n[[ 1.40425094]\n [ 0.61035777]\n [-1.32022988]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#transpose",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#transpose",
    "title": "Overview of linear algebra operations in python",
    "section": "Transpose",
    "text": "Transpose\n\nx = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\nprint(x)\nprint(x.transpose())\n\n[[1 2 3]\n [2 3 4]\n [3 4 5]]\n[[1 2 3]\n [2 3 4]\n [3 4 5]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#norm",
    "title": "Overview of linear algebra operations in python",
    "section": "Norm",
    "text": "Norm\n\nx = np.array([[1, 2], [3, 4]])\nprint(x)\ny = np.linalg.norm(x)\nprint(y)\ny = np.linalg.norm(x, axis=0)\nprint(\"axis=0 yields row norms: {}\".format(y))\ny = np.linalg.norm(x, axis=1)\nprint(\"axis=1 yields column norms: {}\".format(y))\n\n[[1 2]\n [3 4]]\n5.477225575051661\naxis=0 yields row norms: [3.16227766 4.47213595]\naxis=1 yields column norms: [2.23606798 5.        ]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#rank",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#rank",
    "title": "Overview of linear algebra operations in python",
    "section": "Rank",
    "text": "Rank\n\nx = np.array([[1,2],[3,4]])\nnp.linalg.matrix_rank(x)\n\n2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#dataframes-and-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#dataframes-and-matrices",
    "title": "Overview of linear algebra operations in python",
    "section": "Dataframes and matrices",
    "text": "Dataframes and matrices\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\nprint(data[[\"Body Mass (g)\"]])\nprint(data[[\"Body Mass (g)\"]].values)\n\n     Body Mass (g)\n0           3750.0\n1           3800.0\n2           3250.0\n3              NaN\n4           3450.0\n..             ...\n339         4000.0\n340         3400.0\n341         3775.0\n342         4100.0\n343         3775.0\n\n[344 rows x 1 columns]\n[[3750.]\n [3800.]\n [3250.]\n [  nan]\n [3450.]\n [3650.]\n [3625.]\n [4675.]\n [3475.]\n [4250.]\n [3300.]\n [3700.]\n [3200.]\n [3800.]\n [4400.]\n [3700.]\n [3450.]\n [4500.]\n [3325.]\n [4200.]\n [3400.]\n [3600.]\n [3800.]\n [3950.]\n [3800.]\n [3800.]\n [3550.]\n [3200.]\n [3150.]\n [3950.]\n [3250.]\n [3900.]\n [3300.]\n [3900.]\n [3325.]\n [4150.]\n [3950.]\n [3550.]\n [3300.]\n [4650.]\n [3150.]\n [3900.]\n [3100.]\n [4400.]\n [3000.]\n [4600.]\n [3425.]\n [2975.]\n [3450.]\n [4150.]\n [3500.]\n [4300.]\n [3450.]\n [4050.]\n [2900.]\n [3700.]\n [3550.]\n [3800.]\n [2850.]\n [3750.]\n [3150.]\n [4400.]\n [3600.]\n [4050.]\n [2850.]\n [3950.]\n [3350.]\n [4100.]\n [3050.]\n [4450.]\n [3600.]\n [3900.]\n [3550.]\n [4150.]\n [3700.]\n [4250.]\n [3700.]\n [3900.]\n [3550.]\n [4000.]\n [3200.]\n [4700.]\n [3800.]\n [4200.]\n [3350.]\n [3550.]\n [3800.]\n [3500.]\n [3950.]\n [3600.]\n [3550.]\n [4300.]\n [3400.]\n [4450.]\n [3300.]\n [4300.]\n [3700.]\n [4350.]\n [2900.]\n [4100.]\n [3725.]\n [4725.]\n [3075.]\n [4250.]\n [2925.]\n [3550.]\n [3750.]\n [3900.]\n [3175.]\n [4775.]\n [3825.]\n [4600.]\n [3200.]\n [4275.]\n [3900.]\n [4075.]\n [2900.]\n [3775.]\n [3350.]\n [3325.]\n [3150.]\n [3500.]\n [3450.]\n [3875.]\n [3050.]\n [4000.]\n [3275.]\n [4300.]\n [3050.]\n [4000.]\n [3325.]\n [3500.]\n [3500.]\n [4475.]\n [3425.]\n [3900.]\n [3175.]\n [3975.]\n [3400.]\n [4250.]\n [3400.]\n [3475.]\n [3050.]\n [3725.]\n [3000.]\n [3650.]\n [4250.]\n [3475.]\n [3450.]\n [3750.]\n [3700.]\n [4000.]\n [4500.]\n [5700.]\n [4450.]\n [5700.]\n [5400.]\n [4550.]\n [4800.]\n [5200.]\n [4400.]\n [5150.]\n [4650.]\n [5550.]\n [4650.]\n [5850.]\n [4200.]\n [5850.]\n [4150.]\n [6300.]\n [4800.]\n [5350.]\n [5700.]\n [5000.]\n [4400.]\n [5050.]\n [5000.]\n [5100.]\n [4100.]\n [5650.]\n [4600.]\n [5550.]\n [5250.]\n [4700.]\n [5050.]\n [6050.]\n [5150.]\n [5400.]\n [4950.]\n [5250.]\n [4350.]\n [5350.]\n [3950.]\n [5700.]\n [4300.]\n [4750.]\n [5550.]\n [4900.]\n [4200.]\n [5400.]\n [5100.]\n [5300.]\n [4850.]\n [5300.]\n [4400.]\n [5000.]\n [4900.]\n [5050.]\n [4300.]\n [5000.]\n [4450.]\n [5550.]\n [4200.]\n [5300.]\n [4400.]\n [5650.]\n [4700.]\n [5700.]\n [4650.]\n [5800.]\n [4700.]\n [5550.]\n [4750.]\n [5000.]\n [5100.]\n [5200.]\n [4700.]\n [5800.]\n [4600.]\n [6000.]\n [4750.]\n [5950.]\n [4625.]\n [5450.]\n [4725.]\n [5350.]\n [4750.]\n [5600.]\n [4600.]\n [5300.]\n [4875.]\n [5550.]\n [4950.]\n [5400.]\n [4750.]\n [5650.]\n [4850.]\n [5200.]\n [4925.]\n [4875.]\n [4625.]\n [5250.]\n [4850.]\n [5600.]\n [4975.]\n [5500.]\n [4725.]\n [5500.]\n [4700.]\n [5500.]\n [4575.]\n [5500.]\n [5000.]\n [5950.]\n [4650.]\n [5500.]\n [4375.]\n [5850.]\n [4875.]\n [6000.]\n [4925.]\n [  nan]\n [4850.]\n [5750.]\n [5200.]\n [5400.]\n [3500.]\n [3900.]\n [3650.]\n [3525.]\n [3725.]\n [3950.]\n [3250.]\n [3750.]\n [4150.]\n [3700.]\n [3800.]\n [3775.]\n [3700.]\n [4050.]\n [3575.]\n [4050.]\n [3300.]\n [3700.]\n [3450.]\n [4400.]\n [3600.]\n [3400.]\n [2900.]\n [3800.]\n [3300.]\n [4150.]\n [3400.]\n [3800.]\n [3700.]\n [4550.]\n [3200.]\n [4300.]\n [3350.]\n [4100.]\n [3600.]\n [3900.]\n [3850.]\n [4800.]\n [2700.]\n [4500.]\n [3950.]\n [3650.]\n [3550.]\n [3500.]\n [3675.]\n [4450.]\n [3400.]\n [4300.]\n [3250.]\n [3675.]\n [3325.]\n [3950.]\n [3600.]\n [4050.]\n [3350.]\n [3450.]\n [3250.]\n [4050.]\n [3800.]\n [3525.]\n [3950.]\n [3650.]\n [3650.]\n [4000.]\n [3400.]\n [3775.]\n [4100.]\n [3775.]]"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_python.html#datatypes",
    "href": "chapters/06-LinearAlgebra/linear_algebra_python.html#datatypes",
    "title": "Overview of linear algebra operations in python",
    "section": "Datatypes",
    "text": "Datatypes\n\nx = np.array([[1, 2, 3], [2, 3, 4]], dtype=int)\nprint(x)\ny = np.array([[1, 2, 3], [2, 3, 4]], dtype=float)\nprint(y)\nprint(x + y)\n\n[[1 2 3]\n [2 3 4]]\n[[1. 2. 3.]\n [2. 3. 4.]]\n[[2. 4. 6.]\n [4. 6. 8.]]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html",
    "href": "chapters/05-WorkingWithData/r_programming.html",
    "title": "Basics of Programming in R",
    "section": "",
    "text": "The assignment operator in R is &lt;-\nThere is no built-in “dictionary” datatype.\nThe basic datatype in R is the vector, which contains objects of the same type.\n\nVectors are indexed from 1.\n\n\n# n\nx &lt;- c(\"Hello\", 1)\nclass(x)\n\n[1] \"character\"\n\n\nNotice that x is now all characters, and in fact if you now compute 2*x[2] you will get an error.\n\nRanges are inclusive\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nTRUE and FALSE instead of True and False\nindentation does not matter and you can use ; to string multiple statements together.\n\n\nx &lt;- 1\ny &lt;- 1\nz &lt;- 1\n\n\nlength gives the length of a vector, nchar gives the number of characters of a string.\n\n\nlength(\"Hello\")\n\n[1] 1\n\n\n\nlength(c(\"Hello\", \"GoodBye\"))\n\n[1] 2\n\n\n\nnchar(\"Hello\")\n\n[1] 5\n\n\n\nnchar(c(\"Hello\", \"GoodBye\"))\n\n[1] 5 7\n\n\n\nYou need to use substr to extract substrings, not subscripts.\n\n\ns &lt;- \"Hello\"\ns[1]\n\n[1] \"Hello\"\n\n\n\nConvert a vector to a string\n\n\ns &lt;- paste(c(\"A\", \"B\", \"C\"), collapse = \"\")\nt &lt;- paste(c(\"A\", \"B\", \"C\"), c(\"D\", \"E\", \"F\"), sep = \",\", collapse = \" \")\nprint(s)\n\n[1] \"ABC\"\n\nprint(t)\n\n[1] \"A,D B,E C,F\"\n\n\n\ns &lt;- \"This is a string of letters\"\nt &lt;- substr(rep(s, nchar(s) / 2), seq(1, nchar(s), 2), seq(1, nchar(s), 2))\npaste(t, collapse = \"\")\n\n[1] \"Ti sasrn flte\""
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#some-basic-characteristics-of-r",
    "href": "chapters/05-WorkingWithData/r_programming.html#some-basic-characteristics-of-r",
    "title": "Basics of Programming in R",
    "section": "",
    "text": "The assignment operator in R is &lt;-\nThere is no built-in “dictionary” datatype.\nThe basic datatype in R is the vector, which contains objects of the same type.\n\nVectors are indexed from 1.\n\n\n# n\nx &lt;- c(\"Hello\", 1)\nclass(x)\n\n[1] \"character\"\n\n\nNotice that x is now all characters, and in fact if you now compute 2*x[2] you will get an error.\n\nRanges are inclusive\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nTRUE and FALSE instead of True and False\nindentation does not matter and you can use ; to string multiple statements together.\n\n\nx &lt;- 1\ny &lt;- 1\nz &lt;- 1\n\n\nlength gives the length of a vector, nchar gives the number of characters of a string.\n\n\nlength(\"Hello\")\n\n[1] 1\n\n\n\nlength(c(\"Hello\", \"GoodBye\"))\n\n[1] 2\n\n\n\nnchar(\"Hello\")\n\n[1] 5\n\n\n\nnchar(c(\"Hello\", \"GoodBye\"))\n\n[1] 5 7\n\n\n\nYou need to use substr to extract substrings, not subscripts.\n\n\ns &lt;- \"Hello\"\ns[1]\n\n[1] \"Hello\"\n\n\n\nConvert a vector to a string\n\n\ns &lt;- paste(c(\"A\", \"B\", \"C\"), collapse = \"\")\nt &lt;- paste(c(\"A\", \"B\", \"C\"), c(\"D\", \"E\", \"F\"), sep = \",\", collapse = \" \")\nprint(s)\n\n[1] \"ABC\"\n\nprint(t)\n\n[1] \"A,D B,E C,F\"\n\n\n\ns &lt;- \"This is a string of letters\"\nt &lt;- substr(rep(s, nchar(s) / 2), seq(1, nchar(s), 2), seq(1, nchar(s), 2))\npaste(t, collapse = \"\")\n\n[1] \"Ti sasrn flte\""
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#lists",
    "href": "chapters/05-WorkingWithData/r_programming.html#lists",
    "title": "Basics of Programming in R",
    "section": "Lists",
    "text": "Lists\nA list can contain objects of different types.\n\nlst &lt;- list(\"a\", 1.5)\n\nIn particular, a list can contain vectors and can have named entries.\n\nlst &lt;- list(first = c(1, 2, 3), second = c(4, 5, 6))\nprint(lst)\n\n$first\n[1] 1 2 3\n\n$second\n[1] 4 5 6\n\n\nThe presence of [[]] indicates a list.\n\nprint(lst[[1]])\n\n[1] 1 2 3\n\nprint(lst$first)\n\n[1] 1 2 3\n\n\n\nclass(lst[1])\n\n[1] \"list\"\n\nclass(lst[[1]])\n\n[1] \"numeric\"\n\n\n\nSplit a string to a list\n\n\na &lt;- strsplit(\"This is a string\", split = \" \")\nb &lt;- strsplit(\"this is a string split into letters\", split = \"\")\nprint(a)\n\n[[1]]\n[1] \"This\"   \"is\"     \"a\"      \"string\"\n\nprint(b)\n\n[[1]]\n [1] \"t\" \"h\" \"i\" \"s\" \" \" \"i\" \"s\" \" \" \"a\" \" \" \"s\" \"t\" \"r\" \"i\" \"n\" \"g\" \" \" \"s\" \"p\"\n[20] \"l\" \"i\" \"t\" \" \" \"i\" \"n\" \"t\" \"o\" \" \" \"l\" \"e\" \"t\" \"t\" \"e\" \"r\" \"s\"\n\n\n\nExtract every other letter"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#functions",
    "href": "chapters/05-WorkingWithData/r_programming.html#functions",
    "title": "Basics of Programming in R",
    "section": "Functions",
    "text": "Functions\nFunctions are constructed like this:\n\nf &lt;- function(n) {\n    n**2\n}\nf(5)\n\n[1] 25\n\n\nThe last evaluated expression is the value of the function but it is better style to actually use the return statement.\n\nf &lt;- function(n) {\n    return(n**2)\n}\nf(10)\n\n[1] 100\n\n\nFunctions are automatically “vectorized.”\n\nf(1:10)\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nR automatically “recyles” when things fit.\n\n1:3 + 1:6\n\n[1] 2 4 6 5 7 9\n\n\nThe principle of scope is essentially the same as discussed in the python programming notes."
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#iteration-in-r",
    "href": "chapters/05-WorkingWithData/r_programming.html#iteration-in-r",
    "title": "Basics of Programming in R",
    "section": "Iteration in R",
    "text": "Iteration in R\n\ny &lt;- 0\nfor (x in c(1, 2, 3, 10)) {\n    print(x)\n    y &lt;- y + x\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 10\n\ncat(\"y=\", y)\n\ny= 16\n\n\n\ny&lt;-0\nwhile(y&lt;10) {\n    cat(\"y = \",y,\" \",sep=\"\")\n    y &lt;- y+1\n}\n\ny = 0 y = 1 y = 2 y = 3 y = 4 y = 5 y = 6 y = 7 y = 8 y = 9 \n\n\nOften iteration in R is unnecessary. Suppose you want to compute the sum of the squares of the first n integers.\n\nf &lt;- function(n) {\n    s &lt;- 0\n    for (i in seq(1, n)) {\n        s &lt;- s + i^2\n    }\n    return(s)\n}\nf(10)\n\n[1] 385\n\n\n\nf &lt;- function(n) {\n    return(sum(seq(1, n)^2))\n}\nf(10)\n\n[1] 385"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#logical-statements",
    "href": "chapters/05-WorkingWithData/r_programming.html#logical-statements",
    "title": "Basics of Programming in R",
    "section": "Logical statements",
    "text": "Logical statements\n\nif(substr(\"Hesterday\",1,1)==\"H\") {\n    print(\"Yes\")\n} else {\n    print(\"No\")\n}\n\n[1] \"Yes\"\n\n\n\nless_than_one &lt;- function(x) {\nif (any(x&lt;1)) {\n    print(\"Yes\")\n} \nelse {\n    print(\"No\")\n}\n}\n\nAgain you can avoid iteration.\n\nx &lt;- rnorm(20)\nx[x &lt; 1]\n\n [1]  0.01006578 -0.23673463 -0.23173936  0.32124741  0.22064375 -0.10364285\n [7]  0.80566240  0.50677133 -0.99872640 -0.57735191  0.96587941 -0.67340338\n[13] -1.14266055  0.08902873 -1.97807168  0.39255086  0.70728055"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#example",
    "href": "chapters/05-WorkingWithData/r_programming.html#example",
    "title": "Basics of Programming in R",
    "section": "Example",
    "text": "Example\nTake a string and make its first character upper case and the rest lower.\n\nf&lt;-function(s) {\n    a&lt;-paste(toupper(substr(s,1,1)),substr(s,2,nchar(s)),sep=\"\")\n    return(a)\n}\n\nYou can assign to substrings.\n\nf&lt;-function(s) {\n    substr(s,1,1)&lt;-toupper(substr(s,1,1))\n    return(s)\n}"
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_programming.html#problems",
    "href": "chapters/05-WorkingWithData/r_programming.html#problems",
    "title": "Basics of Programming in R",
    "section": "Problems",
    "text": "Problems\n\nWrite a function which takes a string and standardizes it by:\n\nremoves all characters which are not letters, numbers, or spaces\nmakes all the letters lower case\nreplacing all spaces by underscore ’_’\n\n\nHint: convert the string to a vector of letters\n\nThe object penguins_raw is a “tibble”, which is a fancy type of tabular layout. It has named columns that you can extract with $.\n\n\nlibrary(palmerpenguins)\n# view(penguins_raw)\ncolnames(penguins_raw)\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nBy assigning to colnames you can change the column names. (In other words, colnames(penguins_raw)&lt;-c(...) replaces the column names from the given vector. Use your function from part(1) to simplify the column names of this tibble.\n\nYou can access a column of the tibble using $, so for example penguins_raw$species should give you the vector of species. Replace this column with just the first word of the species name (Gentoo, Adelie, Chinstrap).\nLet \\(n\\) be a positive real number and let \\(x_0\\) be 1. The iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\n\nconverges to the square root of \\(n\\). (This is Newton’s Method). Write an R function which computes the square root using this iteration. You should continue to iterate until \\(x_{k+1}\\) is within \\(10^{-6}\\) of \\(x_{k}\\).\n\n#f&lt;-function(n) {\n\n#}\n\nSuppose you want to save the successive values you computed during the iteration for plotting purposes. How could you do that (and return them)?\nSuppose you want the tolerance (here \\(10^{6}\\)) to be a parameter?\nSuppose you want to set a maximum number of iterations, in case something goes wrong, to prevent an infinite loop?"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html",
    "href": "chapters/05-WorkingWithData/python_programming.html",
    "title": "Basics of Programming in Python",
    "section": "",
    "text": "Key ingredients of programming language:\n\ndata types and data structures\nfunctions\ncontrol flow (iteration and logical branches)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#basics-of-programming-in-python",
    "href": "chapters/05-WorkingWithData/python_programming.html#basics-of-programming-in-python",
    "title": "Basics of Programming in Python",
    "section": "",
    "text": "Key ingredients of programming language:\n\ndata types and data structures\nfunctions\ncontrol flow (iteration and logical branches)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#key-data-types-in-python",
    "href": "chapters/05-WorkingWithData/python_programming.html#key-data-types-in-python",
    "title": "Basics of Programming in Python",
    "section": "Key data types in python",
    "text": "Key data types in python\n\nnumbers (integers and floating point)\nstrings\nlists\nnumpy arrays (*)\ndictionaries\npandas dataframes (*)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#basic-examples",
    "href": "chapters/05-WorkingWithData/python_programming.html#basic-examples",
    "title": "Basics of Programming in Python",
    "section": "Basic examples",
    "text": "Basic examples\nFrom before, remember:\n\nn = 56  # integer\nm = 1234.48  # floating point\nL = [1, 2, 3, 4]  # list\nname = \"Jeremy\"  # string\n\nThe typeof operator tells you what something is.\n\nprint(\"type of n is {}, type of name is {}\".format(type(n), type(name)))\n\ntype of n is &lt;class 'int'&gt;, type of name is &lt;class 'str'&gt;"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#working-with-lists-and-strings",
    "href": "chapters/05-WorkingWithData/python_programming.html#working-with-lists-and-strings",
    "title": "Basics of Programming in Python",
    "section": "Working with Lists and Strings",
    "text": "Working with Lists and Strings\nSplit a string to a list.\n\nL = list(\"My name is Jeremy\")\nprint(L)\n\n['M', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'J', 'e', 'r', 'e', 'm', 'y']\n\n\nJoin a list to a string.\n\nprint(''.join([\"A\",\"B\",\"C\"]))\nprint('_'.join([\"A\",\"B\",\"C\"]))\n\nABC\nA_B_C"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#dictionaries",
    "href": "chapters/05-WorkingWithData/python_programming.html#dictionaries",
    "title": "Basics of Programming in Python",
    "section": "Dictionaries",
    "text": "Dictionaries\nA dictionary (or a HashMap, or an associative array) is like an array with arbitrary subscripts.\n\nD = {\"first_name\": \"Jeremy\", \"last_name\": \"Teitelbaum\"}\nD[\"middle_name\"] = \"Thau\"\nprint(D[\"first_name\"])\nD[\"Title\"] = \"Emperor\"\nprint(D)\n# D[\"Subtitle\"]\n\nJeremy\n{'first_name': 'Jeremy', 'last_name': 'Teitelbaum', 'middle_name': 'Thau', 'Title': 'Emperor'}"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#arrays",
    "href": "chapters/05-WorkingWithData/python_programming.html#arrays",
    "title": "Basics of Programming in Python",
    "section": "Arrays",
    "text": "Arrays\n\nimport numpy as np\n\nx=np.array([1,2,3,4])\nx=np.linspace(-5,5,10)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#booleans",
    "href": "chapters/05-WorkingWithData/python_programming.html#booleans",
    "title": "Basics of Programming in Python",
    "section": "Booleans",
    "text": "Booleans\n\nT = True\nF = False\nprint(T or F) # or\nprint(T and F) # and \n3 == 5 # equality\n3 &gt; 5 # \n3 &lt; 5 #\nx = (3 &lt;= 5) #\nprint(x)\ny = (3 != 5) #\nprint(y)\n\nTrue\nFalse\nTrue\nTrue"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#functions",
    "href": "chapters/05-WorkingWithData/python_programming.html#functions",
    "title": "Basics of Programming in Python",
    "section": "Functions",
    "text": "Functions\n\nimport scipy.stats as sps\n\ndef my_function(n,mu,s):\n    x = sps.norm.rvs(mu,s,size=n)\n    return x\n\nImportant concepts: - arguments - scope - return values"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#scope",
    "href": "chapters/05-WorkingWithData/python_programming.html#scope",
    "title": "Basics of Programming in Python",
    "section": "Scope",
    "text": "Scope\nBasic rule of scope: Variables created inside functions are completely separate from those outside the function, changing them has no effect.\nException: some operations (such as list append) modify an element in place and in these cases you may end up modifying something.\n\ndef f(a,b):\n    x=a+b\n    return x\n\n\nx=3\nprint(\"before executing f, x={}\".format(x))\nprint(f(2,5))\nprint(\"after executing f, x={}\".format(x))\n\nbefore executing f, x=3\n7\nafter executing f, x=3\n\n\n\ndef f(x):\n    x=x+[\"d\"]\n    return x\n\nL=[\"a\",\"b\",\"c\"]\nprint(\"L before is {}\".format(L))\nprint(\"result of f(L) is {}\".format(f(L)))\nprint(\"L after is {}\".format(L))\n\nL before is ['a', 'b', 'c']\nresult of f(L) is ['a', 'b', 'c', 'd']\nL after is ['a', 'b', 'c']\n\n\n\ndef f(x):\n    x.append(\"d\") #\n    return x\n\n# Warning\nx = [\"a\",\"b\",\"c\"]\nprint(f(x))\nprint(x)\n\n['a', 'b', 'c', 'd']\n['a', 'b', 'c', 'd']\n\n\n\nx = 55\n\ndef f(n):\n    n = n+x\n    return n\n\nf(24)\n\n79"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#iteration",
    "href": "chapters/05-WorkingWithData/python_programming.html#iteration",
    "title": "Basics of Programming in Python",
    "section": "Iteration",
    "text": "Iteration\n\nfor x in range(10):\n    print(x,end=',')\nprint('\\n---')\n\nfor x in [\"a\",\"b\",\"c\"]:\n    print(x,end=',')\n\n# Also available: while\n\n0,1,2,3,4,5,6,7,8,9,\n---\na,b,c,"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#logic",
    "href": "chapters/05-WorkingWithData/python_programming.html#logic",
    "title": "Basics of Programming in Python",
    "section": "Logic",
    "text": "Logic\n\nif 3&lt;5:\n    print(\"ha\")\nelse:\n    print(\"ba\")\n\nha\n\n\n\nif 3+5==8 and 3-5==-2:\n    print(\"Yeah!\")\nelse:\n    print(\"Nah!\")\n\nYeah!\n\n\n\nif 3+5 in [1,2,3,4,5,6,7]:\n    print(\"Yeah\")\nelse:\n    print(\"nah!\")\n\nnah!"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#list-comprehensions",
    "href": "chapters/05-WorkingWithData/python_programming.html#list-comprehensions",
    "title": "Basics of Programming in Python",
    "section": "List Comprehensions",
    "text": "List Comprehensions\nThis is one of the most useful things about python.\n\nL = [\"hello\",\"Hello\",\"HELLO\",\"jeremy\",\"jereMy\"]\nN = [f(x) for x in L]\nM = [f(x) for x in L if x[0]==\"H\"]\nprint(N,M)\n\n['helloc', 'Helloc', 'HELLOc', 'jeremyc', 'jereMyc'] ['Helloc', 'HELLOc']\n\n\nAnother example.\n\ns=\"Jeremy Teitelbaum\"\nL=[x for x in list(s) if x not in [\" \"]]\nprint(L)\n\n['J', 'e', 'r', 'e', 'm', 'y', 'T', 'e', 'i', 't', 'e', 'l', 'b', 'a', 'u', 'm']\n\n\nCompare:\n\nS=\"\"\nfor x in \"Jeremy Teitelbaum\":\n    if x not in [\" \"]:\n        S+=x"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#a-few-other-tricks",
    "href": "chapters/05-WorkingWithData/python_programming.html#a-few-other-tricks",
    "title": "Basics of Programming in Python",
    "section": "A few other tricks",
    "text": "A few other tricks\n\ndefault arguments\ndocstrings\n\n\ndef f(x=0,y=1):\n    return x+y\n\nprint(f())\nprint(f(1))\nprint(f(3,4))\n\n1\n2\n7\n\n\n\ndef first_letter_cap(s):\n    \"Returns s but first letter of string is upper case\"\n    return s[0].upper()+s[1:]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#some-examples",
    "href": "chapters/05-WorkingWithData/python_programming.html#some-examples",
    "title": "Basics of Programming in Python",
    "section": "Some examples",
    "text": "Some examples\nTake a string and make its first character upper case and the rest lower.\n\ndef f(s):\n    l = s[0].upper()+s[1:].lower()\n    return l\n\nprint(f(\"hello\"),f(\"Hello\"),f(\"HELLO\"))\n\nHello Hello Hello\n\n\nNow do this for each element of a list.\n\ndef h(L):\n    N=[]\n    for x in L:\n        N = N + [f(x)]\n    return N\n\nh([\"hello\",\"HELLO\",\"jeremy\",\"JEREMY\",\"jerEmy\"])\n\n['Hello', 'Hello', 'Jeremy', 'Jeremy', 'Jeremy']"
  },
  {
    "objectID": "chapters/05-WorkingWithData/python_programming.html#problems",
    "href": "chapters/05-WorkingWithData/python_programming.html#problems",
    "title": "Basics of Programming in Python",
    "section": "Problems",
    "text": "Problems\n\nWrite a function which takes a string and standardizes it by:\n\nremoves all characters which are not letters, numbers, or spaces\nmakes all the letters lower case\nreplacing all spaces by underscore ’_’\n\n\nHint: convert the string to a vector of letters.\n\nThe penguins_raw.csv file can get loaded into a pandas dataframe, which is a fancy type of tabular layout. It has named columns that you can extract with .columns\n\n\nimport pandas as pd\npenguins_raw = pd.read_csv(\"data/penguins-raw.csv\")\npenguins_raw.columns\n\nIndex(['studyName', 'Sample Number', 'Species', 'Region', 'Island', 'Stage',\n       'Individual ID', 'Clutch Completion', 'Date Egg', 'Culmen Length (mm)',\n       'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex',\n       'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)', 'Comments'],\n      dtype='object')\n\n\nYou can assign to penguins_raw.columns to change the column names. Use your function from part 1 to standardize and simplify the column names.\n\nYou can access a column of the dataframe using ., so for example penguins_raw.Species should give you the column species. Replace this column with just the first word of the species name (Gentoo, Adelie, Chinstrap). To do this, you have to use the map method. If f is a function that picks out the first word of a string, then penguins_raw.species.map(f) returns the result of applying f to every element of penguins_raw.species.\nLet \\(n\\) be a positive real number and let \\(x_0\\) be 1. The iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\n\nconverges to the square root of \\(n\\). (This is Newton’s Method). Write an R function which computes the square root using this iteration. You should continue to iterate until \\(x_{k+1}\\) is within \\(10^{-6}\\) of \\(x_{k}\\).\n\n# def f(n):\n# \n# ...\n\nSuppose you want to save the successive values you computed during the iteration for plotting purposes. How could you do that (and return them)?\nSuppose you want the tolerance (here \\(10^{6}\\)) to be a parameter?\nSuppose you want to set a maximum number of iterations, in case something goes wrong, to prevent an infinite loop?"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html",
    "title": "Working with data in python/pandas",
    "section": "",
    "text": "import sys\nimport pandas as pd\nimport numpy as np\nimport re\n\nprint(f\"pandas version {pd.__version__}\")\nprint(f\"numpy version {np.__version__}\")\nprint(\"\\n\".join(f\"Python {sys.version}\".split(\"|\")))\n\npandas version 2.1.1\nnumpy version 1.24.3\nPython 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#loading-the-key-libraries",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#loading-the-key-libraries",
    "title": "Working with data in python/pandas",
    "section": "",
    "text": "import sys\nimport pandas as pd\nimport numpy as np\nimport re\n\nprint(f\"pandas version {pd.__version__}\")\nprint(f\"numpy version {np.__version__}\")\nprint(\"\\n\".join(f\"Python {sys.version}\".split(\"|\")))\n\npandas version 2.1.1\nnumpy version 1.24.3\nPython 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#a-comment-on-file-formats",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#a-comment-on-file-formats",
    "title": "Working with data in python/pandas",
    "section": "A comment on file formats",
    "text": "A comment on file formats\nThe most common simple format for tabular data is comma separated or tab separated (csv or tsv).\nNewer formats such as arrow and parquet are more efficient in storage and faster to load.\nPandas 2.0 can handle these newer formats."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#reading-a-dataframe",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#reading-a-dataframe",
    "title": "Working with data in python/pandas",
    "section": "Reading a dataframe",
    "text": "Reading a dataframe\n\n# read from a csv file\npenguins = pd.read_csv(\"data/penguins-raw.csv\")\n# read from a url\n# url = \"https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv\"\n# penguins = pd.read_csv(url)\n# read from an excel file\n# penguins = pd.read_excel('file.xlsx')\nrows, cols = penguins.shape\nprint(f\"Rows: {rows}, Columns: {cols}\")\nprint(f\"Columns:\", \"\\n\".join(penguins.columns))\n\nRows: 344, Columns: 17\nColumns: studyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#series",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#series",
    "title": "Working with data in python/pandas",
    "section": "Series",
    "text": "Series\nEach column of a dataframe is a series accessed by name.\n\npenguins[\"Culmen Length (mm)\"]\n\n0      39.1\n1      39.5\n2      40.3\n3       NaN\n4      36.7\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: Culmen Length (mm), Length: 344, dtype: float64\n\n\nNote the last row: - Name - Length - dtype\nTypes are “inferred” by the read_csv function."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#another-example",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#another-example",
    "title": "Working with data in python/pandas",
    "section": "Another example",
    "text": "Another example\n\npenguins['Date Egg']\n\n0      2007-11-11\n1      2007-11-11\n2      2007-11-16\n3      2007-11-16\n4      2007-11-16\n          ...    \n339    2009-11-19\n340    2009-11-21\n341    2009-11-21\n342    2009-11-21\n343    2009-11-21\nName: Date Egg, Length: 344, dtype: object\n\n\nHere the type is “object” which is the generic python object. But these are clearly supposed to be dates. We’ll fix that later."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#alternative-syntax",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#alternative-syntax",
    "title": "Working with data in python/pandas",
    "section": "Alternative syntax",
    "text": "Alternative syntax\n\n# if the column name is simple, you can use a simpler syntax.\npenguins.Sex\n\n0        MALE\n1      FEMALE\n2      FEMALE\n3         NaN\n4      FEMALE\n        ...  \n339      MALE\n340    FEMALE\n341      MALE\n342      MALE\n343    FEMALE\nName: Sex, Length: 344, dtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#value-counts",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#value-counts",
    "title": "Working with data in python/pandas",
    "section": "Value Counts",
    "text": "Value Counts\nThe value_counts method returns a summary series.\n\npenguins['Island'].value_counts()\n\nIsland\nBiscoe       168\nDream        124\nTorgersen     52\nName: count, dtype: int64\n\n\n\npenguins['Species'].value_counts()\n\nSpecies\nAdelie Penguin (Pygoscelis adeliae)          152\nGentoo penguin (Pygoscelis papua)            124\nChinstrap penguin (Pygoscelis antarctica)     68\nName: count, dtype: int64"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#selecting-a-subset-of-columns",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#selecting-a-subset-of-columns",
    "title": "Working with data in python/pandas",
    "section": "Selecting a subset of columns",
    "text": "Selecting a subset of columns\n\nsimpler = penguins[['Species', 'Body Mass (g)', 'Flipper Length (mm)']]\nsimpler.head()\n\n\n\n\n\n\n\n\nSpecies\nBody Mass (g)\nFlipper Length (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n3750.0\n181.0\n\n\n1\nAdelie Penguin (Pygoscelis adeliae)\n3800.0\n186.0\n\n\n2\nAdelie Penguin (Pygoscelis adeliae)\n3250.0\n195.0\n\n\n3\nAdelie Penguin (Pygoscelis adeliae)\nNaN\nNaN\n\n\n4\nAdelie Penguin (Pygoscelis adeliae)\n3450.0\n193.0"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#index",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#index",
    "title": "Working with data in python/pandas",
    "section": "Index",
    "text": "Index\nA dataframe has an index, which can be just the numbers from 0 to N as in this case.\n\npenguins.index\n\nRangeIndex(start=0, stop=344, step=1)"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#columns-and-rows",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#columns-and-rows",
    "title": "Working with data in python/pandas",
    "section": "Columns and Rows",
    "text": "Columns and Rows\nloc allows you to access individual elements.\n\n# The 23rd row\npenguins.loc[23,:]\n\nstudyName                                          PAL0708\nSample Number                                           24\nSpecies                Adelie Penguin (Pygoscelis adeliae)\nRegion                                              Anvers\nIsland                                              Biscoe\nStage                                   Adult, 1 Egg Stage\nIndividual ID                                        N12A2\nClutch Completion                                      Yes\nDate Egg                                        2007-11-12\nCulmen Length (mm)                                    38.2\nCulmen Depth (mm)                                     18.1\nFlipper Length (mm)                                  185.0\nBody Mass (g)                                       3950.0\nSex                                                   MALE\nDelta 15 N (o/oo)                                  8.43423\nDelta 13 C (o/oo)                                -25.22664\nComments                                               NaN\nName: 23, dtype: object\n\n\n\npenguins.loc[23,'Culmen Length (mm)']\n\n38.2\n\n\n\npenguins.loc[23:28,['Sex','Date Egg']]\n\n\n\n\n\n\n\n\nSex\nDate Egg\n\n\n\n\n23\nMALE\n2007-11-12\n\n\n24\nMALE\n2007-11-10\n\n\n25\nFEMALE\n2007-11-10\n\n\n26\nMALE\n2007-11-12\n\n\n27\nFEMALE\n2007-11-12\n\n\n28\nFEMALE\n2007-11-10"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#filtering",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#filtering",
    "title": "Working with data in python/pandas",
    "section": "Filtering",
    "text": "Filtering\nFiltering is done by using a boolean series as an index.\n\npenguins['Sex']=='FEMALE'\n\n0      False\n1       True\n2       True\n3      False\n4       True\n       ...  \n339    False\n340     True\n341    False\n342    False\n343     True\nName: Sex, Length: 344, dtype: bool\n\n\n\nfemales = penguins[penguins['Sex']=='FEMALE']\nfemales.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n2007-11-11\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n2007-11-16\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n2007-11-16\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n6\nPAL0708\n7\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A1\nNo\n2007-11-15\n38.9\n17.8\n181.0\n3625.0\nFEMALE\n9.18718\n-25.21799\nNest never observed with full clutch.\n\n\n12\nPAL0708\n13\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN7A1\nYes\n2007-11-15\n41.1\n17.6\n182.0\n3200.0\nFEMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n\n\n\n\n\nAn alternative syntax is to use query. The quoting rules here can be tricky. The query is a string, and column names are set off by backticks. Using two different types of quotes allows the query to include a string.\n\nfemales = penguins.query(\"`Sex`=='FEMALE'\")\nfemales.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n2007-11-11\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n2007-11-16\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n2007-11-16\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n6\nPAL0708\n7\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A1\nNo\n2007-11-15\n38.9\n17.8\n181.0\n3625.0\nFEMALE\n9.18718\n-25.21799\nNest never observed with full clutch.\n\n\n12\nPAL0708\n13\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN7A1\nYes\n2007-11-15\n41.1\n17.6\n182.0\n3200.0\nFEMALE\nNaN\nNaN\nNot enough blood for isotopes."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#fancier-filtering",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#fancier-filtering",
    "title": "Working with data in python/pandas",
    "section": "Fancier filtering",
    "text": "Fancier filtering\n\npenguins[penguins[\"Flipper Length (mm)\"]&gt;penguins[\"Body Mass (g)\"]/20]\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n2007-11-16\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n2007-11-16\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n5\nPAL0708\n6\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n2007-11-16\n39.3\n20.6\n190.0\n3650.0\nMALE\n8.66496\n-25.29805\nNaN\n\n\n8\nPAL0708\n9\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN5A1\nYes\n2007-11-09\n34.1\n18.1\n193.0\n3475.0\nNaN\nNaN\nNaN\nNo blood sample obtained.\n\n\n10\nPAL0708\n11\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN6A1\nYes\n2007-11-09\n37.8\n17.1\n186.0\n3300.0\nNaN\n8.63243\n-25.21315\nNo blood sample obtained for sexing.\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nPAL0910\n64\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN98A2\nYes\n2009-11-19\n55.8\n19.8\n207.0\n4000.0\nMALE\n9.70465\n-24.53494\nNaN\n\n\n340\nPAL0910\n65\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN99A1\nNo\n2009-11-21\n43.5\n18.1\n202.0\n3400.0\nFEMALE\n9.37608\n-24.40753\nNest never observed with full clutch.\n\n\n341\nPAL0910\n66\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN99A2\nNo\n2009-11-21\n49.6\n18.2\n193.0\n3775.0\nMALE\n9.46180\n-24.70615\nNest never observed with full clutch.\n\n\n342\nPAL0910\n67\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN100A1\nYes\n2009-11-21\n50.8\n19.0\n210.0\n4100.0\nMALE\n9.98044\n-24.68741\nNaN\n\n\n343\nPAL0910\n68\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN100A2\nYes\n2009-11-21\n50.2\n18.7\n198.0\n3775.0\nFEMALE\n9.39305\n-24.25255\nNaN\n\n\n\n\n147 rows × 17 columns"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#missing-values",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#missing-values",
    "title": "Working with data in python/pandas",
    "section": "Missing values",
    "text": "Missing values\nDealing with missing values is a central problem in data science. One way to identify how many misssing values are out there is as follows:\n\n## Uses the fact that logical True counts as one, False as zero\n## sum() method sums by columns\npenguins.isna().sum()\n\nstudyName                0\nSample Number            0\nSpecies                  0\nRegion                   0\nIsland                   0\nStage                    0\nIndividual ID            0\nClutch Completion        0\nDate Egg                 0\nCulmen Length (mm)       2\nCulmen Depth (mm)        2\nFlipper Length (mm)      2\nBody Mass (g)            2\nSex                     11\nDelta 15 N (o/oo)       14\nDelta 13 C (o/oo)       13\nComments               290\ndtype: int64\n\n\nNearly all of the comments are empty. What are they?\n\ncomments = penguins['Comments'].value_counts()\ncomments\n\nComments\nNest never observed with full clutch.                                   34\nNot enough blood for isotopes.                                           7\nSexing primers did not amplify.                                          4\nNo blood sample obtained.                                                2\nNo blood sample obtained for sexing.                                     2\nAdult not sampled.                                                       1\nNest never observed with full clutch. Not enough blood for isotopes.     1\nSexing primers did not amplify. Not enough blood for isotopes.           1\nAdult not sampled. Nest never observed with full clutch.                 1\nNo delta15N data received from lab.                                      1\nName: count, dtype: int64\n\n\nLet’s save the comments separately and look at the rest.\n\n# drop normally drops rows, but with axis=1 it drops columns\npenguins = penguins.drop('Comments',axis=1)\n\nVarious options: - drop rows with missing values - impute the missing values somehow"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#drop-rows-with-missing-values",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#drop-rows-with-missing-values",
    "title": "Working with data in python/pandas",
    "section": "Drop rows with missing values",
    "text": "Drop rows with missing values\n\n# This makes a boolean where a row is True provided at least one of its entries are NA\nna_rows = (penguins.isna().any(axis=1))\nprint(f\"{na_rows.sum()} rows have NA somewhere outside of comments\")\n\n20 rows have NA somewhere outside of comments\n\n\n\n# here we keep rows only if no NA's.  Can also use notna().\npenguins_nona = penguins.loc[~na_rows,:]"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#imputation",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#imputation",
    "title": "Working with data in python/pandas",
    "section": "Imputation",
    "text": "Imputation\nWe saw above that culmen length has 2 missing values. We can use fillna to replace the missing values with something (like the mean or median or zero).\n\n# using equality w/o copy creates another reference.\npenguins_imputed = penguins.copy()\nculmen_mean = penguins_imputed['Culmen Length (mm)'].mean() # how does this handle NA values?\nprint(f\"Culmen length mean is {culmen_mean}\")\npenguins_imputed['Culmen Length (mm)'] = penguins_imputed['Culmen Length (mm)'].fillna(culmen_mean)\n\nCulmen length mean is 43.9219298245614\n\n\nThere are many other imputation methods. For example, if the data is ordered, you can fill missing data with linear interpolation. (See the interpolate method)."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#data-types",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#data-types",
    "title": "Working with data in python/pandas",
    "section": "Data types",
    "text": "Data types\nAs we saw above, the types of the columns are inferred when the data is read. But it’s not always correct. For example, the “Date Egg” column is supposed to be a date but it’s shown as a generic python object.\nUsing the correct type can greatly improve performance as generic Python arguments are inefficient.\nIn pandas 1.0 strings are always treated as objects but in pandas 2.0 there is a StringDtype.\nThe most common types are: - object - float64 - datetime (datetime64[ns]) - int64 - bool\nOne may also find categorical types.\n\npenguins.dtypes\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\ndtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#setting-datatypes",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#setting-datatypes",
    "title": "Working with data in python/pandas",
    "section": "Setting datatypes",
    "text": "Setting datatypes\nHere’s an example where we manually make sex a categorical type.\n\npenguins = penguins.astype({'Sex':'category'})\npenguins['Sex']\n\n0        MALE\n1      FEMALE\n2      FEMALE\n3         NaN\n4      FEMALE\n        ...  \n339      MALE\n340    FEMALE\n341      MALE\n342      MALE\n343    FEMALE\nName: Sex, Length: 344, dtype: category\nCategories (2, object): ['FEMALE', 'MALE']\n\n\nOne can also pass a dictionary setting the types of columns as an argument when you read them from the csv file."
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#creating-new-columns",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#creating-new-columns",
    "title": "Working with data in python/pandas",
    "section": "Creating new columns",
    "text": "Creating new columns\nSimplifying the species name.\n\ndef first_word(x):\n    return x.split()[0]\npenguins['SimpleSpecies'] = penguins['Species'].map(first_word)\n\nRewriting the body mass in kilograms.\n\npenguins['Body Mass (kg)'] = penguins['Body Mass (g)']/1000"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#sorting",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#sorting",
    "title": "Working with data in python/pandas",
    "section": "Sorting",
    "text": "Sorting\n\npenguins_small = penguins[['Species','Island','Body Mass (g)']]\npenguins_small.sort_values('Body Mass (g)')\n# ascending = False for descending order\n# na_position = 'first' or 'last' (default is 'last')\n# can also provide a key which is a function of prototype Series -&gt; Series\n# inplace = True doesn't return a new dataframe, sorts the given one in place\n\n\n\n\n\n\n\n\nSpecies\nIsland\nBody Mass (g)\n\n\n\n\n314\nChinstrap penguin (Pygoscelis antarctica)\nDream\n2700.0\n\n\n64\nAdelie Penguin (Pygoscelis adeliae)\nBiscoe\n2850.0\n\n\n58\nAdelie Penguin (Pygoscelis adeliae)\nBiscoe\n2850.0\n\n\n116\nAdelie Penguin (Pygoscelis adeliae)\nTorgersen\n2900.0\n\n\n98\nAdelie Penguin (Pygoscelis adeliae)\nDream\n2900.0\n\n\n...\n...\n...\n...\n\n\n269\nGentoo penguin (Pygoscelis papua)\nBiscoe\n6000.0\n\n\n185\nGentoo penguin (Pygoscelis papua)\nBiscoe\n6050.0\n\n\n169\nGentoo penguin (Pygoscelis papua)\nBiscoe\n6300.0\n\n\n3\nAdelie Penguin (Pygoscelis adeliae)\nTorgersen\nNaN\n\n\n271\nGentoo penguin (Pygoscelis papua)\nBiscoe\nNaN\n\n\n\n\n344 rows × 3 columns"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#grouping",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#grouping",
    "title": "Working with data in python/pandas",
    "section": "Grouping",
    "text": "Grouping\nGrouping is a powerful tool. Let’s first group our penguins by species. The result is a “grouped” object which needs to pass through a summarize operation to be useful.\n\npenguins_by_species = penguins.groupby('Species')\npenguins_by_species\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7c7c85c8a8d0&gt;"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#summarizing",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#summarizing",
    "title": "Working with data in python/pandas",
    "section": "Summarizing",
    "text": "Summarizing\n\n# describe computes basic descriptive statistics\npenguins_by_species['Body Mass (g)'].describe()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n151.0\n3700.662252\n458.566126\n2850.0\n3350.0\n3700.0\n4000.0\n4775.0\n\n\nChinstrap penguin (Pygoscelis antarctica)\n68.0\n3733.088235\n384.335081\n2700.0\n3487.5\n3700.0\n3950.0\n4800.0\n\n\nGentoo penguin (Pygoscelis papua)\n123.0\n5076.016260\n504.116237\n3950.0\n4700.0\n5000.0\n5500.0\n6300.0\n\n\n\n\n\n\n\n\n# this fails because some columns aren't numeric\npenguins_by_species.mean(numeric_only=True)\n\n\n\n\n\n\n\n\nSample Number\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nBody Mass (kg)\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n76.5\n38.791391\n18.346358\n189.953642\n3700.662252\n8.859733\n-25.804194\n3.700662\n\n\nChinstrap penguin (Pygoscelis antarctica)\n34.5\n48.833824\n18.420588\n195.823529\n3733.088235\n9.356155\n-24.546542\n3.733088\n\n\nGentoo penguin (Pygoscelis papua)\n62.5\n47.504878\n14.982114\n217.186992\n5076.016260\n8.245338\n-26.185298\n5.076016\n\n\n\n\n\n\n\n\npenguins_by_species.count()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nSimpleSpecies\nBody Mass (kg)\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n152\n152\n152\n152\n152\n152\n152\n152\n151\n151\n151\n151\n146\n141\n141\n152\n151\n\n\nChinstrap penguin (Pygoscelis antarctica)\n68\n68\n68\n68\n68\n68\n68\n68\n68\n68\n68\n68\n68\n67\n68\n68\n68\n\n\nGentoo penguin (Pygoscelis papua)\n124\n124\n124\n124\n124\n124\n124\n124\n123\n123\n123\n123\n119\n122\n122\n124\n123"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#multiindex",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#multiindex",
    "title": "Working with data in python/pandas",
    "section": "MultiIndex",
    "text": "MultiIndex\n\npenguins_by_sex_and_species = penguins.groupby(['Sex','Species'])\npenguins_by_sex_and_species['Body Mass (g)'].describe().round()\n\n/tmp/ipykernel_1315298/3464751443.py:1: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nSex\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\nFEMALE\nAdelie Penguin (Pygoscelis adeliae)\n73.0\n3369.0\n269.0\n2850.0\n3175.0\n3400.0\n3550.0\n3900.0\n\n\nChinstrap penguin (Pygoscelis antarctica)\n34.0\n3527.0\n285.0\n2700.0\n3362.0\n3550.0\n3694.0\n4150.0\n\n\nGentoo penguin (Pygoscelis papua)\n58.0\n4680.0\n282.0\n3950.0\n4462.0\n4700.0\n4875.0\n5200.0\n\n\nMALE\nAdelie Penguin (Pygoscelis adeliae)\n73.0\n4043.0\n347.0\n3325.0\n3800.0\n4000.0\n4300.0\n4775.0\n\n\nChinstrap penguin (Pygoscelis antarctica)\n34.0\n3939.0\n362.0\n3250.0\n3731.0\n3950.0\n4100.0\n4800.0\n\n\nGentoo penguin (Pygoscelis papua)\n61.0\n5485.0\n313.0\n4750.0\n5300.0\n5500.0\n5700.0\n6300.0\n\n\n\n\n\n\n\n\n# pivot tables\npenguins_by_sex_and_species['Body Mass (g)'].mean().reset_index().pivot(index='Sex',columns='Species',values='Body Mass (g)')\n\n\n\n\n\n\n\nSpecies\nAdelie Penguin (Pygoscelis adeliae)\nChinstrap penguin (Pygoscelis antarctica)\nGentoo penguin (Pygoscelis papua)\n\n\nSex\n\n\n\n\n\n\n\nFEMALE\n3368.835616\n3527.205882\n4679.741379\n\n\nMALE\n4043.493151\n3938.970588\n5484.836066"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#pandas-plotting",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#pandas-plotting",
    "title": "Working with data in python/pandas",
    "section": "Pandas plotting",
    "text": "Pandas plotting\nSome simple plots are available directly from pandas.\n\npenguins[penguins['Species'].str.startswith(\"Adel\")].groupby(['Sex'])['Body Mass (g)'].hist(bins=30,legend=True)\n\n/tmp/ipykernel_1315298/3368902341.py:1: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\nSex\nFEMALE    Axes(0.125,0.11;0.775x0.77)\nMALE      Axes(0.125,0.11;0.775x0.77)\nName: Body Mass (g), dtype: object"
  },
  {
    "objectID": "chapters/05-WorkingWithData/pandas_penguins.html#excel-files",
    "href": "chapters/05-WorkingWithData/pandas_penguins.html#excel-files",
    "title": "Working with data in python/pandas",
    "section": "Excel files",
    "text": "Excel files\nWe can read an excel file. This particular one is complicated for various reasons, including the fact that the column heads are in the third row, not at the top. Also there are a bunch of footnotes starting in row 510 that we don’t want. So we don’t read them in.\n\ncrime2019 = pd.read_excel(\"data/Violent Crime-by state-2019-table-5.xls\",header=3,nrows=510)\ncrime2019\n\n\n\n\n\n\n\n\nState\nArea\nUnnamed: 2\nPopulation\nViolent \\ncrime1\nMurder and \\nnonnegligent \\nmanslaughter\nRape2\nRobbery\nAggravated \\nassault\nProperty \\ncrime\nBurglary\nLarceny-theft\nMotor \\nvehicle \\ntheft\n\n\n\n\n0\nALABAMA\nMetropolitan Statistical Area\nNaN\n3728978.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nNaN\nNaN\nArea actually reporting\n0.766\n12880\n182.0\n1141.0\n1706.0\n9851\n65789\n12388.0\n47299.0\n6102.0\n\n\n2\nNaN\nNaN\nEstimated total\n1.000\n19951\n300.0\n1542.0\n3432.0\n14677\n104658\n20728.0\n73857.0\n10073.0\n\n\n3\nNaN\nCities outside metropolitan areas\nNaN\n528518.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nArea actually reporting\n0.893\n3327\n36.0\n297.0\n266.0\n2728\n17915\n3140.0\n13382.0\n1393.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n505\nNaN\nNonmetropolitan counties\nNaN\n160615.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n506\nNaN\nNaN\nArea actually reporting\n0.921\n194\n0.0\n39.0\n0.0\n155\n973\n170.0\n716.0\n87.0\n\n\n507\nNaN\nNaN\nEstimated total\n1.000\n213\n0.0\n42.0\n0.0\n171\n1065\n188.0\n781.0\n96.0\n\n\n508\nNaN\nState Total\nNaN\n578759.000\n1258\n13.0\n324.0\n67.0\n854\n9093\n1396.0\n6984.0\n713.0\n\n\n509\nNaN\nNaN\nRate per 100,000 inhabitants\nNaN\n217.4\n2.2\n56.0\n11.6\n147.6\n1571.1\n241.2\n1206.7\n123.2\n\n\n\n\n510 rows × 13 columns\n\n\n\nThe column names have newlines in them and we’d like to get rid of those.\n\ncrime2019.columns = [x.replace(\" \\n\",\"_\") for x in crime2019.columns]\ncrime2019\n\n\n\n\n\n\n\n\nState\nArea\nUnnamed: 2\nPopulation\nViolent_crime1\nMurder and_nonnegligent_manslaughter\nRape2\nRobbery\nAggravated_assault\nProperty_crime\nBurglary\nLarceny-theft\nMotor_vehicle_theft\n\n\n\n\n0\nALABAMA\nMetropolitan Statistical Area\nNaN\n3728978.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nNaN\nNaN\nArea actually reporting\n0.766\n12880\n182.0\n1141.0\n1706.0\n9851\n65789\n12388.0\n47299.0\n6102.0\n\n\n2\nNaN\nNaN\nEstimated total\n1.000\n19951\n300.0\n1542.0\n3432.0\n14677\n104658\n20728.0\n73857.0\n10073.0\n\n\n3\nNaN\nCities outside metropolitan areas\nNaN\n528518.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nArea actually reporting\n0.893\n3327\n36.0\n297.0\n266.0\n2728\n17915\n3140.0\n13382.0\n1393.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n505\nNaN\nNonmetropolitan counties\nNaN\n160615.000\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n506\nNaN\nNaN\nArea actually reporting\n0.921\n194\n0.0\n39.0\n0.0\n155\n973\n170.0\n716.0\n87.0\n\n\n507\nNaN\nNaN\nEstimated total\n1.000\n213\n0.0\n42.0\n0.0\n171\n1065\n188.0\n781.0\n96.0\n\n\n508\nNaN\nState Total\nNaN\n578759.000\n1258\n13.0\n324.0\n67.0\n854\n9093\n1396.0\n6984.0\n713.0\n\n\n509\nNaN\nNaN\nRate per 100,000 inhabitants\nNaN\n217.4\n2.2\n56.0\n11.6\n147.6\n1571.1\n241.2\n1206.7\n123.2\n\n\n\n\n510 rows × 13 columns\n\n\n\nLet’s look at the states.\n\nstates = crime2019[\"State\"].dropna().values\nstates\n\narray(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA',\n       'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA3',\n       'FLORIDA', 'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA',\n       'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND',\n       'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI4',\n       'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE',\n       'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA',\n       'NORTH DAKOTA', 'OHIO4', 'OKLAHOMA', 'OREGON4', 'PENNSYLVANIA',\n       'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',\n       'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON',\n       'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'], dtype=object)\n\n\nSome have footnotes at the end. We don’t want them.\n\nstates = [re.sub(\"[0-9$]\",\"\",x) for x in states]\nstates\n\n['ALABAMA',\n 'ALASKA',\n 'ARIZONA',\n 'ARKANSAS',\n 'CALIFORNIA',\n 'COLORADO',\n 'CONNECTICUT',\n 'DELAWARE',\n 'DISTRICT OF COLUMBIA',\n 'FLORIDA',\n 'GEORGIA',\n 'HAWAII',\n 'IDAHO',\n 'ILLINOIS',\n 'INDIANA',\n 'IOWA',\n 'KANSAS',\n 'KENTUCKY',\n 'LOUISIANA',\n 'MAINE',\n 'MARYLAND',\n 'MASSACHUSETTS',\n 'MICHIGAN',\n 'MINNESOTA',\n 'MISSISSIPPI',\n 'MISSOURI',\n 'MONTANA',\n 'NEBRASKA',\n 'NEVADA',\n 'NEW HAMPSHIRE',\n 'NEW JERSEY',\n 'NEW MEXICO',\n 'NEW YORK',\n 'NORTH CAROLINA',\n 'NORTH DAKOTA',\n 'OHIO',\n 'OKLAHOMA',\n 'OREGON',\n 'PENNSYLVANIA',\n 'PUERTO RICO',\n 'RHODE ISLAND',\n 'SOUTH CAROLINA',\n 'SOUTH DAKOTA',\n 'TENNESSEE',\n 'TEXAS',\n 'UTAH',\n 'VERMONT',\n 'VIRGINIA',\n 'WASHINGTON',\n 'WEST VIRGINIA',\n 'WISCONSIN',\n 'WYOMING']\n\n\n] We don’t want to include DC or Puerto Rico.\n\nstates = [x for x in states if x!='DISTRICT OF COLUMBIA' and x!='PUERTO RICO']\nstates\n\n['ALABAMA',\n 'ALASKA',\n 'ARIZONA',\n 'ARKANSAS',\n 'CALIFORNIA',\n 'COLORADO',\n 'CONNECTICUT',\n 'DELAWARE',\n 'FLORIDA',\n 'GEORGIA',\n 'HAWAII',\n 'IDAHO',\n 'ILLINOIS',\n 'INDIANA',\n 'IOWA',\n 'KANSAS',\n 'KENTUCKY',\n 'LOUISIANA',\n 'MAINE',\n 'MARYLAND',\n 'MASSACHUSETTS',\n 'MICHIGAN',\n 'MINNESOTA',\n 'MISSISSIPPI',\n 'MISSOURI',\n 'MONTANA',\n 'NEBRASKA',\n 'NEVADA',\n 'NEW HAMPSHIRE',\n 'NEW JERSEY',\n 'NEW MEXICO',\n 'NEW YORK',\n 'NORTH CAROLINA',\n 'NORTH DAKOTA',\n 'OHIO',\n 'OKLAHOMA',\n 'OREGON',\n 'PENNSYLVANIA',\n 'RHODE ISLAND',\n 'SOUTH CAROLINA',\n 'SOUTH DAKOTA',\n 'TENNESSEE',\n 'TEXAS',\n 'UTAH',\n 'VERMONT',\n 'VIRGINIA',\n 'WASHINGTON',\n 'WEST VIRGINIA',\n 'WISCONSIN',\n 'WYOMING']\n\n\nFinally, we want to pull out the violent crime numbers for the total area of the state. Notice that Puerto Rico and DC use “Total”, not “State Total”, for Area and so they will be excluded.\n\nvcrime2019 = crime2019[crime2019['Area'] == 'State Total']['Violent_crime1'].values\nvcrime2019\n\narray([25046, 6343, 33141, 17643, 174331, 21938, 6546, 4115, 81270, 36170,\n       4042, 4000, 51561, 24966, 8410, 11968, 9701, 25537, 1548, 27456,\n       22578, 43686, 13332, 8272, 30380, 4328, 5821, 15210, 2074, 18375,\n       17450, 69764, 38995, 2169, 34269, 17086, 11995, 39228, 2342, 26323,\n       3530, 40647, 121474, 7553, 1262, 17753, 22377, 5674, 17070, 1258],\n      dtype=object)"
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html",
    "href": "chapters/03-RBasics/r-walkthrough.html",
    "title": "R Notebook Walkthrough",
    "section": "",
    "text": "Start out with a code cell saying “Hello World”\nprint(\"Hello World\")\n\n[1] \"Hello World\"\nThe cat command is actually probably more useful than print:\ncat(\"hello world\")\n\nhello world",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#variables-types-and-assignment",
    "href": "chapters/03-RBasics/r-walkthrough.html#variables-types-and-assignment",
    "title": "R Notebook Walkthrough",
    "section": "Variables, Types, and Assignment",
    "text": "Variables, Types, and Assignment\nIn R, the assignment operator is &lt;-, not =. This takes some getting used to.\n\ncount &lt;- 5\nname &lt;- \"Jeremy Teitelbaum\" # string types are called chr for character\nparagraph &lt;- \"Far across the misty mountains cold,\nto dungeons deep and caverns cold,\nwe must away,\nere break of day\nto seek our long forgotten gold.\"\npi &lt;- 3.14159 # R doesn't use integer types unless you force it to, numbers are \"num\" # nolint: line_length_linter.\nepsilon &lt;- 1e-6\ncount &lt;- 5L # this forces an integer\nstudents &lt;- c(\"Jeremy\", \"Phillip\", \"Sara\", \"Molly\")\nhot_dog &lt;- TRUE # note all caps unlike Python; false is FALSE\n\nIn R, you can give names to the elements of a vector.\n\nprint(\"hello\")\n\n[1] \"hello\"\n\n\n\nnames(students) &lt;- c(\"President\", \"Vice President\", \"Treasurer\", \"Secretary\")\nprint(names(students))\n\n[1] \"President\"      \"Vice President\" \"Treasurer\"      \"Secretary\"     \n\nprint(students[\"President\"])\n\nPresident \n \"Jeremy\" \n\nprint(students)\n\n     President Vice President      Treasurer      Secretary \n      \"Jeremy\"      \"Phillip\"         \"Sara\"        \"Molly\" \n\n\nThe cat command is a print command that “concatenates” its arguments; it needs an explicit newline.\n\nprint(students)\n\n     President Vice President      Treasurer      Secretary \n      \"Jeremy\"      \"Phillip\"         \"Sara\"        \"Molly\" \n\nprint(count)\n\n[1] 5\n\ncat(\"Students:\", students, \"\\n\")\n\nStudents: Jeremy Phillip Sara Molly \n\nprint(epsilon)\n\n[1] 1e-06\n\ncat(\"The value of epsilon is:\", epsilon, \"\\n\")\n\nThe value of epsilon is: 1e-06 \n\nprint(paragraph)\n\n[1] \"Far across the misty mountains cold,\\nto dungeons deep and caverns cold,\\nwe must away,\\nere break of day\\nto seek our long forgotten gold.\"\n\ncat(paragraph)\n\nFar across the misty mountains cold,\nto dungeons deep and caverns cold,\nwe must away,\nere break of day\nto seek our long forgotten gold.\n\n\nThe [1] at the beginning of each of these things reflects the fact that in R everything is a vector. So it is telling you that the first thing there is element 1 of the vector.\nThe c() command makes a vector of its arguments. It forces everything to be of the same type.\n\nstr_list &lt;- c(\"Jeremy\", 25, 1.34, FALSE) # everything becomes a string\nint_list &lt;- c(1, 2, 3, 4, 5)\nfloat_list &lt;- c(1, 2, 3.5, 4)",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#arithmetic",
    "href": "chapters/03-RBasics/r-walkthrough.html#arithmetic",
    "title": "R Notebook Walkthrough",
    "section": "Arithmetic",
    "text": "Arithmetic\nR does all arithmetic on vectors/lists. It one is shorter than the other, it repeats the shorter one, but the length of the longer has to be a multiple of the shorter.\n\na &lt;- 1\nb &lt;- 2\na + b\n\n[1] 3\n\n\n\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- 4\na + b\n\n[1] 5 6 7 8 9\n\n\n\na &lt;- c(1, 2, 3, 4, 5, 6)\nb &lt;- c(10, 11)\na + b\n\n[1] 11 13 13 15 15 17\n\n\n\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- c(1, 2)\na + b\n\nWarning in a + b: longer object length is not a multiple of shorter object\nlength\n\n\n[1] 2 4 4 6 6\n\n\n\na / 5\n\n[1] 0.2 0.4 0.6 0.8 1.0\n\n\n\n# integer division (// in python)\na &lt;- 5L\nb &lt;- 3\na %/% b\n\n[1] 1\n\n\n\n# remainder (% in python)\na &lt;- 5\nb &lt;- 3\na %% b\n\n[1] 2\n\n\n\na &lt;- c(1, 2, 3, 4, 5)\na^2\n\n[1]  1  4  9 16 25\n\n\n\nprint(a^2 == a)\n\n[1]  TRUE FALSE FALSE FALSE FALSE\n\nprint(a^2 &gt; a)\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE\n\nprint(a^2 == 4)\n\n[1] FALSE  TRUE FALSE FALSE FALSE",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#operations-on-strings-and-lists",
    "href": "chapters/03-RBasics/r-walkthrough.html#operations-on-strings-and-lists",
    "title": "R Notebook Walkthrough",
    "section": "Operations on strings and lists",
    "text": "Operations on strings and lists\n\nfirst_name &lt;- \"Jeremy\"\nlast_name &lt;- \"Teitelbaum\"\nnchar(first_name)\n\n[1] 6\n\n\n\npaste(first_name, last_name) # spaces by default\n\n[1] \"Jeremy Teitelbaum\"\n\n\n\npaste(first_name, last_name, sep = \"\") # no space\n\n[1] \"JeremyTeitelbaum\"\n\n\n\npaste(c(1, 2, 3), \"Jeremy\") # remember functions work across vectors\n\n[1] \"1 Jeremy\" \"2 Jeremy\" \"3 Jeremy\"",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#substrings",
    "href": "chapters/03-RBasics/r-walkthrough.html#substrings",
    "title": "R Notebook Walkthrough",
    "section": "Substrings",
    "text": "Substrings\nIn R, you always count from 1 (big difference from python)\n\nfirst_name[1] # another difference from Python\n\n[1] \"Jeremy\"\n\n\n\na &lt;- substr(\"Jeremy\", 1, 1)\nb &lt;- substr(\"Jeremy\", 1, 3)\ncat(a, b, paste(a, b, sep = \"\"))\n\nJ Jer JJer",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#slicing-lists",
    "href": "chapters/03-RBasics/r-walkthrough.html#slicing-lists",
    "title": "R Notebook Walkthrough",
    "section": "Slicing lists",
    "text": "Slicing lists\n\nnums &lt;- 0:10 # generates a sequence from 0 to 10 INCLUSIVE (compare python)\nprint(nums)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(nums[c(1, 3)]) # you can pass a list of indices to a subscript\n\n[1] 0 2\n\n\n\nsqrs &lt;- nums^2\nsqrs[seq(1, 10, 2)]\n\n[1]  0  4 16 36 64\n\n\nIn R, negative numbers in seq mean “omit” so this means omit entries 2 through 5. You can’t mix positive and negative numbers\n\nrev &lt;- nums[seq(-2, -5)]\nprint(rev)\n\n[1]  0  5  6  7  8  9 10\n\n\n\nrev(nums) # reverses the list\n\n [1] 10  9  8  7  6  5  4  3  2  1  0",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#libraries-and-packages",
    "href": "chapters/03-RBasics/r-walkthrough.html#libraries-and-packages",
    "title": "R Notebook Walkthrough",
    "section": "Libraries and packages",
    "text": "Libraries and packages\nUse the Rstudio package manager to add libraries to your installation, but to use them you need to use the library function. The tidyverse library is something we will use a lot.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/03-RBasics/r-walkthrough.html#plotting",
    "href": "chapters/03-RBasics/r-walkthrough.html#plotting",
    "title": "R Notebook Walkthrough",
    "section": "Plotting",
    "text": "Plotting\n\nlibrary(ggplot2)\n\n\nx &lt;- seq(-10, 10, .1)\ny &lt;- x**2\ndata &lt;- tibble(\"x\" = x, \"y\" = y)\n\n\nggplot(data = data, aes(x = x)) +\n    geom_point(aes(y = y), color = \"red\") +\n    ggtitle(\"A Parabola\") +\n    scale_x_continuous(breaks = seq(-10, 10, 1)) +\n    scale_y_continuous(breaks = seq(0, 100, 20))\n\n\n\n\n\n\n\n\n\nx &lt;- seq(-10, 10, .1)\ny &lt;- cos(x)\ndata &lt;- tibble(\"x\" = x, \"y\" = y)\nggplot(data = data, aes(x = x)) +\n    geom_line(aes(y = y), color = \"darkgreen\") +\n    ggtitle(\"A Cosine Curve\") +\n    scale_x_continuous(breaks = seq(-10, 10, 1)) +\n    scale_y_continuous(breaks = seq(-1, 1, 5))",
    "crumbs": [
      "Contents",
      "R Notebook Walkthrough"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html",
    "href": "chapters/01-SettingUp/Cluster.html",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "",
    "text": "On your local machine: Login to the login node:\nYou need to install anaconda on your account on the cluster. To do this you can use wget to download the installer and then run it and follow the installation prompts as usual. You only need to do this part once!\nNow check if python and jupyter lab work.\nIf jupyter lab won’t run because of a libc++.so.6.o error, you can run\nMake a note of the node where your interactive process is running. This is in the prompt. It will be something like cn560.\nMake a note of the token provided by the jupyter lab process and the port where the server is running.\nWith luck, you’re running jupyter on a node in the cluster!"
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html#moving-a-file-to-the-cluster",
    "href": "chapters/01-SettingUp/Cluster.html#moving-a-file-to-the-cluster",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "Moving a file to the cluster",
    "text": "Moving a file to the cluster\nIf you can login to the cluster successfully using ssh then you can transfer a file to the cluster from your laptop using rsync. From a shell on your local machine:\nrsync filename &lt;netID&gt;@hpc2.storrs.hpc.uconn.edu"
  },
  {
    "objectID": "chapters/01-SettingUp/Cluster.html#getting-a-file-from-the-cluster",
    "href": "chapters/01-SettingUp/Cluster.html#getting-a-file-from-the-cluster",
    "title": "Jupyter on UConn’s HPC cluster",
    "section": "Getting a file from the cluster",
    "text": "Getting a file from the cluster\nTo transfer a file from the cluster to your local machine, run the following command from a shell on your local machine.\nrsync &lt;netID&gt;@hpc2.storrs.hpc.uconn.edu:filename ."
  },
  {
    "objectID": "chapters/00-OrientationProject/orientation-project.html",
    "href": "chapters/00-OrientationProject/orientation-project.html",
    "title": "Orientation Project",
    "section": "",
    "text": "GitHub is a huge repository of open source software projects managed by the version control software git. GitHub and git are designed to allow many people working independently to contribute to a software project, keeping track of different versions and the contributions of different people\nLater we will use GitHub to actually manage software but our goal today is to take advantage of the ability to create a personal web page on GitHub.",
    "crumbs": [
      "Contents",
      "Orientation Project"
    ]
  },
  {
    "objectID": "chapters/00-OrientationProject/orientation-project.html#overview",
    "href": "chapters/00-OrientationProject/orientation-project.html#overview",
    "title": "Orientation Project",
    "section": "",
    "text": "GitHub is a huge repository of open source software projects managed by the version control software git. GitHub and git are designed to allow many people working independently to contribute to a software project, keeping track of different versions and the contributions of different people\nLater we will use GitHub to actually manage software but our goal today is to take advantage of the ability to create a personal web page on GitHub.",
    "crumbs": [
      "Contents",
      "Orientation Project"
    ]
  },
  {
    "objectID": "chapters/00-OrientationProject/orientation-project.html#steps",
    "href": "chapters/00-OrientationProject/orientation-project.html#steps",
    "title": "Orientation Project",
    "section": "Steps",
    "text": "Steps\n\nCreate a GitHub account with your selected username\nCreate a new repository named username.github.io. Include a basic README.md file.\n\n\n\nTurn on github pages for this repository from the settings link. This is probably done already. Check the published site at https://username.github.io\n\n\n\nCreate a file _config.yml so you can choose a theme. Here we use the architect theme to start with.\n\n\n\nWait a bit and then look at the results.\n\n\n\nLook at the theme possibilities and pick one you like by modifying the _config.yaml file. Notice that it takes a while to deploy the new theme.\n\n\n\nAdd more content! Add more info to the _config.yml file using the theme documentation!",
    "crumbs": [
      "Contents",
      "Orientation Project"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "Grad 5100 is a foundational course in the MS in Data Science Program. It is designed to provide the essential background in programming, statistics, linear algebra, and multivariate calculus that the core and elective courses in the program rely on. The course will run intensively during the first few weeks of the semester and then drop back to a regular weekly schedule.\nNote: This material refers to the Fall 2023 version of Grad5100. See HuskyCT for the current version. Access to HuskyCT is limited to students enrolled in the course.\n\n\n\nWe will rely on the following materials.\n\nThe anaconda machine learning environment for python and associated libraries\nThe R language, Rstudio IDE, and associated libraries\nThe VScode IDE\n\nThere is no formal textbook for the course. Some useful references include the following, all of which are either open source or available through the UConn Library.\n\nProgramming Bootcamp (python) These are notes from a programming bootcamp at Caltech. It is very well done and comprehensive and covers more than we will do in this course.\nProgramming Bootcamp (R) These are notes developed at UConn by Chiranjit Dutta, one of Professor Ravishanker’s students. For a more usable zip file of the Rmd code and the data files, use this link.\nAn Introduction to Statistical Learning by James, et. al. Note that the original version of this book uses the R language, but a new edition available in Summer 2023 uses Python.\nR for Data Science by Wickham and Grolemund.\nPython for Data Science, 3E by Wes McKinney.\nPractical Statistics for Data Scientists by Bruce, Bruce, and Gedeck. Note that this is available for free to UConn students through the UConn library’s subscription to the O’Reilly Learning Platform.\nStatistical Practice for Data Science by Bar, Ravishankar, and Asha (draft).\nMathematics for Machine Learning (draft) by Teitelbaum.\nFluent Python by Ramalho. Available to UConn students through the UConn Library’s subscription to the O’Reilly Learning Platform.\n\nMore advanced technical references include:\n\nThe Elements of Statistical Learning by Hastie, et. al.\nPattern Recognition and Machine Learning by Bishop\n\n\n\n\nWe will use the campuswire Q&A site for class discussions and question asking/answering. Campuswire is like a private version of stackoverflow. Make sure to register for the site.\n\n\n\nCourse grades will be based on:\n\nbiweekly homework assignments (60 %)\na final exam (40 %)\n\n\n\n\nThe instructor reserves the right to modify or adapt this syllabus to account for disruption due to COVID-19 or other unexpected circumstances.\n\n\n\nStudents with disabilities should work with the Center for Students with Disabilities to request academic accommodations. The CSD is located in Wilbur Cross, Room 204 and can be reached at (860)-486-2020 or at csd@uconn.edu.\nStudents are bound by the university’s policies on academic misconduct. Academic misconduct is dishonest or unethical behavior that includes but is not limited to misrepresenting mastery in an academic area (e.g. cheating), failing to properly credit information, research, or ideas to their rightful originators or representing such information, research, or ideas as your own (e.g. plagiarism).\nStudents, faculty, and staff are bound by the university’s policy against discrimination, harassment, and related interpersonal violence.\n\n\n\n\n\n\n\nSetting up a data science working environment\nProbability and Statistics: the normal distribution\nWorking with Data in R and Python\nLinear Algebra: vectors, matrices, the dot product\nPartial derivatives and the gradient; matrix calculus\nSlicing and dicing data in R and Python\nStatistical Models\nHypothesis Testing\nData Structures and Object Oriented Programming\nVisualization tools in R and Python\nVersion Control\nDatabases\nAdditional topics as time permits"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "Grad 5100 is a foundational course in the MS in Data Science Program. It is designed to provide the essential background in programming, statistics, linear algebra, and multivariate calculus that the core and elective courses in the program rely on. The course will run intensively during the first few weeks of the semester and then drop back to a regular weekly schedule.\nNote: This material refers to the Fall 2023 version of Grad5100. See HuskyCT for the current version. Access to HuskyCT is limited to students enrolled in the course."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "We will rely on the following materials.\n\nThe anaconda machine learning environment for python and associated libraries\nThe R language, Rstudio IDE, and associated libraries\nThe VScode IDE\n\nThere is no formal textbook for the course. Some useful references include the following, all of which are either open source or available through the UConn Library.\n\nProgramming Bootcamp (python) These are notes from a programming bootcamp at Caltech. It is very well done and comprehensive and covers more than we will do in this course.\nProgramming Bootcamp (R) These are notes developed at UConn by Chiranjit Dutta, one of Professor Ravishanker’s students. For a more usable zip file of the Rmd code and the data files, use this link.\nAn Introduction to Statistical Learning by James, et. al. Note that the original version of this book uses the R language, but a new edition available in Summer 2023 uses Python.\nR for Data Science by Wickham and Grolemund.\nPython for Data Science, 3E by Wes McKinney.\nPractical Statistics for Data Scientists by Bruce, Bruce, and Gedeck. Note that this is available for free to UConn students through the UConn library’s subscription to the O’Reilly Learning Platform.\nStatistical Practice for Data Science by Bar, Ravishankar, and Asha (draft).\nMathematics for Machine Learning (draft) by Teitelbaum.\nFluent Python by Ramalho. Available to UConn students through the UConn Library’s subscription to the O’Reilly Learning Platform.\n\nMore advanced technical references include:\n\nThe Elements of Statistical Learning by Hastie, et. al.\nPattern Recognition and Machine Learning by Bishop"
  },
  {
    "objectID": "index.html#campuswire",
    "href": "index.html#campuswire",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "We will use the campuswire Q&A site for class discussions and question asking/answering. Campuswire is like a private version of stackoverflow. Make sure to register for the site."
  },
  {
    "objectID": "index.html#assessment",
    "href": "index.html#assessment",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "Course grades will be based on:\n\nbiweekly homework assignments (60 %)\na final exam (40 %)"
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "The instructor reserves the right to modify or adapt this syllabus to account for disruption due to COVID-19 or other unexpected circumstances."
  },
  {
    "objectID": "index.html#university-policies",
    "href": "index.html#university-policies",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "Students with disabilities should work with the Center for Students with Disabilities to request academic accommodations. The CSD is located in Wilbur Cross, Room 204 and can be reached at (860)-486-2020 or at csd@uconn.edu.\nStudents are bound by the university’s policies on academic misconduct. Academic misconduct is dishonest or unethical behavior that includes but is not limited to misrepresenting mastery in an academic area (e.g. cheating), failing to properly credit information, research, or ideas to their rightful originators or representing such information, research, or ideas as your own (e.g. plagiarism).\nStudents, faculty, and staff are bound by the university’s policy against discrimination, harassment, and related interpersonal violence."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Grad 5100: Fundamentals of Data Science Fall 2023",
    "section": "",
    "text": "Setting up a data science working environment\nProbability and Statistics: the normal distribution\nWorking with Data in R and Python\nLinear Algebra: vectors, matrices, the dot product\nPartial derivatives and the gradient; matrix calculus\nSlicing and dicing data in R and Python\nStatistical Models\nHypothesis Testing\nData Structures and Object Oriented Programming\nVisualization tools in R and Python\nVersion Control\nDatabases\nAdditional topics as time permits"
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html",
    "href": "chapters/01-SettingUp/setting-up.html",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Download from https://www.anaconda.com\n\nAnaconda includes:\n\npython\njupyter: notebook working environment\npython libraries: ML, visualization, I/O and others\nconda package manager: for dealing with multiple versions of libraries\nanaconda navigator: a GUI gateway to anaconda tools\nlots of other stuff\n\n\n\n\n\nVerify JupyterLab\n\nFrom a command line\n$ jupyter lab \nor use anaconda navigator to launch jupyterlab.\n\n\nVerify python version\n\nFrom a command line\n$ python --version\nor inside a jupyter notebook cell:\nimport sys\n\nprint(sys.version)\n\n\n\n\nSome notes on how to run Jupyter on the HPC cluster\n\n\n\n\n\nR is an open source language for statistical computations.\nRstudio is a working environment for the R language.\nR and Rstudio need to be installed separately.\nR is available at https://cran.r-project.org\nRstudio is available at https://posit.co/download/rstudio-desktop\n\n\n\n\nFor R, From a command line:\n$ R \nFor Rstudio, use the icon/shortcut or from a command line:\n$ rstudio \n\n\n\n\nvscode is a very powerful “IDE” (integrated development environment).\nit can integrate jupyter notebooks and r workbooks, though it takes some setting up\nvscode is integrated with GitHub copilot, a version of ChatGPT-3 that helps write code.\nvscode is available at http://code.visualstudio.com for windows, linux, and macOS.\n\n\n\n\nVSCode (visual studio code) is a freely distributed code editor/IDE distributed by microsoft.\nIt is extremely capable and well-suited for software development in python and other languages.\nIt is perhaps not as optimized for R as Rstudio but it does work.\nYou can access github copilot a version of chatGPT optimized for code, inside vscode in a straightforward way.\n\n\n\nThe software is available here.\nYou need a github account to use github copilot, and you need to sign in to that account from inside vscode. GitHub copilot is free to students, but you need to sign up for the student developer pack..\n\n\n\n\n\nOpening folders (as projects)\nOpening files\nInstall Extensions:\n\npython\nR\nmany others\n\nThe command palette\n\n\n\n\n\njupyter notebooks inside vscode with github copilot\nInteractive python with code cells (# %%)\nThe terminal\n\n\n\n\n\nCreate a project directory\nSubdirectories\n\ndata for data files\ndocs for notes and documentation\nothers?\n\nCreate a README.md file\n\n\n\n\nFor the directories:\n\nthe finder or File Manager\nthe command line\n\nFor the README file:\n\na text editor such as nano or notepad\njupyter or Rstudio (as we will see soon)\nvscode",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#anaconda-install-for-python",
    "href": "chapters/01-SettingUp/setting-up.html#anaconda-install-for-python",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Download from https://www.anaconda.com\n\nAnaconda includes:\n\npython\njupyter: notebook working environment\npython libraries: ML, visualization, I/O and others\nconda package manager: for dealing with multiple versions of libraries\nanaconda navigator: a GUI gateway to anaconda tools\nlots of other stuff",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#verify-jupyter",
    "href": "chapters/01-SettingUp/setting-up.html#verify-jupyter",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Verify JupyterLab\n\nFrom a command line\n$ jupyter lab \nor use anaconda navigator to launch jupyterlab.\n\n\nVerify python version\n\nFrom a command line\n$ python --version\nor inside a jupyter notebook cell:\nimport sys\n\nprint(sys.version)",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#optional-jupyter-on-uconns-hpc-cluster",
    "href": "chapters/01-SettingUp/setting-up.html#optional-jupyter-on-uconns-hpc-cluster",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Some notes on how to run Jupyter on the HPC cluster",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#r-and-rstudio-install-for-r",
    "href": "chapters/01-SettingUp/setting-up.html#r-and-rstudio-install-for-r",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "R is an open source language for statistical computations.\nRstudio is a working environment for the R language.\nR and Rstudio need to be installed separately.\nR is available at https://cran.r-project.org\nRstudio is available at https://posit.co/download/rstudio-desktop",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#verify-r-and-rstudio",
    "href": "chapters/01-SettingUp/setting-up.html#verify-r-and-rstudio",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "For R, From a command line:\n$ R \nFor Rstudio, use the icon/shortcut or from a command line:\n$ rstudio",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#vscode",
    "href": "chapters/01-SettingUp/setting-up.html#vscode",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "vscode is a very powerful “IDE” (integrated development environment).\nit can integrate jupyter notebooks and r workbooks, though it takes some setting up\nvscode is integrated with GitHub copilot, a version of ChatGPT-3 that helps write code.\nvscode is available at http://code.visualstudio.com for windows, linux, and macOS.",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#using-vscode",
    "href": "chapters/01-SettingUp/setting-up.html#using-vscode",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "VSCode (visual studio code) is a freely distributed code editor/IDE distributed by microsoft.\nIt is extremely capable and well-suited for software development in python and other languages.\nIt is perhaps not as optimized for R as Rstudio but it does work.\nYou can access github copilot a version of chatGPT optimized for code, inside vscode in a straightforward way.",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#installing-vscode",
    "href": "chapters/01-SettingUp/setting-up.html#installing-vscode",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "The software is available here.\nYou need a github account to use github copilot, and you need to sign in to that account from inside vscode. GitHub copilot is free to students, but you need to sign up for the student developer pack..",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#overview-of-vscode",
    "href": "chapters/01-SettingUp/setting-up.html#overview-of-vscode",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Opening folders (as projects)\nOpening files\nInstall Extensions:\n\npython\nR\nmany others\n\nThe command palette",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#more-on-vscode",
    "href": "chapters/01-SettingUp/setting-up.html#more-on-vscode",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "jupyter notebooks inside vscode with github copilot\nInteractive python with code cells (# %%)\nThe terminal",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#setting-up-a-project",
    "href": "chapters/01-SettingUp/setting-up.html#setting-up-a-project",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "Create a project directory\nSubdirectories\n\ndata for data files\ndocs for notes and documentation\nothers?\n\nCreate a README.md file",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/01-SettingUp/setting-up.html#tools",
    "href": "chapters/01-SettingUp/setting-up.html#tools",
    "title": "Key Tools for Data Science",
    "section": "",
    "text": "For the directories:\n\nthe finder or File Manager\nthe command line\n\nFor the README file:\n\na text editor such as nano or notepad\njupyter or Rstudio (as we will see soon)\nvscode",
    "crumbs": [
      "Contents",
      "Key Tools for Data Science"
    ]
  },
  {
    "objectID": "chapters/02-JupyterBasics/jupyter-walkthrough.html",
    "href": "chapters/02-JupyterBasics/jupyter-walkthrough.html",
    "title": "Jupyter Lab and Python Walkthrough",
    "section": "",
    "text": "Use the ‘text editor’ feature in Jupyter Lab to create your README.md file.\nRENAME YOUR NOTEBOOK FILE IMMEDIATELY to something relevant\nCTRL-ENTER executes a cell.\n\n\n\nThis is a markdown cell:\n\nHeadings are #, ##, etc.\nBold is marked **make me bold** like this.\nItalics are marked *make me italic* like this.\nMath can be typeset with if you know it: \\[f(x)=e^{-x}\\cos(x)\\]\nBulleted lists are marked with -.\n\n\n# code cells\n## Code cells contain python code that gets executed.\n# indicates a comment that is ignored.\nprint(\"Hello World!\")\n\nHello World!\n\n\nIn this walkthrough we will look at the following elements of Python in a jupyter notebook.\nThe print statement\n\nprint(\"hello world!\")\n\nhello world!\n\n\nVariables, variable names, and assignment/datatypes\n\ncount = 5  # an integer\nname = \"Jeremy Teitelbaum\"  # a string\nparagraph = \"\"\"This is how you enter a multiline string\nin python. It is enclosed in triple quotes.\"\"\"\npi = 3.14159  # a float\nepsilon = 1.0e-6  # a float\nstudents = [\"Jeremy\", \"Phillip\", \"Sara\", \"Molly\"]  # a list\nHotDog = True\n\n\nprint(students)\n\n['Jeremy', 'Phillip', 'Sara', 'Molly']\n\n\nCompare print for multiline strings with the string value. (\\n means newline)\n\nprint(paragraph)\n\nThis is how you enter a multiline string\nin python. It is enclosed in triple quotes.\n\n\n\nparagraph\n\n'This is how you enter a multiline string\\nin python. It is enclosed in triple quotes.'\n\n\nArithmetic operations\n\nprint(count)\ncount = count + 1\nprint(count)\n\n5\n6\n\n\n\n1 / pi\n\n0.31831015504887655\n\n\n\nprint(2**3)  # exponent\nprint(1 / 2)  # division (converts integer to float)\nprint(1 / (1 / 2))  # 2 becomes 2.0\n\n8\n0.5\n2.0\n\n\n\nquotient = 5 // 3  # integer division\nremainder = 5 % 3  # remainder\nprint(quotient, remainder)\n\n1 2\n\n\nOperations on strings and lists\n\n\"Jeremy\" + \" Teitelbaum\"\n\n'Jeremy Teitelbaum'\n\n\n\n[\"a\", \"b\", \"c\"] + [\"d\"]\n\n['a', 'b', 'c', 'd']\n\n\n\nlen(\"Jeremy\")\n\n6\n\n\n\nlen([\"Jeremy\", \"Teitelbaum\"])\n\n2\n\n\n\nfirstName = \"Jeremy\"\nlastName = \"Teitelbaum\"\nfullName = firstName + \" \" + lastName\n\nSome fancier printing\n\nprint(f\"The first name is {firstName}\")\nprint(f\"The last name is {lastName}\")\nprint(f\"The full name is {firstName} {lastName}\")\nprint(firstName, lastName, sep=\",\")\nprint(firstName, lastName, sep=\":\")\n\nThe first name is Jeremy\nThe last name is Teitelbaum\nThe full name is Jeremy Teitelbaum\nJeremy,Teitelbaum\nJeremy:Teitelbaum\n\n\nSlicing\nIn python, we always count from zero!!!\n\nfirstName[0]\n\n'J'\n\n\n\nlastName[1]\n\n'e'\n\n\n\n# [a:b] means from a to b-1 inclusive\n\nprint(firstName[0:3])\nprint(firstName[3:])\nprint(firstName[3:5])\n\nJer\nemy\nem\n\n\n\n# negative indices count from the end\nprint(firstName[-1])  # the last element\nprint(firstName[-3:-1])  # elements -3 and -2, but not -1\n\ny\nem\n\n\n\n# [a:b:c] means from a to b-1 in steps of c\n# missing numbers mean (beginnging):(end)\nprint(firstName[:5:2])\nprint(firstName[::2])\nprint(firstName[::-1])  # reverse the string\nprint(firstName[3::-1])  # 3,2,1,0\nprint(firstName[3:0:-1])  # 3,2,1\n\nJrm\nJrm\nymereJ\nereJ\nere\n\n\nSlices work the same on list elements\n\nprint(students[0])\nprint(students[-1])\nevery_other_student = students[::2]\nprint(every_other_student)\n\nJeremy\nMolly\n['Jeremy', 'Sara']\n\n\nLibraries\n\nimport math\n\n\nmath.log(23)\n\n3.1354942159291497\n\n\n\nmath.pi\n\n3.141592653589793\n\n\n\nmath.cos(math.pi / 2)  # should be zero\n\n6.123233995736766e-17\n\n\n\nmath.cos(math.pi / 2) == 0\n\nFalse\n\n\n\nabs(math.cos(math.pi / 2)) &lt; 1e-6\n\nTrue\n\n\n\nmath.pi == pi\n\nFalse\n\n\n\nimport numpy as np\n\n\nprint(np.random.randint(0, 10))\n\n3\n\n\n\nprint(np.__version__)\n\n1.24.3\n\n\n\nfrom numpy.random import randint\n\n\nrandint(1, 10)\n\n5\n\n\n\n\n\nA numpy array is like a list, but:\n- it's itended for use with numbers\n- it's designed for fast arithmetic and numerical operations\n- it can be multi-dimensional -- like a table or matrix -- although we won't use that here.\n\nx = np.array([1, 2, 3, 4, 5, 6])\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nYou access arrays like lists, and can use slices; indices start at zero.\n\nx[2:4]\n\narray([3, 4])\n\n\nWhen you apply an operation to an array, it gets applied to every element of the array.\n\nprint(f\"Square of x is {x**2}\")\nprint(f\"1/x is {1/x}\")\nprint(f\"cos(x) is {np.cos(x)}\")\n\nSquare of x is [ 1  4  9 16 25 36]\n1/x is [1.         0.5        0.33333333 0.25       0.2        0.16666667]\ncos(x) is [ 0.54030231 -0.41614684 -0.9899925  -0.65364362  0.28366219  0.96017029]\n\n\nSome special arrays.\n\nx = np.zeros(10)  # 10 zeros\ny = np.ones(20)  # 20 ones\nz = np.linspace(0, 10, 100)  # 100 equally spaced numbers from 0 to 10 **inclusive**\nw = np.array(list(range(-10, 10, 2)))\n\n\nprint(w)\n\n[-10  -8  -6  -4  -2   0   2   4   6   8]\n\n\n\nprint(z)\n\n[ 0.          0.1010101   0.2020202   0.3030303   0.4040404   0.50505051\n  0.60606061  0.70707071  0.80808081  0.90909091  1.01010101  1.11111111\n  1.21212121  1.31313131  1.41414141  1.51515152  1.61616162  1.71717172\n  1.81818182  1.91919192  2.02020202  2.12121212  2.22222222  2.32323232\n  2.42424242  2.52525253  2.62626263  2.72727273  2.82828283  2.92929293\n  3.03030303  3.13131313  3.23232323  3.33333333  3.43434343  3.53535354\n  3.63636364  3.73737374  3.83838384  3.93939394  4.04040404  4.14141414\n  4.24242424  4.34343434  4.44444444  4.54545455  4.64646465  4.74747475\n  4.84848485  4.94949495  5.05050505  5.15151515  5.25252525  5.35353535\n  5.45454545  5.55555556  5.65656566  5.75757576  5.85858586  5.95959596\n  6.06060606  6.16161616  6.26262626  6.36363636  6.46464646  6.56565657\n  6.66666667  6.76767677  6.86868687  6.96969697  7.07070707  7.17171717\n  7.27272727  7.37373737  7.47474747  7.57575758  7.67676768  7.77777778\n  7.87878788  7.97979798  8.08080808  8.18181818  8.28282828  8.38383838\n  8.48484848  8.58585859  8.68686869  8.78787879  8.88888889  8.98989899\n  9.09090909  9.19191919  9.29292929  9.39393939  9.49494949  9.5959596\n  9.6969697   9.7979798   9.8989899  10.        ]\n\n\n\n## Plotting with matplotlib\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot(z, z**2)\n\n\n\n\n\n\n\n\n\nz = np.linspace(-10, 10, 100)\nplt.axes()\nplt.plot(z, np.cos(z), color=\"red\")\nplt.title(\"A cosine curve\")\nplt.grid()\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\nplt.xticks(list(range(-10, 11)))\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\nText(0, 0.5, 'y')",
    "crumbs": [
      "Contents",
      "Jupyter Lab and Python Walkthrough"
    ]
  },
  {
    "objectID": "chapters/02-JupyterBasics/jupyter-walkthrough.html#markdown-cells",
    "href": "chapters/02-JupyterBasics/jupyter-walkthrough.html#markdown-cells",
    "title": "Jupyter Lab and Python Walkthrough",
    "section": "",
    "text": "This is a markdown cell:\n\nHeadings are #, ##, etc.\nBold is marked **make me bold** like this.\nItalics are marked *make me italic* like this.\nMath can be typeset with if you know it: \\[f(x)=e^{-x}\\cos(x)\\]\nBulleted lists are marked with -.\n\n\n# code cells\n## Code cells contain python code that gets executed.\n# indicates a comment that is ignored.\nprint(\"Hello World!\")\n\nHello World!\n\n\nIn this walkthrough we will look at the following elements of Python in a jupyter notebook.\nThe print statement\n\nprint(\"hello world!\")\n\nhello world!\n\n\nVariables, variable names, and assignment/datatypes\n\ncount = 5  # an integer\nname = \"Jeremy Teitelbaum\"  # a string\nparagraph = \"\"\"This is how you enter a multiline string\nin python. It is enclosed in triple quotes.\"\"\"\npi = 3.14159  # a float\nepsilon = 1.0e-6  # a float\nstudents = [\"Jeremy\", \"Phillip\", \"Sara\", \"Molly\"]  # a list\nHotDog = True\n\n\nprint(students)\n\n['Jeremy', 'Phillip', 'Sara', 'Molly']\n\n\nCompare print for multiline strings with the string value. (\\n means newline)\n\nprint(paragraph)\n\nThis is how you enter a multiline string\nin python. It is enclosed in triple quotes.\n\n\n\nparagraph\n\n'This is how you enter a multiline string\\nin python. It is enclosed in triple quotes.'\n\n\nArithmetic operations\n\nprint(count)\ncount = count + 1\nprint(count)\n\n5\n6\n\n\n\n1 / pi\n\n0.31831015504887655\n\n\n\nprint(2**3)  # exponent\nprint(1 / 2)  # division (converts integer to float)\nprint(1 / (1 / 2))  # 2 becomes 2.0\n\n8\n0.5\n2.0\n\n\n\nquotient = 5 // 3  # integer division\nremainder = 5 % 3  # remainder\nprint(quotient, remainder)\n\n1 2\n\n\nOperations on strings and lists\n\n\"Jeremy\" + \" Teitelbaum\"\n\n'Jeremy Teitelbaum'\n\n\n\n[\"a\", \"b\", \"c\"] + [\"d\"]\n\n['a', 'b', 'c', 'd']\n\n\n\nlen(\"Jeremy\")\n\n6\n\n\n\nlen([\"Jeremy\", \"Teitelbaum\"])\n\n2\n\n\n\nfirstName = \"Jeremy\"\nlastName = \"Teitelbaum\"\nfullName = firstName + \" \" + lastName\n\nSome fancier printing\n\nprint(f\"The first name is {firstName}\")\nprint(f\"The last name is {lastName}\")\nprint(f\"The full name is {firstName} {lastName}\")\nprint(firstName, lastName, sep=\",\")\nprint(firstName, lastName, sep=\":\")\n\nThe first name is Jeremy\nThe last name is Teitelbaum\nThe full name is Jeremy Teitelbaum\nJeremy,Teitelbaum\nJeremy:Teitelbaum\n\n\nSlicing\nIn python, we always count from zero!!!\n\nfirstName[0]\n\n'J'\n\n\n\nlastName[1]\n\n'e'\n\n\n\n# [a:b] means from a to b-1 inclusive\n\nprint(firstName[0:3])\nprint(firstName[3:])\nprint(firstName[3:5])\n\nJer\nemy\nem\n\n\n\n# negative indices count from the end\nprint(firstName[-1])  # the last element\nprint(firstName[-3:-1])  # elements -3 and -2, but not -1\n\ny\nem\n\n\n\n# [a:b:c] means from a to b-1 in steps of c\n# missing numbers mean (beginnging):(end)\nprint(firstName[:5:2])\nprint(firstName[::2])\nprint(firstName[::-1])  # reverse the string\nprint(firstName[3::-1])  # 3,2,1,0\nprint(firstName[3:0:-1])  # 3,2,1\n\nJrm\nJrm\nymereJ\nereJ\nere\n\n\nSlices work the same on list elements\n\nprint(students[0])\nprint(students[-1])\nevery_other_student = students[::2]\nprint(every_other_student)\n\nJeremy\nMolly\n['Jeremy', 'Sara']\n\n\nLibraries\n\nimport math\n\n\nmath.log(23)\n\n3.1354942159291497\n\n\n\nmath.pi\n\n3.141592653589793\n\n\n\nmath.cos(math.pi / 2)  # should be zero\n\n6.123233995736766e-17\n\n\n\nmath.cos(math.pi / 2) == 0\n\nFalse\n\n\n\nabs(math.cos(math.pi / 2)) &lt; 1e-6\n\nTrue\n\n\n\nmath.pi == pi\n\nFalse\n\n\n\nimport numpy as np\n\n\nprint(np.random.randint(0, 10))\n\n3\n\n\n\nprint(np.__version__)\n\n1.24.3\n\n\n\nfrom numpy.random import randint\n\n\nrandint(1, 10)\n\n5",
    "crumbs": [
      "Contents",
      "Jupyter Lab and Python Walkthrough"
    ]
  },
  {
    "objectID": "chapters/02-JupyterBasics/jupyter-walkthrough.html#numpy-arrays",
    "href": "chapters/02-JupyterBasics/jupyter-walkthrough.html#numpy-arrays",
    "title": "Jupyter Lab and Python Walkthrough",
    "section": "",
    "text": "A numpy array is like a list, but:\n- it's itended for use with numbers\n- it's designed for fast arithmetic and numerical operations\n- it can be multi-dimensional -- like a table or matrix -- although we won't use that here.\n\nx = np.array([1, 2, 3, 4, 5, 6])\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nYou access arrays like lists, and can use slices; indices start at zero.\n\nx[2:4]\n\narray([3, 4])\n\n\nWhen you apply an operation to an array, it gets applied to every element of the array.\n\nprint(f\"Square of x is {x**2}\")\nprint(f\"1/x is {1/x}\")\nprint(f\"cos(x) is {np.cos(x)}\")\n\nSquare of x is [ 1  4  9 16 25 36]\n1/x is [1.         0.5        0.33333333 0.25       0.2        0.16666667]\ncos(x) is [ 0.54030231 -0.41614684 -0.9899925  -0.65364362  0.28366219  0.96017029]\n\n\nSome special arrays.\n\nx = np.zeros(10)  # 10 zeros\ny = np.ones(20)  # 20 ones\nz = np.linspace(0, 10, 100)  # 100 equally spaced numbers from 0 to 10 **inclusive**\nw = np.array(list(range(-10, 10, 2)))\n\n\nprint(w)\n\n[-10  -8  -6  -4  -2   0   2   4   6   8]\n\n\n\nprint(z)\n\n[ 0.          0.1010101   0.2020202   0.3030303   0.4040404   0.50505051\n  0.60606061  0.70707071  0.80808081  0.90909091  1.01010101  1.11111111\n  1.21212121  1.31313131  1.41414141  1.51515152  1.61616162  1.71717172\n  1.81818182  1.91919192  2.02020202  2.12121212  2.22222222  2.32323232\n  2.42424242  2.52525253  2.62626263  2.72727273  2.82828283  2.92929293\n  3.03030303  3.13131313  3.23232323  3.33333333  3.43434343  3.53535354\n  3.63636364  3.73737374  3.83838384  3.93939394  4.04040404  4.14141414\n  4.24242424  4.34343434  4.44444444  4.54545455  4.64646465  4.74747475\n  4.84848485  4.94949495  5.05050505  5.15151515  5.25252525  5.35353535\n  5.45454545  5.55555556  5.65656566  5.75757576  5.85858586  5.95959596\n  6.06060606  6.16161616  6.26262626  6.36363636  6.46464646  6.56565657\n  6.66666667  6.76767677  6.86868687  6.96969697  7.07070707  7.17171717\n  7.27272727  7.37373737  7.47474747  7.57575758  7.67676768  7.77777778\n  7.87878788  7.97979798  8.08080808  8.18181818  8.28282828  8.38383838\n  8.48484848  8.58585859  8.68686869  8.78787879  8.88888889  8.98989899\n  9.09090909  9.19191919  9.29292929  9.39393939  9.49494949  9.5959596\n  9.6969697   9.7979798   9.8989899  10.        ]\n\n\n\n## Plotting with matplotlib\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot(z, z**2)\n\n\n\n\n\n\n\n\n\nz = np.linspace(-10, 10, 100)\nplt.axes()\nplt.plot(z, np.cos(z), color=\"red\")\nplt.title(\"A cosine curve\")\nplt.grid()\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\nplt.xticks(list(range(-10, 11)))\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\nText(0, 0.5, 'y')",
    "crumbs": [
      "Contents",
      "Jupyter Lab and Python Walkthrough"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-theory",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-theory",
    "title": "Statistical Basics",
    "section": "Probability Theory",
    "text": "Probability Theory\nProbability theory is based on:\n\nAn underlying collection \\(S\\) of all possible outcomes (a population or sample space) of an experiment.\nA rule \\(P\\) that assigns a number between zero and one to each subset of the sample space satisfying certain rules.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sample-space",
    "href": "chapters/04-StatBasics/stat-basics.html#sample-space",
    "title": "Statistical Basics",
    "section": "Sample Space",
    "text": "Sample Space\nFor example:\n\nFor a flip of a single coin, the possible outcomes are Heads and Tails and the sample space has two elements. For multiple flips, the outcomes are sequences of Heads and Tails.\nFor a measurement of temperature, we might model the possible outcomes, or the sample space, as all real numbers, recognizing that only some of them are actually possible results of the experiment.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#simple-events",
    "href": "chapters/04-StatBasics/stat-basics.html#simple-events",
    "title": "Statistical Basics",
    "section": "Simple Events",
    "text": "Simple Events\nThe elements of the sample space or population are the outcomes or simple events or sample points.\n\nFor a flip of a coin, the possible outcomes are Heads or Tails. For multiple flips, the possible outcomes are particular sequences of Heads or Tails.\nFor a measurement of temperature, a simple event would be a particular number obtained at a particular time.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#events",
    "href": "chapters/04-StatBasics/stat-basics.html#events",
    "title": "Statistical Basics",
    "section": "Events",
    "text": "Events\nSubsets of the population make up events or outcomes.\n\nAmong the population made up of sequences of 10 coin flips, the subset consisting of sequences containing at least 3 heads is an event.\nAmong the measurements of temperature, a measurement lying between say 22 and 25 degrees celsius would be an event.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-measure",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-measure",
    "title": "Statistical Basics",
    "section": "Probability Measure",
    "text": "Probability Measure\nThe last element of probability theory is the function P that assigns a number between 0 and 1 to every event such that\n\n\\(P(\\emptyset)=0\\)\n\\(P(S)=1\\).\nIf \\(A\\cap B=\\emptyset\\) then \\(P(A\\cup B)=P(A)+P(B)\\). This is also required to hold for infinite collections of disjoint sets but we won’t worry much about the foundations of probability.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#random-variables",
    "title": "Statistical Basics",
    "section": "Random Variables",
    "text": "Random Variables\nA random variable is a rule that assigns a number to an event.\n\nWe can assign the value 1 to heads and 0 to tails. This is a bernoulli random variable.\nOur sample space can be sets of 10 coin flips. The number of heads is a random variable.\nThe measurement of temperature yields a number.\n\nIf we pick a person at random, we can assign the value 1 if they wear glasses and 0 if not.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#discrete-vs-continuous-random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#discrete-vs-continuous-random-variables",
    "title": "Statistical Basics",
    "section": "Discrete vs Continuous Random Variables",
    "text": "Discrete vs Continuous Random Variables\nA discrete random variables takes “separate” values depending on the event. A continuous random variable takes values in a range.\n\nBernoulli random variable is discrete (0/1)\nNumber of heads in 10 flips is discrete (takes values 0,…,10)\nTemperature is continuous (in principle can get any reading)\nMass of a penguin is continuous\nSpecies of penguin is discrete",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#events-and-random-variables",
    "href": "chapters/04-StatBasics/stat-basics.html#events-and-random-variables",
    "title": "Statistical Basics",
    "section": "Events and Random Variables",
    "text": "Events and Random Variables\nSpecifying a value, or a range of values, for a random variable defines an event.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#bernoulli-example",
    "href": "chapters/04-StatBasics/stat-basics.html#bernoulli-example",
    "title": "Statistical Basics",
    "section": "Bernoulli example",
    "text": "Bernoulli example\n\nSample space is \\(\\{H,T\\}\\)\n\\(P(H)=p\\)\n\\(X\\) is the random variable with \\(X(H)=1\\) and \\(X(T)=0\\)\n\nThen:\n\n\\(X=1\\) is the same as the event \\(H\\)\n\\(P(X=1)\\)=p",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#independence",
    "href": "chapters/04-StatBasics/stat-basics.html#independence",
    "title": "Statistical Basics",
    "section": "Independence",
    "text": "Independence\nTwo events are independent if the chance of both occurring is the product of the chances of them occurring separately.\n\\[\nP(X\\cap Y)=P(X)P(Y)\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#binomial-example",
    "href": "chapters/04-StatBasics/stat-basics.html#binomial-example",
    "title": "Statistical Basics",
    "section": "Binomial Example",
    "text": "Binomial Example\nA binomial random variable (with parameters \\(n\\) and \\(p\\)) is the sum of \\(n\\) bernoulli random variables with probability \\(p\\). It corresponds to flipping a coin (with \\(P(H)=p\\)) \\(n\\) times and counting up the heads.\nThe probability of getting \\(k\\) heads is \\[\nP(k)=\\binom{n}{k}p^k(1-p)^{n-k}\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#binomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#binomial-distribution",
    "title": "Statistical Basics",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#continuous-example",
    "href": "chapters/04-StatBasics/stat-basics.html#continuous-example",
    "title": "Statistical Basics",
    "section": "Continuous example",
    "text": "Continuous example\n\nSample space is the possible temperatures at a particular point in space and time.\nRandom variable \\(T\\) is a measure of temperature.\n\\(P(21&lt;T&lt;22)\\) is the probability that the temperature is between 21 and 22 degrees.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#probability-density-functions",
    "href": "chapters/04-StatBasics/stat-basics.html#probability-density-functions",
    "title": "Statistical Basics",
    "section": "Probability density functions",
    "text": "Probability density functions\nIn the continuous case, probability is measured by a probability density function \\(P(x)\\). The classic example is the normal (bell-shaped) curve.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#density-functions",
    "href": "chapters/04-StatBasics/stat-basics.html#density-functions",
    "title": "Statistical Basics",
    "section": "Density Functions",
    "text": "Density Functions\nIf \\(P(x)\\) is the density function, then:\n\nthe probability that \\(x\\) lies between \\(a\\) and \\(b\\) is the area under density function between \\(a\\) and \\(b\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#area-gives-probability",
    "href": "chapters/04-StatBasics/stat-basics.html#area-gives-probability",
    "title": "Statistical Basics",
    "section": "Area gives probability",
    "text": "Area gives probability\n\nThe shaded area gives probability 0.87 for temp between 21.7 and 22.3.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#standard-normal",
    "href": "chapters/04-StatBasics/stat-basics.html#standard-normal",
    "title": "Statistical Basics",
    "section": "Standard Normal",
    "text": "Standard Normal\nA normal curve is defined by two parameters:\n\nthe mean \\(\\mu\\), which sets the location\nthe standard deviation \\(\\sigma\\) or its square, the variance \\(\\sigma^2\\), which sets the scale.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#z-score",
    "href": "chapters/04-StatBasics/stat-basics.html#z-score",
    "title": "Statistical Basics",
    "section": "Z-score",
    "text": "Z-score\nIf \\(x\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then \\[\nz = \\frac{x-\\mu}{\\sigma}\n\\] is a normal random variable with mean \\(0\\) and variance \\(1\\). This is called a \\(z\\)-score or a standard normal variable.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution",
    "title": "Statistical Basics",
    "section": "Cumulative Distribution",
    "text": "Cumulative Distribution\nThe cumulative distribution is a function \\(f(x)\\) such that \\(f(x)\\) is the the percentage of samples that are less than \\(x\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution-1",
    "href": "chapters/04-StatBasics/stat-basics.html#cumulative-distribution-1",
    "title": "Statistical Basics",
    "section": "Cumulative Distribution",
    "text": "Cumulative Distribution\n\nSo the median of the samples occurs where the \\(y\\)-axis is \\(.5\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#quantiles",
    "href": "chapters/04-StatBasics/stat-basics.html#quantiles",
    "title": "Statistical Basics",
    "section": "Quantiles",
    "text": "Quantiles\n\nIf \\(q\\) is between \\(0\\) and \\(1\\), then the \\(q^{th}\\) quantile \\(Q\\) of a random variable \\(x\\) is the value of \\(x\\) such that the fraction of the population with \\(x&lt;Q\\) is \\(q\\).\nThe median of \\(x\\) is the \\(.5\\) quantile for \\(x\\) because half of the population has values less than the median.\nOne can read quantiles from the cumulative distribution.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distributions-in-r",
    "href": "chapters/04-StatBasics/stat-basics.html#distributions-in-r",
    "title": "Statistical Basics",
    "section": "Distributions in R",
    "text": "Distributions in R\nThere are many distributions in R. We’ve talked about the binomial (discrete) and normal (continuous).\n\nrnorm (rbinom) draws samples from the distribution\ndnorm (dbinom) gives the value of the probability density function\npnorm (pbinom) gives the value of the cumulative density function\nqnorm (qbinom) gives the quantiles, that is, qnorm(p) gives the value of the parameter so that the probability of getting a result less than that parameter is p.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#examples-in-r",
    "href": "chapters/04-StatBasics/stat-basics.html#examples-in-r",
    "title": "Statistical Basics",
    "section": "Examples in R",
    "text": "Examples in R\n\nsamples &lt;- rnorm(10, mean = 0, sd = 1)\n\ndensityfn &lt;- dnorm(1, mean = 0, sd = 1)\ncdf &lt;- pnorm(1, mean = 0, sd = 1)\nquant &lt;- qnorm(.05, mean = 0, sd = 1)\ncat(\"samples: \", samples, \"\\n\")\n\nsamples:  -0.1043745 0.5584354 -0.5277565 0.5115066 1.300398 0.2761651 -0.2821563 1.608456 -0.611635 0.7147849 \n\ncat(\"Density=\", densityfn, \" CDF value=\", cdf, \" Quantile=\", quant)\n\nDensity= 0.2419707  CDF value= 0.8413447  Quantile= -1.644854",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distributions-in-python",
    "href": "chapters/04-StatBasics/stat-basics.html#distributions-in-python",
    "title": "Statistical Basics",
    "section": "Distributions in Python",
    "text": "Distributions in Python\nIn python the distributions are available in the scipy.stats library. Assuming import scipy.stats as sps:\n\nsps.norm.rvs draws from the distribution\nsps.norm.pdf is the density\nsps.norm.cdf is the cumulative distribution\nsps.norm.ppf are the quantiles",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#examples-in-python",
    "href": "chapters/04-StatBasics/stat-basics.html#examples-in-python",
    "title": "Statistical Basics",
    "section": "Examples in Python",
    "text": "Examples in Python\n\nimport scipy.stats as sps\n\nsamples = sps.norm.rvs(0, 1, size=10)\n\ndensityfn = sps.norm.pdf(1, 0, 1)\ncdf = sps.norm.cdf(1, 0, 1)\nquant = sps.norm.ppf(0.05, 0, 1)\nprint(\n    (\"samples = [ \" + \"{:.3f} \" * len(samples)).format(*samples) + \"]\",\n    \"Density={:.3f} CDF value={:.3f} Quantile={:.3f}\".format(densityfn, cdf, quant),\n)\n\nsamples = [ -1.593 -1.045 0.129 -0.124 1.632 -2.125 -0.992 -0.104 -0.171 -0.765 ] Density=0.242 CDF value=0.841 Quantile=-1.645",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics",
    "title": "Statistical Basics",
    "section": "Order Statistics",
    "text": "Order Statistics\nThe sample median and the sample quantiles (such as the 25th percentile or 75th percentile) are examples of order statistics.\nThe smallest element, the second smallest element, and so on are other examples of order statistics.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics-example",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics-example",
    "title": "Statistical Basics",
    "section": "Order Statistics example",
    "text": "Order Statistics example\nWe take 100 samples from a normal distribution and compute the median, minimum, and maximum. Then we do that 10000 times and produce a histogram.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#order-statistics-histogram",
    "href": "chapters/04-StatBasics/stat-basics.html#order-statistics-histogram",
    "title": "Statistical Basics",
    "section": "Order Statistics Histogram",
    "text": "Order Statistics Histogram",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#the-multinomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#the-multinomial-distribution",
    "title": "Statistical Basics",
    "section": "The multinomial distribution",
    "text": "The multinomial distribution\nThe multinomial distribution arises when you have \\(n\\) outcomes for your experiment, say \\(x_1,\\ldots, x_n\\); and the probability of getting \\(x_i\\) is \\(p_i\\). Here we have to have \\[\n\\sum p_{i}=1.\n\\]\nThis generalizes the bernoulli distribution.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean",
    "href": "chapters/04-StatBasics/stat-basics.html#mean",
    "title": "Statistical Basics",
    "section": "Mean",
    "text": "Mean\nThe mean of a random variable is perhaps the most important statistic associated with a probability space.\nThe mean is the “average value” of the random variable.\nThe mean of \\(x\\) is denoted \\(\\overline{x}\\) .\nExpectation or expected value is another name for the mean, and so the mean is also denoted \\(E(x)\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-discrete-case",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-discrete-case",
    "title": "Statistical Basics",
    "section": "Mean – discrete case",
    "text": "Mean – discrete case\nIn the discrete case:\n\\[\n\\overline{x}=\\sum_{a\\in X} x(a)p(a)\n\\]\nIn other words, the mean of \\(\\overline{x}\\) is the sum of \\(x\\) at each event, weighted by the probability of that event.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-a-bernoulli-random-variable",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-a-bernoulli-random-variable",
    "title": "Statistical Basics",
    "section": "Mean of a bernoulli random variable",
    "text": "Mean of a bernoulli random variable\nIf \\(x\\) is bernoulli, with \\(p(x=1)=p\\), then the mean of \\(x\\) is \\[\np(1)+(1-p)(0)=p.\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-a-binomial-random-variable",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-a-binomial-random-variable",
    "title": "Statistical Basics",
    "section": "Mean of a binomial random variable",
    "text": "Mean of a binomial random variable\nIf \\(x\\) is binomial, corresponding to the sum of \\(N\\) bernoulli random variables with probability \\(p\\), then \\[\n\\overline{x} = \\sum_{0\\le i\\le N} i\\binom{N}{i}p^{i}(1-p)^{N-i}=Np\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-continuous-case",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-continuous-case",
    "title": "Statistical Basics",
    "section": "Mean – continuous case",
    "text": "Mean – continuous case\nThe mean of a continuous random variable is given by an integral:\n\\[\n\\overline{x} = \\int_{X} xp(x) dx\n\\]\nwhere \\(p(x)\\) is the probability density. This is the limiting case of the formula in the discrete case.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#mean-of-standard-normal",
    "href": "chapters/04-StatBasics/stat-basics.html#mean-of-standard-normal",
    "title": "Statistical Basics",
    "section": "Mean of standard normal",
    "text": "Mean of standard normal\nThe mean of the standard normal is zero.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-and-standard-deviation",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-and-standard-deviation",
    "title": "Statistical Basics",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\nThe variance of a random variable measures how it is distributed around its mean value.\nThe variance is the average value of the difference between \\(x\\) and its mean.\n\\[\n\\sigma^2=E((x-\\overline{x})^2)\n\\]\nIn the case of a discrete random variable with outcomes values \\(x\\) having probability \\(p(x)\\), the variance is \\[\n\\sum_{x} (x-\\overline{x})^2p(x)\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-alternative-formula",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-alternative-formula",
    "title": "Statistical Basics",
    "section": "Variance alternative formula",
    "text": "Variance alternative formula\nThis is the same as\n\\[\n\\sigma^2 = \\overline{x^2}-(\\overline{x})^2\n\\]\nThe standard deviation is the square root of the variance.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-of-bernoulli",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-of-bernoulli",
    "title": "Statistical Basics",
    "section": "Variance of Bernoulli",
    "text": "Variance of Bernoulli\nIn the Bernoulli case, the variance is \\[\n(1-p)^2p+p^2(1-p)=p(1-p).\n\\]\nNotice that the maximum variance happens when \\(p=1/2\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#variance-of-binomial",
    "href": "chapters/04-StatBasics/stat-basics.html#variance-of-binomial",
    "title": "Statistical Basics",
    "section": "Variance of Binomial",
    "text": "Variance of Binomial\nA binomial random variable with probability \\(p\\) and \\(n\\) trials is a sum of \\(n\\) bernoulli random variables with probability \\(p\\). Using the formula you get \\[\n\\sigma^2 = \\sum_{i=0}^{n}(i-np)^2\\binom{n}{i}p^{i}(1-p)^{n-i}\n\\]\nThis turns out to be \\[\n\\sigma^2 = np(1-p).\n\\]\nNote: there are easier ways to get this formula. If two random variables are independent, then the variance of their sum is the sum of their variances.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling",
    "title": "Statistical Basics",
    "section": "Sampling",
    "text": "Sampling\nIn practice we study random variables through samples. A sample of a random variable is a choice of values distributed according to the associated probability. So for example a sample of a Bernoulli random variable is a coin flip where \\(P(H)=p\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling-1",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling-1",
    "title": "Statistical Basics",
    "section": "Sampling",
    "text": "Sampling\nIf we draw \\(N\\) sample values \\(x_i\\) ofa random variable, then the mean and variance of those sampled values, computed by\n\\[\n\\overline{x} = \\frac{1}{N}\\sum x_{i}\n\\]\nand \\[\n\\overline{x} = \\frac{1}{N-1}\\sum (x_{i}-\\overline{x})^2\n\\]",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sample-mean-and-variance",
    "href": "chapters/04-StatBasics/stat-basics.html#sample-mean-and-variance",
    "title": "Statistical Basics",
    "section": "Sample Mean and Variance",
    "text": "Sample Mean and Variance\nThe formulae above are called the sample mean and variance; they are estimates of the mean and variance of the underlying random variable.\nThe law of large numbers says that, as \\(N\\to\\infty\\), these estimates converge to the true values.\nIn general these values are also random (they depend on the particular choices drawn from the distribution) and follow their own probabilility distribution.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#distribution-of-sample-mean-and-variance",
    "href": "chapters/04-StatBasics/stat-basics.html#distribution-of-sample-mean-and-variance",
    "title": "Statistical Basics",
    "section": "Distribution of sample mean and variance",
    "text": "Distribution of sample mean and variance\nSo for example, if you sample a Bernoulli random variable \\(10\\) times, the mean is \\[\n\\frac{k}{N}\n\\] where \\(k\\) is the number of heads.\nThis mean follows a binomial distribution.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#sampling-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#sampling-distribution",
    "title": "Statistical Basics",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution\n\nBy looking at sample means (or other sample statistics) we can try to uncover information about the underlying probability distribution.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#hypothesis-testing",
    "href": "chapters/04-StatBasics/stat-basics.html#hypothesis-testing",
    "title": "Statistical Basics",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\nA statistical hypothesis is a claim about a particular population. A hypothesis test is a method to determine which of two contradictory hypotheses is supported by the data.\nUnderlying idea: a lot of surprising things happen by chance. If you do an experiment and observe an effect, that might be the result of pure chance. Can you quantify that?",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#an-example",
    "href": "chapters/04-StatBasics/stat-basics.html#an-example",
    "title": "Statistical Basics",
    "section": "An example",
    "text": "An example\nSuppose we have a coin and we’d like to do some testing to determine if we have reason to suspect that the coin is biased. Put another way, you’d like to know if this coin behaves differently from a reference, standard coin that is fair.\nNote this is more common than you might think. It might arise in the following circumstance in “real life.” You have two web pages, your current one and a proposed new one. You’d like to know if seeing the proposed one increases the chance of a viewer clicking through to something. This is called A/B testing and it amounts to comparing the probability of click-through in the reference case to the proposed case.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#null-and-alternative-hypotheses",
    "href": "chapters/04-StatBasics/stat-basics.html#null-and-alternative-hypotheses",
    "title": "Statistical Basics",
    "section": "Null (and alternative) hypotheses",
    "text": "Null (and alternative) hypotheses\nThe Null hypothesis is the hypotheses that our coin is fair, or that our two web pages yield the same results, or more generally that the observations we make are accounted for only by chance and not by some underlying effect. So our null hypothesis for our coin is “P=.5”.\nAn alternative hypothesis is a statement that contradicts the null hypothesis. For example, “P&gt;.5” or “P&lt;.5” or “P is different from .5.”",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#test-statistic",
    "href": "chapters/04-StatBasics/stat-basics.html#test-statistic",
    "title": "Statistical Basics",
    "section": "Test statistic",
    "text": "Test statistic\nA test statistic is a measurement of the data used to draw conclusions about the sample.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#back-to-our-example",
    "href": "chapters/04-StatBasics/stat-basics.html#back-to-our-example",
    "title": "Statistical Basics",
    "section": "Back to our example",
    "text": "Back to our example\nFor our test statistic, we are going to use the fraction of times we get a head in N flips.\nIn the A/B testing situation, our test statistic would be the fraction of times a person “clicked through” when given the proposed web site.\nIntuitively, if the fraction of heads differs significantly from the expected fraction of heads (.5) then we take that as strong evidence for the unfairness of our coin (or the increased value of our proposed web page).\nHow can we quantify this?",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-and-significance",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-and-significance",
    "title": "Statistical Basics",
    "section": "Rejection region and “significance”",
    "text": "Rejection region and “significance”\nTo make things concrete, suppose the coin is fair (in other words, the null hypothesis is true) we flip the coin \\(10\\) times. If the coin is far, we expect to get roughly 5 heads.\nThere’s a long tradition of saying something unlikely is “significant” if the chance of it occurring, assuming the null hypothesis, is less than .05 or one in twenty.\nThe chance of getting \\(0\\), \\(1\\), \\(9\\), or \\(10\\) heads is \\(.02\\). If we allow \\(2\\) or \\(8\\) heads in addition, the chance is about \\(11%\\), so if we set our significance level at \\(.05\\) we reject the null hypothesis if our experiment yields \\(0\\), \\(1\\), \\(9\\), or \\(10\\) heads.\nThis is the “rejection region.”",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-plot-code",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-plot-code",
    "title": "Statistical Basics",
    "section": "Rejection Region (plot code)",
    "text": "Rejection Region (plot code)\n\nlibrary(ggplot2)\n# two-sided\nrejection2 &lt;- function(n,d=10) {\n    results &lt;- data.frame(\n            x=seq(0,n),\n            y=dbinom(seq(0,n),n,.5),\n            keep=sapply(seq(0,n),\n                function(x) \n                    (x&lt;qbinom(.025,n,.5)) | (x&gt;qbinom(.975,n,.5))))\n    ggplot(\n        data=results,aes(x=x,y=y,fill=keep))+ \n        geom_bar(stat=\"identity\")+\n        scale_x_continuous(breaks=seq(0,n,d))+\n        ggtitle(\"Two sided rejection region at alpha=.05\")\n    \n}",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#more-code",
    "href": "chapters/04-StatBasics/stat-basics.html#more-code",
    "title": "Statistical Basics",
    "section": "More code",
    "text": "More code\n\nrejection1 &lt;-function(n,d=10) {\n    results &lt;- data.frame(\n        x=seq(0,n),\n        y=dbinom(seq(0,n),n,.5),\n        keep=sapply(seq(0,n),function(x) (x&gt;qbinom(.95,n,.5))))\n    ggplot(data=results,aes(x=x,y=y,fill=keep))+\n    geom_bar(stat=\"identity\")+\n    scale_x_continuous(breaks=seq(0,n,d))+\n    ggtitle(\"One sided rejection region at alpha=.05\")\n}",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#rejection-region-plotted",
    "href": "chapters/04-StatBasics/stat-basics.html#rejection-region-plotted",
    "title": "Statistical Basics",
    "section": "Rejection Region (plotted)",
    "text": "Rejection Region (plotted)",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-test",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-test",
    "title": "Statistical Basics",
    "section": "One-sided test",
    "text": "One-sided test\nSuppose you want evidence that your coin is more likely to get heads.\n-Your null hypothesis is that your coin has \\(p=.5\\). Your alternative hypothesis is \\(p&gt;.5\\).\n\nThe probability of getting 0,1,2 heads is \\(.054\\), which is a bit larger than \\(.05\\). So the one-sided test would reach significance only at 0 or 1 heads same as the two-sided test.\nBut suppose we did 50 flips? Then the one- and two-sided limits are slightly different on the right.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region",
    "title": "Statistical Basics",
    "section": "One-sided rejection region",
    "text": "One-sided rejection region",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region-1",
    "href": "chapters/04-StatBasics/stat-basics.html#one-sided-rejection-region-1",
    "title": "Statistical Basics",
    "section": "One-sided rejection region",
    "text": "One-sided rejection region",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#normal-approximation",
    "href": "chapters/04-StatBasics/stat-basics.html#normal-approximation",
    "title": "Statistical Basics",
    "section": "Normal approximation",
    "text": "Normal approximation\nFor large \\(n\\), the binomial distribution distribution with probability \\(p\\) becomes a version of the normal distribution with mean \\(Np\\) and standard deviation \\(\\sqrt{Np(1-p)}\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#normal-and-binomial-distribution",
    "href": "chapters/04-StatBasics/stat-basics.html#normal-and-binomial-distribution",
    "title": "Statistical Basics",
    "section": "Normal and binomial distribution",
    "text": "Normal and binomial distribution\n\nSo one can use the normal distribution to determine the rejection region if \\(n\\) is large.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#errors",
    "href": "chapters/04-StatBasics/stat-basics.html#errors",
    "title": "Statistical Basics",
    "section": "Errors",
    "text": "Errors\nTwo things can go wrong:\n\nType I error: You reject the null hypothesis, but the null hypothesis is true. The probability of a Type I error is something you choose when you set the significance level. This is usually called \\(\\alpha\\).\nType II error: You accept the null hypothesis when it is false. In this case, you’ve missed an actual effect. This probability of this is called \\(\\beta\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#tradeoff-between-error-types",
    "href": "chapters/04-StatBasics/stat-basics.html#tradeoff-between-error-types",
    "title": "Statistical Basics",
    "section": "Tradeoff between error types",
    "text": "Tradeoff between error types\nOther things equal, if you make \\(\\alpha\\) smaller (thus reducing the chance of a Type I error) you make \\(\\beta\\) bigger (increasing the chance of a type II error).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#statistical-power",
    "href": "chapters/04-StatBasics/stat-basics.html#statistical-power",
    "title": "Statistical Basics",
    "section": "Statistical Power",
    "text": "Statistical Power\nInformally, statistical power measures the ability of an experiment to detect a real effect. If a study has high power, then you are very unlikely to make a Type II error.\nFor example, return to the coin flipping problem (or the A/B testing problem).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power",
    "href": "chapters/04-StatBasics/stat-basics.html#power",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nSuppose we flip our coin \\(20\\) times and our null hypothesis is that \\(p=.5\\) If our significance level is \\(.05\\), we will reject the null hypothesis and conclude that the coin is not fair (and biased towards heads) provided we get \\(15\\) or more heads.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-computations",
    "href": "chapters/04-StatBasics/stat-basics.html#power-computations",
    "title": "Statistical Basics",
    "section": "Power Computations",
    "text": "Power Computations\n\n# look at the probability density for this case\nprobs &lt;- dbinom(seq(0, 20), 20, .5)\n# The qbinom function tells us the threshold\nrejection &lt;- qbinom(.95, 20, .5)\n# We check this by comparing the probability of $15-20$ vs $14-20$ heads:\nsum(probs[16:21]) # remember probs[i] is the chance of i-1 heads\n\n[1] 0.02069473\n\nsum(probs[15:21])\n\n[1] 0.05765915\n\n# The chance of $15-20$ heads is greater than $.05$.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-1",
    "href": "chapters/04-StatBasics/stat-basics.html#power-1",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nNow suppose the coin is not fair and \\(p=.6\\). What is the chance that we accept the null hypothesis and conclude, falsely, that the coin is fair? It is the chance that we get \\(14\\) or fewer heads when \\(p=.6\\).\n\nprobs6 &lt;- dbinom(seq(0, 20), 20, .6)\nsum(probs6[1:15])\n\n[1] 0.874401\n\n\nThis is \\(87\\) percent! In other words, our experiment is very unlikely to detect the unfairness of the coin if the unfairness is only the difference between \\(p=.6\\) and \\(p=.5\\)",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#power-2",
    "href": "chapters/04-StatBasics/stat-basics.html#power-2",
    "title": "Statistical Basics",
    "section": "Power",
    "text": "Power\nBut if the coin is very unfair, with, say \\(p=.8\\), then we find:\n\nprobs8 &lt;- dbinom(seq(0, 20), 20, .8)\nsum(probs8[1:15])\n\n[1] 0.1957922\n\n\nWe have only a 20% chance of a Type II error so there’s an 80% chance we’ll detect the difference.\nNow suppose we use \\(100\\) flips.\n\nrejection &lt;- qbinom(.95, 100, .5)\nprobs6 &lt;- dbinom(seq(0, 100), 100, .6)\nsum(probs6[1:rejection])\n\n[1] 0.3032601\n\n\nNow we have a 70% chance of detecting the difference unfairness of \\(p=.6\\).",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#more-on-ab-example",
    "href": "chapters/04-StatBasics/stat-basics.html#more-on-ab-example",
    "title": "Statistical Basics",
    "section": "More on AB example",
    "text": "More on AB example\nNull hypothesis: the two ads are the same, and of the 9400 who see an ad, 2108 click through. This is a probabiility of 22.4%.\nThe .95 quantile for the binomial distribution with n=4600 and p=.224 is 1077. Thus the 1133 click through rate is significantly higher. Similarly the 975 out of 4800 is significantly lower.\nSo ad B is better than ad A at the .05 significance level. In fact the odds of getting a number as high as 1133 is more like 1 in 10^4 so the evidence for ad b is overwhelming.",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/04-StatBasics/stat-basics.html#simulation",
    "href": "chapters/04-StatBasics/stat-basics.html#simulation",
    "title": "Statistical Basics",
    "section": "Simulation",
    "text": "Simulation\nBy simulation:\n\nsimulated &lt;- rbinom(10000, 4600, .224)\nsum(simulated &gt;= 1133)\n\n[1] 3",
    "crumbs": [
      "Contents",
      "Statistical Basics"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html",
    "href": "chapters/05-WorkingWithData/pythonAndR.html",
    "title": "Data Structures and Functions in R and Python",
    "section": "",
    "text": "Both R and Python have data structures like excel spreadsheets that are the basic way to organize tabular data.\nIn R, these tools are packaged together in a family of libraries called the tidyverse.\nIn Python they are packaged in two closely related libraries, numpy (which handles numerical linear algebra) and pandas which handles tabular data.\nIn Python, these tabular data structures are called dataframes; in R they are called tibbles (there are dataframes in R as well but the tidyverse package mainly uses tibbles.)",
    "crumbs": [
      "Contents",
      "Data Structures and Functions in R and Python"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#basic-data-structures-for-analysis",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#basic-data-structures-for-analysis",
    "title": "Data Structures and Functions in R and Python",
    "section": "",
    "text": "Both R and Python have data structures like excel spreadsheets that are the basic way to organize tabular data.\nIn R, these tools are packaged together in a family of libraries called the tidyverse.\nIn Python they are packaged in two closely related libraries, numpy (which handles numerical linear algebra) and pandas which handles tabular data.\nIn Python, these tabular data structures are called dataframes; in R they are called tibbles (there are dataframes in R as well but the tidyverse package mainly uses tibbles.)",
    "crumbs": [
      "Contents",
      "Data Structures and Functions in R and Python"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#features",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#features",
    "title": "Data Structures and Functions in R and Python",
    "section": "Features",
    "text": "Features\nThe basic operations that both R and Python offer are\n\nmapping a function to a column of data and creating a new column\nselecting a particular column\nfiltering to select rows where column entries meet a condition\ngrouping rows by keys\nsummarizing data by computing sums, counts, averages, variances, and so on.",
    "crumbs": [
      "Contents",
      "Data Structures and Functions in R and Python"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#visualization",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#visualization",
    "title": "Data Structures and Functions in R and Python",
    "section": "Visualization",
    "text": "Visualization\nIn addition, both R and Python have plotting libraries that rely on dataframes/tibbles as input and libraries that apply ML algorithms to tabular data stored in dataframes/tibbles.",
    "crumbs": [
      "Contents",
      "Data Structures and Functions in R and Python"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/pythonAndR.html#walkthroughs",
    "href": "chapters/05-WorkingWithData/pythonAndR.html#walkthroughs",
    "title": "Data Structures and Functions in R and Python",
    "section": "Walkthroughs",
    "text": "Walkthroughs\n\nR/basics of R programming\nR/tidyverse walkthrough\nPython/basics of python programming\nPython/pandas walkthrough\n\nTo download the materials including the data so you can work with them locally, follow this link.",
    "crumbs": [
      "Contents",
      "Data Structures and Functions in R and Python"
    ]
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_penguins.html",
    "href": "chapters/05-WorkingWithData/r_penguins.html",
    "title": "Working with data in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\ncat(paste(R.version$version.string, \"\\n\"))\n\nR version 4.3.2 (2023-10-31) \n\n\n\n\n\n\npenguins &lt;- read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\ncat(\"Rows:\", nrow(penguins), \", Columns:\", ncol(penguins), \"\\n\")\n\nRows: 344 , Columns: 17 \n\n\n\n\n\n\ncat(\"Columns:\\n\")\n\nColumns:\n\nprint(colnames(penguins))\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n\n\n\n\nsimpler &lt;- penguins |&gt; select(`Species`, `Body Mass (g)`, `Flipper Length (mm)`)\nhead(simpler)\n\n# A tibble: 6 × 3\n  Species                             `Body Mass (g)` `Flipper Length (mm)`\n  &lt;chr&gt;                                         &lt;dbl&gt;                 &lt;dbl&gt;\n1 Adelie Penguin (Pygoscelis adeliae)            3750                   181\n2 Adelie Penguin (Pygoscelis adeliae)            3800                   186\n3 Adelie Penguin (Pygoscelis adeliae)            3250                   195\n4 Adelie Penguin (Pygoscelis adeliae)              NA                    NA\n5 Adelie Penguin (Pygoscelis adeliae)            3450                   193\n6 Adelie Penguin (Pygoscelis adeliae)            3650                   190\n\n\n\n\n\n\nprint(rownames(penguins))\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\" \"151\" \"152\" \"153\" \"154\" \"155\" \"156\"\n[157] \"157\" \"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\"\n[169] \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\"\n[181] \"181\" \"182\" \"183\" \"184\" \"185\" \"186\" \"187\" \"188\" \"189\" \"190\" \"191\" \"192\"\n[193] \"193\" \"194\" \"195\" \"196\" \"197\" \"198\" \"199\" \"200\" \"201\" \"202\" \"203\" \"204\"\n[205] \"205\" \"206\" \"207\" \"208\" \"209\" \"210\" \"211\" \"212\" \"213\" \"214\" \"215\" \"216\"\n[217] \"217\" \"218\" \"219\" \"220\" \"221\" \"222\" \"223\" \"224\" \"225\" \"226\" \"227\" \"228\"\n[229] \"229\" \"230\" \"231\" \"232\" \"233\" \"234\" \"235\" \"236\" \"237\" \"238\" \"239\" \"240\"\n[241] \"241\" \"242\" \"243\" \"244\" \"245\" \"246\" \"247\" \"248\" \"249\" \"250\" \"251\" \"252\"\n[253] \"253\" \"254\" \"255\" \"256\" \"257\" \"258\" \"259\" \"260\" \"261\" \"262\" \"263\" \"264\"\n[265] \"265\" \"266\" \"267\" \"268\" \"269\" \"270\" \"271\" \"272\" \"273\" \"274\" \"275\" \"276\"\n[277] \"277\" \"278\" \"279\" \"280\" \"281\" \"282\" \"283\" \"284\" \"285\" \"286\" \"287\" \"288\"\n[289] \"289\" \"290\" \"291\" \"292\" \"293\" \"294\" \"295\" \"296\" \"297\" \"298\" \"299\" \"300\"\n[301] \"301\" \"302\" \"303\" \"304\" \"305\" \"306\" \"307\" \"308\" \"309\" \"310\" \"311\" \"312\"\n[313] \"313\" \"314\" \"315\" \"316\" \"317\" \"318\" \"319\" \"320\" \"321\" \"322\" \"323\" \"324\"\n[325] \"325\" \"326\" \"327\" \"328\" \"329\" \"330\" \"331\" \"332\" \"333\" \"334\" \"335\" \"336\"\n[337] \"337\" \"338\" \"339\" \"340\" \"341\" \"342\" \"343\" \"344\"\n\n\n\n\n\n\npenguins[23, ]\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                23 Adelie Penguin … Anvers Biscoe Adul… N12A1          \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\npenguins[23, \"Culmen Length (mm)\"]\n\n# A tibble: 1 × 1\n  `Culmen Length (mm)`\n                 &lt;dbl&gt;\n1                 35.9\n\n\n\n\n\n\npenguins[23:28, c(\"Sex\", \"Date Egg\")]\n\n# A tibble: 6 × 2\n  Sex    `Date Egg`\n  &lt;chr&gt;  &lt;date&gt;    \n1 FEMALE 2007-11-12\n2 MALE   2007-11-12\n3 MALE   2007-11-10\n4 FEMALE 2007-11-10\n5 MALE   2007-11-12\n6 FEMALE 2007-11-12\n\n\n\n\n\n\npenguins |&gt; count(Island)\n\n# A tibble: 3 × 2\n  Island        n\n  &lt;chr&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n\n\n\n\n\npenguins |&gt; count(Species)\n\n# A tibble: 3 × 2\n  Species                                       n\n  &lt;chr&gt;                                     &lt;int&gt;\n1 Adelie Penguin (Pygoscelis adeliae)         152\n2 Chinstrap penguin (Pygoscelis antarctica)    68\n3 Gentoo penguin (Pygoscelis papua)           124\n\n\n\n\n\n\nfemales &lt;- penguins |&gt; filter(Sex == \"FEMALE\")\nhead(females)\n\n# A tibble: 6 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n2 PAL0708                 3 Adelie Penguin … Anvers Torge… Adul… N2A1           \n3 PAL0708                 5 Adelie Penguin … Anvers Torge… Adul… N3A1           \n4 PAL0708                 7 Adelie Penguin … Anvers Torge… Adul… N4A1           \n5 PAL0708                13 Adelie Penguin … Anvers Torge… Adul… N7A1           \n6 PAL0708                16 Adelie Penguin … Anvers Torge… Adul… N8A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\npenguins |&gt; filter(`Flipper Length (mm)` &gt; `Body Mass (g)` / 20)\n\n# A tibble: 147 × 17\n   studyName `Sample Number` Species         Region Island Stage `Individual ID`\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n 1 PAL0708                 3 Adelie Penguin… Anvers Torge… Adul… N2A1           \n 2 PAL0708                 5 Adelie Penguin… Anvers Torge… Adul… N3A1           \n 3 PAL0708                 6 Adelie Penguin… Anvers Torge… Adul… N3A2           \n 4 PAL0708                 9 Adelie Penguin… Anvers Torge… Adul… N5A1           \n 5 PAL0708                11 Adelie Penguin… Anvers Torge… Adul… N6A1           \n 6 PAL0708                13 Adelie Penguin… Anvers Torge… Adul… N7A1           \n 7 PAL0708                14 Adelie Penguin… Anvers Torge… Adul… N7A2           \n 8 PAL0708                17 Adelie Penguin… Anvers Torge… Adul… N9A1           \n 9 PAL0708                19 Adelie Penguin… Anvers Torge… Adul… N10A1          \n10 PAL0708                21 Adelie Penguin… Anvers Biscoe Adul… N11A1          \n# ℹ 137 more rows\n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\ncolSums(is.na(penguins))\n\n          studyName       Sample Number             Species              Region \n                  0                   0                   0                   0 \n             Island               Stage       Individual ID   Clutch Completion \n                  0                   0                   0                   0 \n           Date Egg  Culmen Length (mm)   Culmen Depth (mm) Flipper Length (mm) \n                  0                   2                   2                   2 \n      Body Mass (g)                 Sex   Delta 15 N (o/oo)   Delta 13 C (o/oo) \n                  2                  11                  14                  13 \n           Comments \n                290 \n\n\n\n\n\n\npenguins &lt;- penguins |&gt; select(-Comments)\n\n\n\n\n\npenguins_nona &lt;- penguins |&gt; drop_na()\ndim(penguins_nona)\n\n[1] 324  16\n\n\n\n\n\n\npenguins_imputed &lt;- penguins |&gt;\n    mutate(`Culmen Length (mm)` = if_else(is.na(`Culmen Length (mm)`), mean(`Culmen Length (mm)`, na.rm = TRUE), `Culmen Length (mm)`))\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(Sex = as.factor(Sex))\n\n\n\n\n\nggplot(data = penguins, aes(x = Sex)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(SimpleSpecies = word(Species, 1))\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(`Body Mass (kg)` = `Body Mass (g)` / 1000)\n\n\n\n\n\npenguins_small &lt;- penguins |&gt; select(Species, Island, `Body Mass (g)`)\npenguins_small |&gt; arrange(`Body Mass (g)`)\n\n# A tibble: 344 × 3\n   Species                                   Island    `Body Mass (g)`\n   &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;\n 1 Chinstrap penguin (Pygoscelis antarctica) Dream                2700\n 2 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 3 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 4 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2900\n 5 Adelie Penguin (Pygoscelis adeliae)       Dream                2900\n 6 Adelie Penguin (Pygoscelis adeliae)       Torgersen            2900\n 7 Chinstrap penguin (Pygoscelis antarctica) Dream                2900\n 8 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2925\n 9 Adelie Penguin (Pygoscelis adeliae)       Dream                2975\n10 Adelie Penguin (Pygoscelis adeliae)       Dream                3000\n# ℹ 334 more rows\n\n\n\n\n\n\npenguins_by_species &lt;- penguins |&gt; group_by(Species)\n#### summarize the \"Body Mass (g)\" column for each group\n\n\npenguins_by_species |&gt; drop_na()|&gt; summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n# A tibble: 3 × 4\n  Species                                    mean    sd     n\n  &lt;chr&gt;                                     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Adelie Penguin (Pygoscelis adeliae)       3703.  460.   139\n2 Chinstrap penguin (Pygoscelis antarctica) 3730.  386.    67\n3 Gentoo penguin (Pygoscelis papua)         5091.  503.   118\n\n\n\n\n\n\npenguins_by_sex_and_species &lt;- penguins |&gt; group_by(Sex, Species)\n\n\n\n\n\npenguins_by_sex_and_species |&gt; summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 8 × 5\n# Groups:   Sex [3]\n  Sex    Species                                    mean    sd     n\n  &lt;fct&gt;  &lt;chr&gt;                                     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 FEMALE Adelie Penguin (Pygoscelis adeliae)       3369.  269.    73\n2 FEMALE Chinstrap penguin (Pygoscelis antarctica) 3527.  285.    34\n3 FEMALE Gentoo penguin (Pygoscelis papua)         4680.  282.    58\n4 MALE   Adelie Penguin (Pygoscelis adeliae)       4043.  347.    73\n5 MALE   Chinstrap penguin (Pygoscelis antarctica) 3939.  362.    34\n6 MALE   Gentoo penguin (Pygoscelis papua)         5485.  313.    61\n7 &lt;NA&gt;   Adelie Penguin (Pygoscelis adeliae)         NA    NA      6\n8 &lt;NA&gt;   Gentoo penguin (Pygoscelis papua)           NA    NA      5\n\n\n\n\n\n\npenguins_by_sex_and_species |&gt;\n    summarize(mean = mean(`Body Mass (g)`)) |&gt;\n    pivot_wider(names_from = Species, values_from = mean)\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 3 × 4\n# Groups:   Sex [3]\n  Sex    Adelie Penguin (Pygosce…¹ Chinstrap penguin (P…² Gentoo penguin (Pygo…³\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 FEMALE                     3369.                  3527.                  4680.\n2 MALE                       4043.                  3939.                  5485.\n3 &lt;NA&gt;                         NA                     NA                     NA \n# ℹ abbreviated names: ¹​`Adelie Penguin (Pygoscelis adeliae)`,\n#   ²​`Chinstrap penguin (Pygoscelis antarctica)`,\n#   ³​`Gentoo penguin (Pygoscelis papua)`\n\n\n\n\n\n\npenguins |&gt;\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |&gt;\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |&gt;\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\n\n\nOne can also work with excel files. You need the readxl library.\n\nlibrary(\"readxl\")\n\nAs an example, we use an excel spreadsheet violent crime data from the FBI."
  },
  {
    "objectID": "chapters/05-WorkingWithData/r_penguins.html#working-with-data-in-r",
    "href": "chapters/05-WorkingWithData/r_penguins.html#working-with-data-in-r",
    "title": "Working with data in R",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\ncat(paste(R.version$version.string, \"\\n\"))\n\nR version 4.3.2 (2023-10-31) \n\n\n\n\n\n\npenguins &lt;- read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\ncat(\"Rows:\", nrow(penguins), \", Columns:\", ncol(penguins), \"\\n\")\n\nRows: 344 , Columns: 17 \n\n\n\n\n\n\ncat(\"Columns:\\n\")\n\nColumns:\n\nprint(colnames(penguins))\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n\n\n\n\nsimpler &lt;- penguins |&gt; select(`Species`, `Body Mass (g)`, `Flipper Length (mm)`)\nhead(simpler)\n\n# A tibble: 6 × 3\n  Species                             `Body Mass (g)` `Flipper Length (mm)`\n  &lt;chr&gt;                                         &lt;dbl&gt;                 &lt;dbl&gt;\n1 Adelie Penguin (Pygoscelis adeliae)            3750                   181\n2 Adelie Penguin (Pygoscelis adeliae)            3800                   186\n3 Adelie Penguin (Pygoscelis adeliae)            3250                   195\n4 Adelie Penguin (Pygoscelis adeliae)              NA                    NA\n5 Adelie Penguin (Pygoscelis adeliae)            3450                   193\n6 Adelie Penguin (Pygoscelis adeliae)            3650                   190\n\n\n\n\n\n\nprint(rownames(penguins))\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\" \"151\" \"152\" \"153\" \"154\" \"155\" \"156\"\n[157] \"157\" \"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\"\n[169] \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\"\n[181] \"181\" \"182\" \"183\" \"184\" \"185\" \"186\" \"187\" \"188\" \"189\" \"190\" \"191\" \"192\"\n[193] \"193\" \"194\" \"195\" \"196\" \"197\" \"198\" \"199\" \"200\" \"201\" \"202\" \"203\" \"204\"\n[205] \"205\" \"206\" \"207\" \"208\" \"209\" \"210\" \"211\" \"212\" \"213\" \"214\" \"215\" \"216\"\n[217] \"217\" \"218\" \"219\" \"220\" \"221\" \"222\" \"223\" \"224\" \"225\" \"226\" \"227\" \"228\"\n[229] \"229\" \"230\" \"231\" \"232\" \"233\" \"234\" \"235\" \"236\" \"237\" \"238\" \"239\" \"240\"\n[241] \"241\" \"242\" \"243\" \"244\" \"245\" \"246\" \"247\" \"248\" \"249\" \"250\" \"251\" \"252\"\n[253] \"253\" \"254\" \"255\" \"256\" \"257\" \"258\" \"259\" \"260\" \"261\" \"262\" \"263\" \"264\"\n[265] \"265\" \"266\" \"267\" \"268\" \"269\" \"270\" \"271\" \"272\" \"273\" \"274\" \"275\" \"276\"\n[277] \"277\" \"278\" \"279\" \"280\" \"281\" \"282\" \"283\" \"284\" \"285\" \"286\" \"287\" \"288\"\n[289] \"289\" \"290\" \"291\" \"292\" \"293\" \"294\" \"295\" \"296\" \"297\" \"298\" \"299\" \"300\"\n[301] \"301\" \"302\" \"303\" \"304\" \"305\" \"306\" \"307\" \"308\" \"309\" \"310\" \"311\" \"312\"\n[313] \"313\" \"314\" \"315\" \"316\" \"317\" \"318\" \"319\" \"320\" \"321\" \"322\" \"323\" \"324\"\n[325] \"325\" \"326\" \"327\" \"328\" \"329\" \"330\" \"331\" \"332\" \"333\" \"334\" \"335\" \"336\"\n[337] \"337\" \"338\" \"339\" \"340\" \"341\" \"342\" \"343\" \"344\"\n\n\n\n\n\n\npenguins[23, ]\n\n# A tibble: 1 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                23 Adelie Penguin … Anvers Biscoe Adul… N12A1          \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\npenguins[23, \"Culmen Length (mm)\"]\n\n# A tibble: 1 × 1\n  `Culmen Length (mm)`\n                 &lt;dbl&gt;\n1                 35.9\n\n\n\n\n\n\npenguins[23:28, c(\"Sex\", \"Date Egg\")]\n\n# A tibble: 6 × 2\n  Sex    `Date Egg`\n  &lt;chr&gt;  &lt;date&gt;    \n1 FEMALE 2007-11-12\n2 MALE   2007-11-12\n3 MALE   2007-11-10\n4 FEMALE 2007-11-10\n5 MALE   2007-11-12\n6 FEMALE 2007-11-12\n\n\n\n\n\n\npenguins |&gt; count(Island)\n\n# A tibble: 3 × 2\n  Island        n\n  &lt;chr&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n\n\n\n\n\npenguins |&gt; count(Species)\n\n# A tibble: 3 × 2\n  Species                                       n\n  &lt;chr&gt;                                     &lt;int&gt;\n1 Adelie Penguin (Pygoscelis adeliae)         152\n2 Chinstrap penguin (Pygoscelis antarctica)    68\n3 Gentoo penguin (Pygoscelis papua)           124\n\n\n\n\n\n\nfemales &lt;- penguins |&gt; filter(Sex == \"FEMALE\")\nhead(females)\n\n# A tibble: 6 × 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 2 Adelie Penguin … Anvers Torge… Adul… N1A2           \n2 PAL0708                 3 Adelie Penguin … Anvers Torge… Adul… N2A1           \n3 PAL0708                 5 Adelie Penguin … Anvers Torge… Adul… N3A1           \n4 PAL0708                 7 Adelie Penguin … Anvers Torge… Adul… N4A1           \n5 PAL0708                13 Adelie Penguin … Anvers Torge… Adul… N7A1           \n6 PAL0708                16 Adelie Penguin … Anvers Torge… Adul… N8A2           \n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\npenguins |&gt; filter(`Flipper Length (mm)` &gt; `Body Mass (g)` / 20)\n\n# A tibble: 147 × 17\n   studyName `Sample Number` Species         Region Island Stage `Individual ID`\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n 1 PAL0708                 3 Adelie Penguin… Anvers Torge… Adul… N2A1           \n 2 PAL0708                 5 Adelie Penguin… Anvers Torge… Adul… N3A1           \n 3 PAL0708                 6 Adelie Penguin… Anvers Torge… Adul… N3A2           \n 4 PAL0708                 9 Adelie Penguin… Anvers Torge… Adul… N5A1           \n 5 PAL0708                11 Adelie Penguin… Anvers Torge… Adul… N6A1           \n 6 PAL0708                13 Adelie Penguin… Anvers Torge… Adul… N7A1           \n 7 PAL0708                14 Adelie Penguin… Anvers Torge… Adul… N7A2           \n 8 PAL0708                17 Adelie Penguin… Anvers Torge… Adul… N9A1           \n 9 PAL0708                19 Adelie Penguin… Anvers Torge… Adul… N10A1          \n10 PAL0708                21 Adelie Penguin… Anvers Biscoe Adul… N11A1          \n# ℹ 137 more rows\n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n\n\n\n\ncolSums(is.na(penguins))\n\n          studyName       Sample Number             Species              Region \n                  0                   0                   0                   0 \n             Island               Stage       Individual ID   Clutch Completion \n                  0                   0                   0                   0 \n           Date Egg  Culmen Length (mm)   Culmen Depth (mm) Flipper Length (mm) \n                  0                   2                   2                   2 \n      Body Mass (g)                 Sex   Delta 15 N (o/oo)   Delta 13 C (o/oo) \n                  2                  11                  14                  13 \n           Comments \n                290 \n\n\n\n\n\n\npenguins &lt;- penguins |&gt; select(-Comments)\n\n\n\n\n\npenguins_nona &lt;- penguins |&gt; drop_na()\ndim(penguins_nona)\n\n[1] 324  16\n\n\n\n\n\n\npenguins_imputed &lt;- penguins |&gt;\n    mutate(`Culmen Length (mm)` = if_else(is.na(`Culmen Length (mm)`), mean(`Culmen Length (mm)`, na.rm = TRUE), `Culmen Length (mm)`))\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(Sex = as.factor(Sex))\n\n\n\n\n\nggplot(data = penguins, aes(x = Sex)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(SimpleSpecies = word(Species, 1))\n\n\n\n\n\npenguins &lt;- penguins |&gt; mutate(`Body Mass (kg)` = `Body Mass (g)` / 1000)\n\n\n\n\n\npenguins_small &lt;- penguins |&gt; select(Species, Island, `Body Mass (g)`)\npenguins_small |&gt; arrange(`Body Mass (g)`)\n\n# A tibble: 344 × 3\n   Species                                   Island    `Body Mass (g)`\n   &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;\n 1 Chinstrap penguin (Pygoscelis antarctica) Dream                2700\n 2 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 3 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2850\n 4 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2900\n 5 Adelie Penguin (Pygoscelis adeliae)       Dream                2900\n 6 Adelie Penguin (Pygoscelis adeliae)       Torgersen            2900\n 7 Chinstrap penguin (Pygoscelis antarctica) Dream                2900\n 8 Adelie Penguin (Pygoscelis adeliae)       Biscoe               2925\n 9 Adelie Penguin (Pygoscelis adeliae)       Dream                2975\n10 Adelie Penguin (Pygoscelis adeliae)       Dream                3000\n# ℹ 334 more rows\n\n\n\n\n\n\npenguins_by_species &lt;- penguins |&gt; group_by(Species)\n#### summarize the \"Body Mass (g)\" column for each group\n\n\npenguins_by_species |&gt; drop_na()|&gt; summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n# A tibble: 3 × 4\n  Species                                    mean    sd     n\n  &lt;chr&gt;                                     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Adelie Penguin (Pygoscelis adeliae)       3703.  460.   139\n2 Chinstrap penguin (Pygoscelis antarctica) 3730.  386.    67\n3 Gentoo penguin (Pygoscelis papua)         5091.  503.   118\n\n\n\n\n\n\npenguins_by_sex_and_species &lt;- penguins |&gt; group_by(Sex, Species)\n\n\n\n\n\npenguins_by_sex_and_species |&gt; summarize(mean = mean(`Body Mass (g)`), sd = sd(`Body Mass (g)`), n = n())\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 8 × 5\n# Groups:   Sex [3]\n  Sex    Species                                    mean    sd     n\n  &lt;fct&gt;  &lt;chr&gt;                                     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 FEMALE Adelie Penguin (Pygoscelis adeliae)       3369.  269.    73\n2 FEMALE Chinstrap penguin (Pygoscelis antarctica) 3527.  285.    34\n3 FEMALE Gentoo penguin (Pygoscelis papua)         4680.  282.    58\n4 MALE   Adelie Penguin (Pygoscelis adeliae)       4043.  347.    73\n5 MALE   Chinstrap penguin (Pygoscelis antarctica) 3939.  362.    34\n6 MALE   Gentoo penguin (Pygoscelis papua)         5485.  313.    61\n7 &lt;NA&gt;   Adelie Penguin (Pygoscelis adeliae)         NA    NA      6\n8 &lt;NA&gt;   Gentoo penguin (Pygoscelis papua)           NA    NA      5\n\n\n\n\n\n\npenguins_by_sex_and_species |&gt;\n    summarize(mean = mean(`Body Mass (g)`)) |&gt;\n    pivot_wider(names_from = Species, values_from = mean)\n\n`summarise()` has grouped output by 'Sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 3 × 4\n# Groups:   Sex [3]\n  Sex    Adelie Penguin (Pygosce…¹ Chinstrap penguin (P…² Gentoo penguin (Pygo…³\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 FEMALE                     3369.                  3527.                  4680.\n2 MALE                       4043.                  3939.                  5485.\n3 &lt;NA&gt;                         NA                     NA                     NA \n# ℹ abbreviated names: ¹​`Adelie Penguin (Pygoscelis adeliae)`,\n#   ²​`Chinstrap penguin (Pygoscelis antarctica)`,\n#   ³​`Gentoo penguin (Pygoscelis papua)`\n\n\n\n\n\n\npenguins |&gt;\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |&gt;\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n    filter(Species %in% c(\"Adelie Penguin (Pygoscelis adeliae)\", \"Gentoo penguin (Pygoscelis papua)\"), Sex == \"FEMALE\") |&gt;\n    ggplot(aes(x = `Body Mass (g)`)) +\n    geom_histogram(bins = 30) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\n\n\nOne can also work with excel files. You need the readxl library.\n\nlibrary(\"readxl\")\n\nAs an example, we use an excel spreadsheet violent crime data from the FBI."
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html",
    "title": "Essential Linear Algebra",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Arrow\n\n\ndef make_plot(xmin, ymin, xmax, ymax):\n    fig, ax = plt.subplots()\n    ax.set_xlim(xmin, xmax)\n    ax.set_ylim(ymin, ymax)\n    ax.set_xticks(np.arange(xmin, xmax, 1))\n    ax.set_yticks(np.arange(ymin, ymax, 1))\n    ax.set_aspect(\"equal\")\n    ax.grid(visible=True)\n    return fig, ax\n\n\ndef draw_arrow(x0, y0, x1, y1, axes, color=\"blue\", alpha=1):\n    axes.add_patch(Arrow(x0, y0, x1 - x0, y1 - y0, width=0.3, color=color, alpha=alpha))\n    return axes",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#r-and-python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#r-and-python",
    "title": "Essential Linear Algebra",
    "section": "R and Python",
    "text": "R and Python\nFor a look at linear algebra basics in R and Python, see:\n\nPython Linear Algebra\nR Linear Algebra",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#vectors-and-scalars",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#vectors-and-scalars",
    "title": "Essential Linear Algebra",
    "section": "Vectors and Scalars",
    "text": "Vectors and Scalars\n\\(\\mathbf{R}^{n}\\) is the set of vectors (ordered tuples) of real numbers of length \\(n\\). A scalar is a real number.\n\nVectors are added componentwise.\nA vector can be multiplied by a scalar.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#addition",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#addition",
    "title": "Essential Linear Algebra",
    "section": "Addition",
    "text": "Addition\n\nfig, ax = make_plot(0, 0, 12, 12)\nax.set_title(\"Vector Addition\")\nax = draw_arrow(0, 0, 3, 5, ax)\nax = draw_arrow(0, 0, 1, 4, ax)\nax = draw_arrow(1, 4, 4, 9, ax)\nax = draw_arrow(3, 5, 4, 9, ax)\nplt.show()",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#scalar-multiplication",
    "title": "Essential Linear Algebra",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\nfig, ax = make_plot(0, 0, 12, 12)\nax.set_title(\"Scalar Multiplication\")\nax = draw_arrow(0, 0, 3, 5, ax)\nax = draw_arrow(0, 0, 6, 10, ax, color=\"red\", alpha=0.5)",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#geometric-interpretation-in-2-and-3-dimensions",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#geometric-interpretation-in-2-and-3-dimensions",
    "title": "Essential Linear Algebra",
    "section": "Geometric Interpretation in 2 and 3 dimensions",
    "text": "Geometric Interpretation in 2 and 3 dimensions",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#feature-space",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#feature-space",
    "title": "Essential Linear Algebra",
    "section": "Feature Space",
    "text": "Feature Space\nEach ‘dimension’ in feature space corresponds to a ‘feature’ or measurement of the data. Here we are assuming for now that the features are continuous and measured by real numbers.\nLet’s choose some numerical features of the penguins dataset.\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\ndata = (\n    data[\n        [\n            \"Culmen Length (mm)\",\n            \"Culmen Depth (mm)\",\n            \"Flipper Length (mm)\",\n            \"Body Mass (g)\",\n        ]\n    ]\n    .dropna()\n    .values\n)\n\nEach penguin is represented by a vector in \\(\\mathbf{R}^{4}\\). So for example penguin number 34 is represented as follows.\n\ndata[34, :]\n\narray([  39.2,   21.1,  196. , 4150. ])\n\n\nThis abstraction of penguins into vectors is sometimes called “an embedding”.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#features",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#features",
    "title": "Essential Linear Algebra",
    "section": "Features",
    "text": "Features\nWe can also look at a single feature for all of the penguins. For example, ‘Culmen Length (mm)’ is a feature and there is a vector in \\(\\mathbf{R}^{342}\\) consisting of all of the Culmen Lengths for all of the penguins.\nIn the tidy convention, we summarize our data in an array or matrix where each row corresponds to a sample and each column to a feature. So our penguin data has \\(342\\) rows (corresponding to the 342 penguins with no missing data) and 4 columns corresponding to four features.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#image-embeddings",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#image-embeddings",
    "title": "Essential Linear Algebra",
    "section": "Image Embeddings",
    "text": "Image Embeddings\nEach sample in the MNIST database is a \\(28x28\\) gray scale image, represented by a \\(28\\times 28\\) array of integers between 0 and 255.\n\nwith open(\"data/train-images.idx3-ubyte\", \"rb\") as f:\n    f.read(16)\n    buf = f.read(28 * 28)\n    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n    data = data.reshape(1, 28, 28)\nfor x in range(28):\n    for y in range(28):\n        print(\"{:&gt;4}\".format(int(data[0, x, y])), end=\"\")\n    print(\"\\n\")\n\nimage = np.asarray(data[0].squeeze())\nplt.imshow(image)\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0\n\n   0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0\n\n   0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0\n\n   0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n\n\n\n\n\n\n\n\n\n\nHere we can view each image as a vector in a 784 dimensional (=28*28) space.\nA collection of 100 images would be represented by an array with 100 rows and 784 columns\nA 28x28 image in color has 28283 numbers to account for the RGB channels.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#one-hot-embedding",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#one-hot-embedding",
    "title": "Essential Linear Algebra",
    "section": "One Hot Embedding",
    "text": "One Hot Embedding\nNormally categorical variables don’t embed direcly into \\(\\mathbf{R}^{n}\\) but one can use “one-hot” embedding.\nSuppose our categorical vector has 4 levels: red, green, blue, orange.\nThe “one-hot” embedding uses four features, and each color corresponds to a vector with a one in the column corresponding to the color and zeros elsewhere.\n\n\n\nred\ngreen\nblue\norange\n\n\n\n\n1\n0\n0\n0\n\n\n0\n1\n0\n0\n\n\n0\n0\n1\n0\n\n\n0\n0\n0\n1\n\n\n\nSo to use one-hot encoding of our feature data, we’d add four columns to our data matrix.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#word-embeddings",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#word-embeddings",
    "title": "Essential Linear Algebra",
    "section": "Word embeddings",
    "text": "Word embeddings\nWord2vec is a technique developed by scientists at google that embeds a vocabulary into \\(\\mathbf{R}^{n}\\). Each of 3 million words has a 300 dimensional vector representing it.\nSee this google page.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#the-curse-of-dimensionality",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#the-curse-of-dimensionality",
    "title": "Essential Linear Algebra",
    "section": "The Curse of Dimensionality",
    "text": "The Curse of Dimensionality\nOur intuition misleads us when we think about high dimensional space. There is just vastly more “space” in high dimensional space then we expect.\nOne way to see this is to compare the unit sphere in \\(\\mathbf{R}^{n}\\) and the unit cube in \\(\\mathbf{R}^{n}\\).\nIn the plane, the unit cube has volume 4 and the unit circle has volume 3.14. So the unit circle fills up most of the cube. Given vectors with coordinates \\((x,y)\\) between \\(-1\\) and \\(1\\), about 75 percent are within distance one of the origin.\n\nrng = np.random.default_rng()\ndef hypercube(n,d):\n    data = rng.uniform(-1,1,size=(n,d))\n    r = np.linalg.norm(data,axis=1)\n    hist, edges = np.histogram(r,bins=20,density=True)\n    fig = plt.figure()\n    axes = fig.subplots()\n    axes.bar(x=edges[:-1], height=hist,align='edge',width=edges[1]-edges[0],edgecolor='white')\n    axes.set_title(\"Distance to zero for {} points\\n in the hypercube in {} dimensions\".format(n,d))\nhypercube(10000,2)\n\n\n\n\n\n\n\n\nIn 20 dimensions, the situation is quite different. The hypercube has volume 2^{20} (this volume grows exponentially with the dimension) while the sphere has volume \\[\n\\frac{\\pi^{10}}{10!}=.025\n\\]\nIf you compare the distribution you see that most of the points are very far from the origin; basically none are within the unit sphere.\n\nhypercube(10000,20)\n\n\n\n\n\n\n\n\nThis means that even huge numbers of points in relatively high dimensions are very sparsely distributed.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-combinations",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-combinations",
    "title": "Essential Linear Algebra",
    "section": "Linear combinations",
    "text": "Linear combinations\nIf \\(v_1,\\ldots, v_k\\) are vectors in \\(\\mathbf{R}^{n}\\) then a weighted sum of the \\(v_{i}\\) is called a linear combination.\n\\[\nw = \\sum b_{i}v_{i}\n\\]\nSuppose our data is the performance of students on 2 homeworks, 1 midterm, and one final, all scored on a 100 points scale, with each homework worth 10% of the total, the midterm worth 25% and the final worth 55%. If there are 20 students our data is a \\(20 x 4\\) array with each row having the grades of a single student and each column having all the scores for a particular assignment.\nLet \\(v_1, v_2, v_3, v_4\\) be the four columns. Then the final score is the linear combination \\[\ns=.1v_1+.1v_2+.25v_3+.55v_4\n\\]\nThe vector \\(s\\), the score, is a linear combination of the features.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-dependence-and-linear-independence",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-dependence-and-linear-independence",
    "title": "Essential Linear Algebra",
    "section": "Linear Dependence and Linear Independence",
    "text": "Linear Dependence and Linear Independence\nIn the example above, the final score is a linear combination of the features. We say that the final score is dependent on the features. More generally, a collection of vectors is linearly dependent if there are constants, not all zero, so that\n\\[\nb_1v_1+...+b_kv_k=0.\n\\]\nIf they’re dependent, it means one of them can be written in terms of the other.\nIf they aren’t dependent, they are independent. This means that the only way you can get \\[\nb_1v_1+...+b_kv_k=0\n\\] is if all the constants are zero.\nNone of the vectors can be written in terms of the others.\nMathematically, dependence is an exact relationship.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#linear-relations-in-python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#linear-relations-in-python",
    "title": "Essential Linear Algebra",
    "section": "Linear relations in python",
    "text": "Linear relations in python\n\nvectors = [np.random.uniform(size=8) for i in range(5)]  # 10 random vectors\nscalars = [np.random.normal() for i in range(5)]  # 10 random scalars\nprods = [scalars[i] * vectors[i] for i in range(5)]  # products\nresult = sum(prods)  # sum of products\nprint(result)\n\n[0.33587957 0.91692119 0.72692985 0.63306026 0.03864674 0.88773759\n 1.01912383 0.74088351]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#approximate-linear-dependence",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#approximate-linear-dependence",
    "title": "Essential Linear Algebra",
    "section": "Approximate linear dependence",
    "text": "Approximate linear dependence\nSometimes two features are “almost” linearly related.\nIn an old dataset about car models, with 398 types of cars and 9 features, two features are “miles per gallon” and “engine displacement”. If we look at mpg and displacement relative to their means by subtracting their averages values, we see that\nHere, miles per gallon (relative to its mean value) is roughly linearly dependent on displacement (relative to its mean). \\[\n\\mathrm{mpg}-\\overline{\\mathrm{mpg}} = -.0603(\\mathrm{disp}-\\overline{\\mathrm{disp}})\n\\]\nSo we don’t learn much new from ‘mpg’ that isn’t already in ‘displacement’.\n\nimport statsmodels.api as sm\n\nmpg = pd.read_csv(\"data/auto-mpg.csv\")\nx = mpg[\"displacement\"].values\nx = x - np.mean(x)\ny = mpg[\"mpg\"].values\ny = y - np.mean(y)\nx1 = sm.add_constant(x)\nmodel = sm.OLS(y, x1).fit()\nx0 = np.linspace(-100, 300, 10)\nx1 = sm.add_constant(x0)\npredictions = model.predict(x1)\nplt.scatter(x, y)\nplt.plot(x0, predictions, color=\"red\")\nplt.title(\"Miles per Gallon vs Engine Displacement\")\nplt.xlabel(\"Displacement\")\n\nText(0.5, 0, 'Displacement')\n\n\n\n\n\n\n\n\n\nLinear Regression (studied later) tries to capture this.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#span",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#span",
    "title": "Essential Linear Algebra",
    "section": "Span",
    "text": "Span\nThe span of a collection of vectors is the set of all linear combinations of those vectors.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#basis-and-dimension",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#basis-and-dimension",
    "title": "Essential Linear Algebra",
    "section": "Basis and dimension",
    "text": "Basis and dimension\nA basis is a linearly independent, spanning set. The number of elements in a basis is always the same; it is called the dimension of the vector space.\nThe dimension of \\(\\mathbf{R}^{n}\\) is \\(n\\) (the standard vectors are independent and span).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#distances-and-the-euclidean-norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#distances-and-the-euclidean-norm",
    "title": "Essential Linear Algebra",
    "section": "Distances and the euclidean norm",
    "text": "Distances and the euclidean norm\nThe norm of a vector \\(v=(a_1,\\ldots, a_n)\\) is \\[\n\\|v\\| = (\\sum a_{i}^2)^{1/2}\n\\]\nIt is the “length” of the vector.\nThe Euclidean distance between two points \\(v\\) and \\(w\\) is \\[\n\\|v-w\\|\n\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#mean-squared-error-in-vector-form",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#mean-squared-error-in-vector-form",
    "title": "Essential Linear Algebra",
    "section": "Mean Squared Error in vector form",
    "text": "Mean Squared Error in vector form\nRemember our example the “almost” dependence of mpg and displacement.\n\nmpg0 = mpg[\"mpg\"] - np.mean(mpg[\"mpg\"])\ndisp0 = mpg[\"displacement\"] - np.mean(mpg[\"displacement\"])\npredicted = -0.0603 * disp0\nplt.scatter(disp0, mpg0)\nplt.scatter(disp0, predicted)\nplt.title(\"MSE={:.2f}\".format(np.linalg.norm(mpg0 - predicted) / mpg0.shape[0]))\n\nText(0.5, 1.0, 'MSE=0.23')\n\n\n\n\n\n\n\n\n\nThe mean squared error is the squared distance between a true and predicted value, divided by the number of values.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#the-dot-product",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#the-dot-product",
    "title": "Essential Linear Algebra",
    "section": "The dot product",
    "text": "The dot product\nSuppose we have two vectors: \\[\\begin{aligned}\nv_1 & =[a_1,a_2,\\dots, a_n] \\\\\nv_2 &= [b_1,b_2,\\ldots, b_n]\n\\end{aligned}\n\\]\nThe “dot product” or “inner product” of these two vectors is: \\[\nv_1\\cdot v_2 = \\sum_{i=1}^{n} a_i b_i.\n\\]\nImportant: The dot product *converts two vectors into a scalar!",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#properties-of-the-dot-product",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#properties-of-the-dot-product",
    "title": "Essential Linear Algebra",
    "section": "Properties of the dot product",
    "text": "Properties of the dot product\n\n\\(v_1\\cdot v_1 = \\|v_1\\|^2\\)\n\\((av_1+bv_2)\\cdot v_3 = a(v_1\\cdot v_2) + b(v_2\\cdot v_2)\\)\n\\(v_1\\cdot v_2 = v_2 \\cdot v_1\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#angles-and-cauchy-schwartz",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#angles-and-cauchy-schwartz",
    "title": "Essential Linear Algebra",
    "section": "Angles and Cauchy-Schwartz",
    "text": "Angles and Cauchy-Schwartz\nThe law of cosines: \\[\\|v_1\\|^2+\\|v_2\\|^2 - 2\\|v_1\\|\\|v_2\\|\\cos(\\theta) =\\|v_1-v_2\\|^2\\]\nmeans that\n\\[\nv_1\\cdot v_2 = \\|v_1\\|\\|v_2\\|\\cos(\\theta)\n\\tag{1}\\]\nIn particular:\n\\[|v_1\\cdot v_2|\\le \\|v_1\\|\\|v_2\\|\n\\tag{2}\\]\nThis says \\[\n|\\sum_{i=1}^{n} a_{i}b_{i}|^2\\le (\\sum_{i=1}^{n} a_{i}^2)(\\sum_{i=1}^{n} b_{i}^2)\n\\]\nEquation 2 is called the “Cauchy-Schwartz inequality.”",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#python",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#python",
    "title": "Essential Linear Algebra",
    "section": "Python",
    "text": "Python\n\n\n\nListing 1: Dot product computation\n\n\n# python\nv = np.array([1,2,3,4,5])\nw = np.array([2,4,6,8,10])\nprint('Entry by entry product = {}'.format(v*w))\nprint('Dot product = {}'.format(np.dot(v,w)))\n\n\n\nNote: In R, the symbol for dot product is %*%.\nIn Listing 1 we show how to compute the dot product in python.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#orthogonality",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#orthogonality",
    "title": "Essential Linear Algebra",
    "section": "Orthogonality",
    "text": "Orthogonality\nIf \\(v_1\\cdot v_2=0\\) then either one of \\(v_1\\) or \\(v_2\\) is zero, or the angle between then is 90 degrees.\nIn this case we saw the vectors are orthogonal.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#unit-vectors-and-projection",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#unit-vectors-and-projection",
    "title": "Essential Linear Algebra",
    "section": "Unit vectors and projection",
    "text": "Unit vectors and projection\nA vector \\(u\\) is a unit vector if \\(u\\cdot u=1\\).\nThe quantity \\(v\\cdot u\\) measures the projection of \\(v\\) into the direction given by \\(u\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#variance-correlation-and-cosine-similarity",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#variance-correlation-and-cosine-similarity",
    "title": "Essential Linear Algebra",
    "section": "Variance, Correlation and cosine similarity",
    "text": "Variance, Correlation and cosine similarity\nIf \\(v\\) is a feature vector, let \\(\\overline{v}=\\frac{1}{n}\\sum_{i=1}^{n} v_{i}\\).\nNotice that \\(\\overline{v}=\\frac{v\\cdot E}{n}\\) where \\(E\\) is the vector with \\(1\\) in each entry.\n\\[\n\\|(v-\\overline{v}E)\\|=\\sigma^{2}\n\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#covariance",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#covariance",
    "title": "Essential Linear Algebra",
    "section": "Covariance",
    "text": "Covariance\nIf \\(v\\) and \\(w\\) are two vectors, their covariance is \\[\n\\sigma_{vw} = \\frac{(v-\\overline{v}E)\\cdot (w-\\overline{w}E)}{n}\n\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#correlation",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#correlation",
    "title": "Essential Linear Algebra",
    "section": "Correlation",
    "text": "Correlation\nThe correlation coefficient of \\(v\\) and \\(w\\) is \\[\nr_{vw} = \\frac{\\sigma_{vw}}{\\sigma_{v}\\sigma_{w}}=\\frac{|(v-\\overline{v}E)\\cdot(w-\\overline{w}E)|}{\\|v-\\overline{v}E)\\|\\|w-\\overline{w}E\\|}=\\cos\\theta\n\\]\nIt measures the cosine of the angle between \\(v-\\overline{v}E\\) and \\(w-\\overline{w}E\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#cosine-similarity",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#cosine-similarity",
    "title": "Essential Linear Algebra",
    "section": "Cosine similarity",
    "text": "Cosine similarity\nIn general,\n\\[\n\\cos(\\theta) = \\frac{v\\cdot w}{\\|v\\|\\|w\\|}\n\\] measures the angle between two feature vectors and is a measure of “similarity” between \\(0\\) and \\(1\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#hyperplanes",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#hyperplanes",
    "title": "Essential Linear Algebra",
    "section": "Hyperplanes",
    "text": "Hyperplanes\nA (linear) hyperplane is a subspace of dimension \\(n-1\\) in a vector space of dimension \\(n\\). It is given by an equation of the form\n\\[\n\\sum a_{i}x_{i}=0.\n\\]\nGeometrically this can be written \\(v\\cdot x=0\\) where \\(v=[a_1,\\ldots, a_n]\\) and \\(x=[x_1,\\ldots, x_n]\\). The vector \\(v\\) is called the normal vector to the hyperplane.\nAn (affine) hyperplane is given by an equation of the form \\[\nv\\cdot x = b\n\\] for some constant \\(b\\)\n\nx = np.linspace(-5, 5, 10)\ny = 2 / 3 * x\nplt.plot(x, y)\nplt.grid(True)\nplt.gca().set_aspect(\"equal\")\n\nplt.plot([0, -2], [0, 3])\nplt.plot([-2, -2], [3, 2])\nplt.plot([-2, -1], [3, 2.6])\nplt.title(\"Hyperplane 2x-3y=0 with normal vector [-2,3]\")\n\nText(0.5, 1.0, 'Hyperplane 2x-3y=0 with normal vector [-2,3]')",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#affine-hyperplanes",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#affine-hyperplanes",
    "title": "Essential Linear Algebra",
    "section": "Affine hyperplanes",
    "text": "Affine hyperplanes\nFor fixed \\(v\\) and varying \\(b\\), the hyperplanes \\(v\\cdot x=b\\) form a parallel family.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#distance-from-a-point-to-a-hyperplane",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#distance-from-a-point-to-a-hyperplane",
    "title": "Essential Linear Algebra",
    "section": "Distance from a point to a hyperplane",
    "text": "Distance from a point to a hyperplane\nThe distance from a point \\(w\\) to the hyperplane \\(v\\cdot x = b\\) is \\[\nD = \\frac{w\\cdot v-b}{\\|v\\|}.\n\\]\nThis is the projection of the line from \\(w\\) to a point \\(x\\) on the hyperplane against the unit normal \\(\\frac{v}{\\|v\\|}\\).\n\\[\n(w-x)\\cdot\\frac{v}{\\|v\\|} =\\frac{(w\\cdot v -x\\cdot v)}{\\|v\\|} = \\frac{(w\\cdot v - b)}{\\|v\\|}\n\\]\n\nx = np.linspace(-4, 4, 10)\ny = 2 / 3 * x\nplt.plot(x, y)\nplt.grid(True)\nplt.gca().set_aspect(\"equal\")\nplt.title(\"Dist. from point to hyperplane\")\nplt.plot([0, -2 / np.sqrt(13)], [0, 3 / np.sqrt(13)], color=\"red\", linewidth=3)\nplt.plot([0, -2], [0, 3])\nplt.plot([-3, -2], [-2, 3])\nplt.text(-2.4, 3, r\"w\")\nplt.text(-3, -2.3, r\"x\")\nplt.text(-3.6, 0, r\"$\\|w-x\\|$\")\nplt.text(-1.9, 2.2, r\"$\\theta$\")\nplt.text(-0.5, 1.4, r\"$\\|w-x\\|\\cos(\\theta)$\")\n\nText(-0.5, 1.4, '$\\\\|w-x\\\\|\\\\cos(\\\\theta)$')",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrices",
    "title": "Essential Linear Algebra",
    "section": "Matrices",
    "text": "Matrices\nAn \\(n\\times m\\) matrix is an array of real numbers with \\(n\\) rows, \\(m\\) columns, and a total of \\(nm\\) entries.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector",
    "title": "Essential Linear Algebra",
    "section": "Matrix times Vector",
    "text": "Matrix times Vector\nIf \\(M\\) is an \\(n\\times m\\) matrix and \\(v\\) is an \\(m\\times 1\\) vector (a column vector) then \\(Mv\\) is the \\(n\\times 1\\) column vector whose entries are \\[\nM[i,:]\\cdot v\n\\] where \\(i\\) runs from 1 to \\(n\\). Here \\(M[i,:]\\) is the \\(i^{th}\\) row of \\(M\\).\nIf \\(v\\) is a \\(1\\times n\\) row vector then \\(vM\\) is the \\(1\\times m\\) row vector whose entries are \\(v\\cdot M[:,i]\\) as \\(i\\) runs from 1 to \\(m\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector-is-linear",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-vector-is-linear",
    "title": "Essential Linear Algebra",
    "section": "Matrix times vector is linear",
    "text": "Matrix times vector is linear\n\\[M(v+w) = Mv+Mw\\] \\[M(aw) = aMw\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-standard-vector-gives-rowcolumn",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-standard-vector-gives-rowcolumn",
    "title": "Essential Linear Algebra",
    "section": "Matrix times standard vector gives row/column",
    "text": "Matrix times standard vector gives row/column\nIf \\(v\\) is a column vector with a a \\(1\\) in position \\(i\\) and zeros elsewhere, then \\(Mv\\) is the \\(i^{th}\\) column of \\(M\\).\nIf \\(v\\) is a row vector with a \\(1\\) in position \\(i\\) and zeros elsewhere, then \\(vM\\) is the \\(i^{th}\\) row of \\(M\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#mvvm-gives-linear-combination-of-columnsrows",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#mvvm-gives-linear-combination-of-columnsrows",
    "title": "Essential Linear Algebra",
    "section": "\\(Mv\\)/\\(vM\\) gives linear combination of columns/rows",
    "text": "\\(Mv\\)/\\(vM\\) gives linear combination of columns/rows\n\\(Mv\\) is a linear combination of the columns of \\(M\\) weighted by the entries of \\(v\\).\n\\(vM\\) is a linear combination of the rows of \\(M\\) weighted by the entries of \\(v\\).",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#matrix-times-matrix",
    "title": "Essential Linear Algebra",
    "section": "Matrix times matrix",
    "text": "Matrix times matrix\nAn \\(n\\times m\\) matrix times an \\(m\\times k\\) matrix yields an \\(n\\times k\\) matrix.\nYou can view \\(MN\\) as \\(Mv\\) where \\(v\\) runs through the columns of \\(N\\). Each column has \\(n\\) rows.\n\\[\nMN=\\left[\n    \\begin{matrix}\n     M[0,:]N & M[1,:]N &\\cdots&M[m,:]N\\\\\n    \\end{matrix}\n    \\right]\n\\]\nOR you can view \\(MN\\) as \\(wN\\) where \\(w\\) runs through the rows of \\(M\\).\n\\[\nMN = \\left[\\begin{matrix} MN[:,0] \\\\ MN[:,1] \\\\\\vdots\\\\MN[:,k]\\end{matrix}\\right]\n\\]\nOR\nyou can view \\(MN\\) where the \\(i,j\\) entry of \\(MN\\) is the dot product of the \\(i^{th}\\) row of \\(M\\) with the \\(j^{th}\\) column of \\(N\\) (each of which has \\(m\\) entries).\n\\[(MN)_{ij} = M[i,:]\\cdot N[;,j]\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#python-1",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#python-1",
    "title": "Essential Linear Algebra",
    "section": "Python",
    "text": "Python\nThe ‘@’ sign gives matrix multiplication in python. In R, it’s %*%.\n\nM = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\nv = np.array([[-1], [0], [1]])\nprint(M)\nprint(v)\nprint(M @ v)\nprint(\"Compare -M[:,0]+M[:,2] with M@v\\n both are {}\".format(-M[:, 0] + M[:, 2]))\n\n[[1 2 3]\n [2 3 4]\n [3 4 5]]\n[[-1]\n [ 0]\n [ 1]]\n[[2]\n [2]\n [2]]\nCompare -M[:,0]+M[:,2] with M@v\n both are [2 2 2]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#where-does-matrix-multiplication-come-from",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#where-does-matrix-multiplication-come-from",
    "title": "Essential Linear Algebra",
    "section": "Where does matrix multiplication come from?",
    "text": "Where does matrix multiplication come from?\nIf \\(v\\) is in \\(\\mathbf{R}^{m}\\) as a column vector, and \\(M\\) is an \\(n\\times m\\) matrix, then \\(Mv\\in\\mathbf{R}^{n}\\). So the function \\(v\\to Mv\\) is a function from \\(\\mathbf{R}^{m}\\to \\mathbf{R}^{m}\\).\nNow if \\(N\\) is a \\(k\\times n\\) matrix, then \\(NMv\\) is in \\(\\mathbf{R}^{k}\\).\nIf we want \\(N(Mv)=(NM)v\\) to be true then this forces the definition of matrix multiplication.\nThe Matrix Product gives composition of functions",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#transpose-of-a-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#transpose-of-a-matrix",
    "title": "Essential Linear Algebra",
    "section": "Transpose of a matrix",
    "text": "Transpose of a matrix\nThe transpose \\(M^{T}\\) of a matrix is the matrix obtained from \\(M\\) by switching rows and columns.\nThe transpose switches the order of a product.\n\\[(MN)^{T}=N^{T}M^{T}\\]",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#covariance-matrix",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#covariance-matrix",
    "title": "Essential Linear Algebra",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\nRemember that if \\(v\\) and \\(w\\) are feature vectors, then \\((v-\\overline{v})\\cdot (w-\\overline{w})\\) is the covariance of \\(v\\) and \\(w\\).\nSuppose \\(v_1,\\ldots, v_n\\) are features forming a data matrix \\(X\\).\nLet \\(X_{0}\\) be the matrix whose columns are \\(v_{i}-\\overline{v_{i}}\\).\nThen \\(\\frac{1}{N}X_{0}^{T}X_{0}\\) is \\(n\\times n\\) and called the covariance matrix.\nIf \\(Y_{0}\\) is obtained from \\(X_{0}\\) by dividing each column by its norm, then \\(Y_{0}^{T}Y_{0}\\) is the correlation matrix – ones on the diagonal, correlation coefficients off diagonal.\n\ndata = pd.read_csv(\"data/penguins-raw.csv\")\ndata = (\n    data[\n        [\n            \"Culmen Length (mm)\",\n            \"Culmen Depth (mm)\",\n            \"Flipper Length (mm)\",\n            \"Body Mass (g)\",\n        ]\n    ]\n    .dropna()\n    .values\n)\n# axis=0 means take the average of the columns (summarize over rows)\ndata.mean(axis=0)\n\n# \"center\" each column; scale column 3\ndata0 = data - data.mean(axis=0)\nprint(np.linalg.norm(data0, axis=0))\ndata0 = data0 / np.linalg.norm(data0, axis=0)\nD = data0.transpose() @ data0\nprint(D)\nplt.imshow(D, cmap=\"hot\", interpolation=\"nearest\")\nplt.title(\"covariance matrix heatmap\")\n\n[  100.81768459    36.46689639   259.66621062 14809.0410685 ]\n[[ 1.         -0.23505287  0.65618134  0.59510982]\n [-0.23505287  1.         -0.58385122 -0.47191562]\n [ 0.65618134 -0.58385122  1.          0.87120177]\n [ 0.59510982 -0.47191562  0.87120177  1.        ]]\n\n\nText(0.5, 1.0, 'covariance matrix heatmap')\n\n\n\n\n\n\n\n\n\n\nplt.scatter(x=data0[:, 2], y=data0[:, 3])",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra.html#rank-and-invertibility",
    "href": "chapters/06-LinearAlgebra/linear_algebra.html#rank-and-invertibility",
    "title": "Essential Linear Algebra",
    "section": "Rank and invertibility",
    "text": "Rank and invertibility\nThe column rank of a matrix is the dimension of the space spanned by its columns; this is the number of linearly independent columns.\nThe row rank is the number of linearly independent rows.\nTheorem: These two numbers are equal.",
    "crumbs": [
      "Contents",
      "Essential Linear Algebra"
    ]
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#creating-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#creating-matrices",
    "title": "Fundamentals of Machine Learning",
    "section": "Creating matrices",
    "text": "Creating matrices\n\nm &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 1)\nn &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 2)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    1    2    3    4    5    6    7    8\n\nprint(n)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#reshaping-and-broadcasting",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#reshaping-and-broadcasting",
    "title": "Fundamentals of Machine Learning",
    "section": "Reshaping and broadcasting",
    "text": "Reshaping and broadcasting\n\nm &lt;- matrix(1:8)\nprint(m)\n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3\n[4,]    4\n[5,]    5\n[6,]    6\n[7,]    7\n[8,]    8\n\nm &lt;- matrix(m, nrow = 2)\nprint(m)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\nm &lt;- matrix(m, ncol = 2)\nprint(m)\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\n# note that R repeats things if they fit\nm &lt;- matrix(c(1, 2), ncol = 10)\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    2    1    2    1    2    1    2    1     2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#special-matrices",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#special-matrices",
    "title": "Fundamentals of Machine Learning",
    "section": "Special matrices",
    "text": "Special matrices\n\none &lt;- matrix(1, nrow = 2, ncol = 3)\nprint(one)\n\n     [,1] [,2] [,3]\n[1,]    1    1    1\n[2,]    1    1    1\n\nzero &lt;- matrix(0, nrow = 2, ncol = 3)\nprint(zero)\n\n     [,1] [,2] [,3]\n[1,]    0    0    0\n[2,]    0    0    0\n\nd &lt;- diag(c(1, 2, 3, 4, 5))\nprint(d)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    0    0    0    0\n[2,]    0    2    0    0    0\n[3,]    0    0    3    0    0\n[4,]    0    0    0    4    0\n[5,]    0    0    0    0    5"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#addition-and-scalar-multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#addition-and-scalar-multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Addition and scalar multiplication",
    "text": "Addition and scalar multiplication\n\nx &lt;- rnorm(4)\ny &lt;- rnorm(4)\nprint(x + y)\n\n[1] -0.2603366  1.1393094 -0.3571646 -1.0366498\n\n# note that in R this makes sense\nu &lt;- rnorm(2)\nprint(x + u)\n\n[1] -1.2355950  1.3143255 -0.3463806  0.5944031"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#element-by-element",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#element-by-element",
    "title": "Fundamentals of Machine Learning",
    "section": "Element by element",
    "text": "Element by element\n\nu = matrix(rnorm(20), ncol = 4)\nv = matrix(rnorm(20), ncol = 4)\nprint(u + v)\n\n           [,1]       [,2]        [,3]       [,4]\n[1,]  0.7593375  0.2767851 -4.11133153  1.5774825\n[2,] -2.0340433  1.3869568  0.11218511 -3.0959786\n[3,]  1.4407247  0.8120174 -2.14403643 -1.8769940\n[4,]  1.4904696  1.2255598  0.59088532  0.8808149\n[5,] -1.4534834 -0.6228316  0.04752087  0.1657468\n\nprint(u)\n\n           [,1]        [,2]       [,3]       [,4]\n[1,]  0.9734602  0.28614909 -1.2952055  0.6047754\n[2,] -0.7790485  0.96105130  0.4726260 -2.1998513\n[3,]  1.8351617  0.07373893 -0.7289349  0.4606372\n[4,]  1.0649698  0.79897404  0.1151499  1.0380597\n[5,] -0.8771409 -0.02859159 -0.3874812  0.4164523\n\nprint(1 / u)\n\n           [,1]       [,2]       [,3]       [,4]\n[1,]  1.0272634   3.494682 -0.7720783  1.6535064\n[2,] -1.2836172   1.040527  2.1158381 -0.4545762\n[3,]  0.5449111  13.561357 -1.3718645  2.1709061\n[4,]  0.9389938   1.251605  8.6843321  0.9633357\n[5,] -1.1400677 -34.975322 -2.5807703  2.4012352\n\nprint(log(abs(u)))\n\n            [,1]        [,2]       [,3]       [,4]\n[1,] -0.02689834 -1.25124231  0.2586693 -0.5028981\n[2,] -0.24968200 -0.03972748 -0.7494510  0.7883898\n[3,]  0.60713260 -2.60722433 -0.3161708 -0.7751446\n[4,]  0.06294645 -0.22442682 -2.1615205  0.0373533\n[5,] -0.13108764 -3.55464272 -0.9480879 -0.8759833"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#slices-using-apply",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#slices-using-apply",
    "title": "Fundamentals of Machine Learning",
    "section": "Slices using apply",
    "text": "Slices using apply\n\nu = matrix(rnorm(20), ncol = 4)\nprint(colMeans(u))\n\n[1]  0.73927324 -0.04228004  1.07442276  0.44702910\n\nprint(rowMeans(u))\n\n[1]  1.0156446 -0.2035237  0.6436251  0.2622229  1.0550874\n\napply(u, 1, function(x) mean(x))\n\n[1]  1.0156446 -0.2035237  0.6436251  0.2622229  1.0550874\n\napply(u, 2, function(x) var(x))\n\n[1] 1.0622565 0.5313461 1.7671191 1.1348808"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#multiplication",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#multiplication",
    "title": "Fundamentals of Machine Learning",
    "section": "Multiplication",
    "text": "Multiplication\n\nx &lt;- matrix(rnorm(12), nrow = 3)\ny &lt;- matrix(rnorm(15), ncol = 3)\nprint(y %*% x)\n\n           [,1]         [,2]       [,3]       [,4]\n[1,] -0.3249907  3.256489468  3.7350551 -1.9713010\n[2,]  1.2387300 -0.003915827  1.0615159 -0.9274304\n[3,]  1.0508988  0.768977193  1.6798658 -1.3982150\n[4,]  1.5320991 -0.590454228  0.5868742 -0.7507172\n[5,]  0.2352962 -3.294646257 -3.5872313  2.2000429"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#transpose",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#transpose",
    "title": "Fundamentals of Machine Learning",
    "section": "Transpose",
    "text": "Transpose\n\nx = matrix(rnorm(12), nrow = 3)\nprint(t(x))\n\n           [,1]        [,2]       [,3]\n[1,]  0.9187313 -0.76582013 -1.7076644\n[2,] -2.1058542  3.67844225 -0.1388855\n[3,]  0.2515910 -0.12589308 -0.6746914\n[4,] -2.0873916 -0.03932317 -1.2686636\n\nprint(nrow(t(x)))\n\n[1] 4"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#norm",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#norm",
    "title": "Fundamentals of Machine Learning",
    "section": "Norm",
    "text": "Norm\n\nx = matrix(c(1, 2, 3, 4), nrow = 2)\nnorm(x, type = \"2\")\n\n[1] 5.464986\n\napply(x, 2, function(x) norm(x, type = \"2\"))\n\n[1] 2.236068 5.000000\n\napply(x, 1, function(x) norm(x, type = \"2\"))\n\n[1] 3.162278 4.472136"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#rank",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#rank",
    "title": "Fundamentals of Machine Learning",
    "section": "Rank",
    "text": "Rank\n\nlibrary(Matrix)\nx = matrix(c(1,2,3,4),nrow=2)\nz=rankMatrix(x)\nz[[1]]\n\n[1] 2"
  },
  {
    "objectID": "chapters/06-LinearAlgebra/linear_algebra_r.html#dataframes-and-arrays",
    "href": "chapters/06-LinearAlgebra/linear_algebra_r.html#dataframes-and-arrays",
    "title": "Fundamentals of Machine Learning",
    "section": "Dataframes and arrays",
    "text": "Dataframes and arrays\nUse the “[[]]” or as.vector to convert tibbles to vectors.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata = read_csv(\"data/penguins-raw.csv\")\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmass &lt;- data |&gt; select(\"Body Mass (g)\")\nprint(mass)\n\n# A tibble: 344 × 1\n   `Body Mass (g)`\n             &lt;dbl&gt;\n 1            3750\n 2            3800\n 3            3250\n 4              NA\n 5            3450\n 6            3650\n 7            3625\n 8            4675\n 9            3475\n10            4250\n# ℹ 334 more rows\n\nprint(as.vector(mass))\n\n$`Body Mass (g)`\n  [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400\n [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950\n [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000\n [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750\n [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700\n [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600\n [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925\n[106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325\n[121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425\n[136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750\n[151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650\n[166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650\n[181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300\n[196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000\n[211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100\n[226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300\n[241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975\n[256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000\n[271] 4925   NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150\n[286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800\n[301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700\n[316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050\n[331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775\n\n\nprint(data[“Body Mass (g)”]) print(data[[‘Body Mass (g)’]])"
  },
  {
    "objectID": "chapters/08-Summarizing/experiments.html",
    "href": "chapters/08-Summarizing/experiments.html",
    "title": "Pandas Grouping and Summarizing",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nabnb = pd.read_csv(\"data/AB_NYC_2019.csv\")"
  },
  {
    "objectID": "chapters/08-Summarizing/experiments.html#exercise",
    "href": "chapters/08-Summarizing/experiments.html#exercise",
    "title": "Pandas Grouping and Summarizing",
    "section": "Exercise",
    "text": "Exercise\nAre there missing values? If so, where?\nSuppose you want to study the price differential by neighborhood. To start, make a pivot table showing average price by neighborhood and room type.\nDo these exercises in R as well."
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html",
    "href": "chapters/08-Summarizing/grouping_pandas.html",
    "title": "Grouping and Summarizing in Pandas",
    "section": "",
    "text": "dictionaries\nlambda functions",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in Pandas"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#two-python-techniques",
    "href": "chapters/08-Summarizing/grouping_pandas.html#two-python-techniques",
    "title": "Grouping and Summarizing in Pandas",
    "section": "",
    "text": "dictionaries\nlambda functions",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in Pandas"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#refactoring",
    "href": "chapters/08-Summarizing/grouping_pandas.html#refactoring",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Refactoring",
    "text": "Refactoring\nSee this python script file for an example of how to pull out code into a python function that standardizes your data preparation. To use this, you can use the %load command in a jupyter notebook. The command %load filename loads the content of the file into an executable cell. You need to execute that cell.\nIf you modify the script, you need to reload it.",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in Pandas"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#grouping-and-summarizing",
    "href": "chapters/08-Summarizing/grouping_pandas.html#grouping-and-summarizing",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\n\nimport pandas as pd\nimport  numpy as np\n\nOur first pass will be with our old friends the penguins.\n\npenguins = pd.read_csv(\"data/penguins-raw.csv\")",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in Pandas"
    ]
  },
  {
    "objectID": "chapters/08-Summarizing/grouping_pandas.html#some-basic-data-cleaning",
    "href": "chapters/08-Summarizing/grouping_pandas.html#some-basic-data-cleaning",
    "title": "Grouping and Summarizing in Pandas",
    "section": "Some basic data cleaning",
    "text": "Some basic data cleaning\n\nData types\n\n\npenguins.dtypes\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\nComments                object\ndtype: object\n\n\n\nFocus on Species, Island, Sex, Culmen Length/Depth, Flipper Length, Body Mass.\n\n\nfocus = ['Species','Island','Sex','Culmen Length (mm)','Culmen Depth (mm)','Flipper Length (mm)', 'Body Mass (g)']\nsimplified = penguins[focus]\n\n\nClean up column names\n\n\nedited_columns = ['species','island','sex','culmen_length', 'culmen_depth','flipper_length','body_mass']\nsimplified.columns = edited_columns\n\n\nSimplify factor names. (Note use of dictionary)\n\n\nspecies = simplified['species'].unique()\nsimple_species_dict={x:x.split(' ')[0].lower() for x in species}\nsimplified['species'].map(simple_species_dict)\n\n0         adelie\n1         adelie\n2         adelie\n3         adelie\n4         adelie\n         ...    \n339    chinstrap\n340    chinstrap\n341    chinstrap\n342    chinstrap\n343    chinstrap\nName: species, Length: 344, dtype: object\n\n\n\nRemaking a column (watch out!)\n\n\n#simplified['species'] = simplified['species'].map(simple_species_dict)\n\nOld option: use .loc.\n\n#simplified.loc[:,'species'] = simplified['species'].map(simple_species_dict)\n\nNewer option: use .assign(). Notice that .assign() returns a dataframe.\n\nsimplified = simplified.assign(species = lambda x: x['species'].map(simple_species_dict))\n\nFix some other factor variables:\n\nsimplified  = simplified.assign(island = lambda x: x.island.str.lower())\nsimplified = simplified.assign(sex = lambda x: x['sex'].str.lower())\n\n\nStandardize the variables - column by column\n\n\n#simplified = simplified.assign(culmen_length_std = lambda x: (x.culmen_length-x.culmen_length.mean())/x.culmen_length.std())\n\nor make a standardization function. (note use of **)\n\ndef standardize(x):\n    return (x-x.mean())/x.std()\nsimplified = simplified.assign(\n    **{i+'_std':(lambda x: standardize(x[i])) for i in simplified.columns[3:]}\n)\n\n\nMissing Values\n\n\nsimplified.isna().sum()\nsimplified = simplified.dropna(axis=0)\n\n\nGrouping\n\nGrouping combines with aggregation.\n\nnumerical_variables = ['culmen_length','culmen_depth','flipper_length','body_mass']\nby_sex_mean = simplified[['sex']+numerical_variables].groupby('sex').mean()\n\nAlternatively one can use .agg\n\nnumerical_variables = ['culmen_length','culmen_depth','flipper_length','body_mass']\nby_sex = simplified[['sex']+numerical_variables].groupby('sex').agg('mean')\n\nAnd then get multiple aggregations.\n\nby_sex = simplified[['sex']+numerical_variables].groupby('sex').agg(['count','mean','std'])\n\nTo access individual elements, use tuples as names.\n\nby_sex.loc[:,('culmen_depth','mean')]\n\nsex\nfemale    16.425455\nmale      17.891071\nName: (culmen_depth, mean), dtype: float64\n\n\nOne can also group on multiple factors.\n\nby_sex_and_species = (\n    simplified[[\"sex\", \"species\"] + numerical_variables]\n    .groupby([\"sex\", \"species\"])\n    .mean()\n)\nfemales_by_species = by_sex_and_species.loc[(\"female\",)]\nmales_by_species = by_sex_and_species.loc[(\"male\",)]\n\nYou can skip levels in the hierarchy using slice(None):\n\nby_sex_and_species.loc[(slice('female'),slice('adelie','chinstrap')),:]\n\n\n\n\n\n\n\n\n\nculmen_length\nculmen_depth\nflipper_length\nbody_mass\n\n\nsex\nspecies\n\n\n\n\n\n\n\n\nfemale\nadelie\n37.257534\n17.621918\n187.794521\n3368.835616\n\n\nchinstrap\n46.573529\n17.588235\n191.735294\n3527.205882\n\n\n\n\n\n\n\n\nPivot tables\n\n\nexpanded = by_sex_and_species.reset_index()\nexpanded.pivot(index='sex',columns='species',values='culmen_length')\n\n\n\n\n\n\n\nspecies\nadelie\nchinstrap\ngentoo\n\n\nsex\n\n\n\n\n\n\n\nfemale\n37.257534\n46.573529\n45.563793\n\n\nmale\n40.390411\n51.094118\n49.473770\n\n\n\n\n\n\n\n\npd.pivot_table(simplified,values='culmen_length',index='sex',columns='species',aggfunc='mean')\n\n\n\n\n\n\n\nspecies\nadelie\nchinstrap\ngentoo\n\n\nsex\n\n\n\n\n\n\n\nfemale\n37.257534\n46.573529\n45.563793\n\n\nmale\n40.390411\n51.094118\n49.473770\n\n\n\n\n\n\n\n\nMaking a function\n\n\ndef ptable(value, aggfunc=\"mean\"):\n    return pd.pivot_table(\n        simplified, values=value, index=\"sex\", columns=\"species\", aggfunc=aggfunc\n    )\n\n\nptable(\"body_mass\", \"std\")\n\n\n\n\n\n\n\nspecies\nadelie\nchinstrap\ngentoo\n\n\nsex\n\n\n\n\n\n\n\nfemale\n269.380102\n285.333912\n281.578294\n\n\nmale\n346.811553\n362.137550\n313.158596",
    "crumbs": [
      "Contents",
      "Grouping and Summarizing in Pandas"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/Rfiles.html",
    "href": "chapters/09-Regexps/Rfiles.html",
    "title": "Reading from and Writing to Files in R",
    "section": "",
    "text": "The R/tidyverse library readr is the main tool for reading various types of data files.\n\nlibrary(readr)\n\n\nfile &lt;- read_file(\"data/gettysburg.txt\")\n\n\nline &lt;- read_lines(\"data/gettysburg.txt\", n_max = 1)\n\n\nlines &lt;- read_lines(\"data/gettysburg.txt\")\n\n\ntext &lt;- c(\"Now is the time\", \"for us to rise up\", \"against our robot overlords\")\nwrite_lines(text, \"data/robots.txt\", sep = \"-\")\n\n\n# write_file overwrites.  Use the append flag to append\nwrite_file(paste0(text, collapse = \" \")[1], \"data/robots.txt\", append = TRUE)\n\n\nFile operations\nThe fs library allows you to do file manipulations.\n\nlibrary(fs)\n# file_create\n# file_move\n# file_copy\n# file_ls to list directory\n# file_exists\n# file_show",
    "crumbs": [
      "Contents",
      "Reading from and Writing to Files in R"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html",
    "href": "chapters/09-Regexps/regexpsPython.html",
    "title": "Python regexps",
    "section": "",
    "text": "# Regular Expressions\nimport re\nimport pandas as pd\ntext = \"\"\"\nLong ago, I travelled to the far west, seeking my fortune. I found\nfrosty mountains, arid deserts, lush oases, and a huge ocean.\nAt times, I was gripped by despair, and at other times filled with Joy.\n\n- Anonymous, 1865\n\"\"\"\nwith open(\"data/filenames.txt\") as f:\n    filenames = f.readlines()\nprint(filenames[0])\n\nHW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-28_Homework2-R.qmd",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#guide-works-in-both-python-and-r",
    "href": "chapters/09-Regexps/regexpsPython.html#guide-works-in-both-python-and-r",
    "title": "Python regexps",
    "section": "Guide (works in both python and R)",
    "text": "Guide (works in both python and R)\n\nLetters, Numbers match themselves\n‘.’ matches one of anything\n‘+’ means one or more of the preceeding\n’*’ means 0 or more of the preceding\n‘?’ matches 0 or 1 occurrences of the previous pattern.\n[] groups things ([A-Z]+ matches a sequence of one or more capital letters); [^...] matches anything not in the range.\n‘\\w’ matches “word” characters (`[a-zA-Z0-9_]’)\n‘\\W’ matches non-word characters\n‘\\b’ matches boundaries (end or start of string)\n‘{5}’’ matches 5 times\n‘{3,5}’ matches 3, 4 or 5 occurrences.\n‘{3,}’ matches 3 or more occurrences\n‘\\s’ matches whitespace\n‘\\S’ matches non-whitespace\n‘^….’ matches at the start of a line\n‘…$’ matches at the end of a line\n‘(a|b)’ matches a or b.\nUse backslash to escape.",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#key-functions",
    "href": "chapters/09-Regexps/regexpsPython.html#key-functions",
    "title": "Python regexps",
    "section": "Key functions",
    "text": "Key functions\n\nmatch finds matches at the start of the string; returns None if it doesn’t find one, otherwise returns match object.\nsearch finds matches; returns None if it doesn’t find one, otherwise returns first match object\nfindall returns a list of all matches (not match objects)\nfinditer iterates over matches",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#match-objects",
    "href": "chapters/09-Regexps/regexpsPython.html#match-objects",
    "title": "Python regexps",
    "section": "Match objects",
    "text": "Match objects\n\nif m is a match object, then\n\nm[0] is the match\nm[2], m[3] and so on are the subgroup matches\nm.span(n) is (start, stop) for match n.\nm.start(n) and m.end(n) are the start and end of match n.\nm.string is the string being matched against",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#looking-for-explicit-strings",
    "href": "chapters/09-Regexps/regexpsPython.html#looking-for-explicit-strings",
    "title": "Python regexps",
    "section": "Looking for explicit strings",
    "text": "Looking for explicit strings\n\nif re.search(r\"travel\", text):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n\nif re.match(r\"travel\", text):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n\nYes\nNo",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#some-fancier-examples",
    "href": "chapters/09-Regexps/regexpsPython.html#some-fancier-examples",
    "title": "Python regexps",
    "section": "Some fancier examples",
    "text": "Some fancier examples\n\n# All the words\nall_words = re.findall(r\"\\b[a-zA-Z]+\\b\", text)\nall_words[0:5]\n\n['Long', 'ago', 'I', 'travelled', 'to']\n\n\n\n# words (allowing numbers and underline) but lower case\nre.findall(r\"\\b\\w+\\b\", text.lower())[0:5]\n\n['long', 'ago', 'i', 'travelled', 'to']\n\n\n\n# numbers\nre.findall(r\"\\b\\d+\\b\", text)\n\n['1865']\n\n\n\nregular = re.search(r'[A-Z][a-z]+',text)\nshort = re.search(r'[A-Z][a-z]?',text)\n\n\n#Compare these\nplus = re.findall(r'[A-Z][a-z ]+',text)\nplusq = re.findall(r'[A-Z][a-z ]+?',text)\n\n\n# Finding capitalized words\nre.findall(r\"\\b[A-Z][a-z]*\\b\", text)\n\n['Long', 'I', 'I', 'At', 'I', 'Joy', 'Anonymous']\n\n\n\n# Problem: Find all sentences (Start with capital letter, end with period. Remember to use `\\.`",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/09-Regexps/regexpsPython.html#an-example",
    "href": "chapters/09-Regexps/regexpsPython.html#an-example",
    "title": "Python regexps",
    "section": "An example",
    "text": "An example\n\nwith open(\"data/filenames.txt\",\"r\") as f:\n    filenames = f.readlines()\nprint(filenames[0])\nfilenames = [x.strip() for x in filenames] #get rid of the newlines\n\nHW2 - R - QMD_aft85126_attempt_2023-09-24-18-40-28_Homework2-R.qmd\n\n\n\n\n# Using alternation to select qmd or Rmd files\nselected = [x for x in filenames if re.match(r\".*\\.(qmd|Rmd)\",x)]\nrejected = [x for x in filenames if not re.match(r\".*\\.(qmd|Rmd)\",x)]\n\n\n# Using grouping to extract netid\nmatches = [re.search(r\"_([a-z]{3}[0-9]{5})_\",x) for x in selected]\n[x[1] for x in matches][0:5]\n\n['aft85126', 'pez35105', 'min29847', 'imk48906', 'uwc08078']\n\n\n\nfilenames = pd.read_csv(\"data/filenames.txt\",names=[\"Name\"])\n\n\nfilenames['Name'].map(lambda x: re.search(r\"_([a-z]{3}[0-9]{5})_\",x)[1])\nfilenames = filenames.assign(netid = filenames['Name'].map(lambda x: re.search(r\"_([a-z]{3}[0-9]{5})_\",x)[1])\n )\nfilenames = filenames.assign(extension = filenames['Name'].map(lambda x: re.search(r\".*\\.(qmd|Rmd|pdf)$\",x)[1]))\n\nAdding (?P&lt;name&gt;...) names the submatch. You can then extract or refer to the submatch by name.\n\nm = re.search(r\"(?P&lt;found&gt;[a-z]{3})\",\"abcdefghij\")\nprint(m[0],m.group(1),m.group('found'))\n\nabc abc abc\n\n\nThe .str.extract method is a powerful way to pick apart a string into columns in a pandas dataframe. It combines the operations above into a single operation. Combining it with named submatches gives names to the new columns.\n\nfilenames = pd.read_csv(\"data/filenames.txt\",names=[\"Name\"])\nfilenames=filenames['Name'].str.extract(r\"(?P&lt;name&gt;.*_(?P&lt;netid&gt;[a-z]{3}[0-9]{5})_.*\\.(?P&lt;extension&gt;qmd|Rmd|pdf))$\")\n\nThere are many other useful operations available with the pandas str library.\n\nstr.split\nstr.replace\nstr.cat (joins strings together with argument sep=)",
    "crumbs": [
      "Contents",
      "Python regexps"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html",
    "href": "chapters/10-Shell/UnixCommandLine.html",
    "title": "The UNIX command line",
    "section": "",
    "text": "Access to remote servers is generally purely CLI\nProcess automation often relies on CLI\nCLI is a quick and efficient way to work with files and directories",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#why-learn-the-command-line",
    "href": "chapters/10-Shell/UnixCommandLine.html#why-learn-the-command-line",
    "title": "The UNIX command line",
    "section": "",
    "text": "Access to remote servers is generally purely CLI\nProcess automation often relies on CLI\nCLI is a quick and efficient way to work with files and directories",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#unix",
    "href": "chapters/10-Shell/UnixCommandLine.html#unix",
    "title": "The UNIX command line",
    "section": "UNIX",
    "text": "UNIX\nUNIX is a generic term for a family of operating systems dating back to the 1960’s. Many systems today are in the UNIX family. The most notable examples are\n\nLinux (actually a whole family of Linux OS’s) – derived from an open source system created by Linus Torvalds\nMacOS\n\nIn addition, Microsoft now supports a system called WSL (Windows subsystem for Linux) that allows you to work with Linux on a windows machine.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-gnu-project",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-gnu-project",
    "title": "The UNIX command line",
    "section": "The GNU project",
    "text": "The GNU project\nThe GNU project is a collection of open source tools written (primarily) for the UNIX ecosystem. The GNU project includes shells (bash), compilers (gcc), text editors (emacs), and many other resources. Most Linux systems are closely integrated with GNU tools.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-unix-shell",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-unix-shell",
    "title": "The UNIX command line",
    "section": "The UNIX shell",
    "text": "The UNIX shell\nThe shell is a program that provides access to a range of tools for working with files and directoriees, and which can launch other programs that can do pretty much anything.\nOne can write programs for the shell to execute (these are called shell scripts) or one can use the shell interactively.\nThere are many shells available but the three you are most likely to encounter are:\n\nthe bourne shell (sh). This is the simplest shell program and mostly occurs in shell scripts. It is the “lowest common denominator” of UNIX shells.\nbash is the standard shell that is associated with the GNU toolkit\nzsh has become a popular shell because of its flexibility and its many customization options.\n\nOn Windows, the gitbash package provides a bash shell that runs in the Windows environment.\nMost interactive commands are the same regardless of which shell you use, but the programming languages for each shell are similar but definitely not the same.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#which-shell-am-i-running",
    "href": "chapters/10-Shell/UnixCommandLine.html#which-shell-am-i-running",
    "title": "The UNIX command line",
    "section": "Which shell am I running?",
    "text": "Which shell am I running?\nWhen you launch a terminal window on Linux or MacOS, the system starts a shell program in that window and you interact with that shell. On MacOS, the default shell is zsh. On most Linux installations, it is bash.\nTo see what’s happening on your computer, run the following command in a terminal window. Here, and later, the initial ‘$’ stands for the prompt you receive from the shell. Yours may be fancier. We’ll see later how to customize it.\n\n$ echo $0\n\n(Note: for a whole range of technical reasons this isn’t 100% guaranteed to work but it is almost certainly correct!)",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#navigation",
    "href": "chapters/10-Shell/UnixCommandLine.html#navigation",
    "title": "The UNIX command line",
    "section": "Navigation",
    "text": "Navigation\nYour shell process always has a notion of “current directory.” This is the folder/directory that will be accessed by default when you run commands.\nWhen you start a shell, the current directory is your home directory.\nFiles and directories are referred to by paths that (in UNIX derived OS’s) always use the ‘/’ character.\nThree important conventions\n\nThe current working directory is abbreviated as ‘.’\nThe parent of the current working directory is abbreviated as ‘..’\nYour home directory is abbreviated as ‘~’.\n\n\nKey Navigation Commands\nThe key commands for navigation through the file system are:\n\npwd prints the current working directory\nls lists the files in the current directory\ncd changes the working directory\nmkdir creates a new directory\nrmdir deletes a directory, assuming it is empty.\n\nNote: The ‘#’ symbol means to treat everything following as a comment, not to be executed.\n\n$ pwd\n/home/jeremy9959\n\n\n$ ls\ndata/  model.py  notes/\n\n\n$ cd data # change working directory to data\n$ pwd # check our working directory\n/home/jeremy9959/data\n$ ls # list files\ntest.csv  training.csv\n$ cd .. # change to parent directory\n$ pwd # confirm our location\n/home/jeremy9959\n\n\n\nOptions\nUnix commands typically take (many) options. The general structure of these options are either - followed by a letter, or --word. Sometimes you specify the option as --word=value.\n\n$ (command) -a -b -c --name --option=whatever\n\nYou can usually run commands together like this:\n\n$ (command) -abc\n\nThe ls command has many options and variations. These vary from system to system.\n\n$ ls --help  # sometimes this works, but not always\n$ man ls # this opens a manual page for the ls command which may tell you more than you want to know\n\nSome important special cases that (almost always) work.\n\n$ ls -l # long form listing\ndrwxrwxr-x - jet08013 11 Oct 09:21 data  # permissions/size/owner/group/modification date\n.rw-rw-r-- 0 jet08013 11 Oct 09:20 model.py\ndrwxrwxr-x - jet08013 11 Oct 09:21 notes\n\n\n$ ls -a # show  \"hidden files\" (names start with .)\n.settings  data  model.py  notes\n\n\n$ ls -F # \ndata/ model.py notes/\n\n\n$ ls data  # lists the contents of the directory\ntest.csv training.csv\n$ ls -F -d data  # list the directory name\ndata/\n\nYou can also use wildcards.\n\n$ ls *.py\nmodel.py\n$ ls -Fd d* # what happens if you just do ls -F?\ndata/\n\n\n\nMaking and removing directories\nYou can always create a directory, but the system won’t let you remote directories that aren’t empty.\n\n$ ls \ndata  model.py  notes\n$ mkdir report\n$ ls -F\ndata/  model.py  notes/  report/\n$ cd report\n$ pwd\n/home/jeremy9959/report\n$ ls \n(nothing)\n$ cd ..\n$ pwd\n/home/jeremy9959\n$ rmdir report\n$ ls -F\ndata/ model.py notes/\n$ rmdir data\nrmdir: failed to remote `data`: Directory not empty\n$ ls data\ntest.csv  training.csv\n\n\n\nWorking with files\nKey commands for working with files.\n\nnano is a tiny text editor that works from the command line and is very easy to use. Other options are vi and emacs. vscode has options allowing you to work remotely as well.\ncp copy a file\nmv rename/move a file or directory\ncat type a file onto the terminal (or more generally combine files)\nmore and less list files page by page\nhead and tail look at first and last lines of a file\nrm remove/delete a file.\n\n\n$ cd data\n$ cp test.csv test_2.csv # make a new copy called test_2.csv\n$ ls\ntest.csv test_2.csv training.csv\n$ mv test_2.csv new_test.csv # rename test_2.csv to new_test.csv\n$ ls\nnew_test.csv test.csv training.csv\n$ cat test.csv\n(... bunch of stuff)\n$ head test.csv\n(first ten lines)\n$ tail test.csv\n(last ten lines)\n$ head -5 test.csv # first 5 lines\n(first 5 lines)\n$ tail -5 test.csv # last 5 lines\n(last 5 lines)\n$ tail  +2 test.csv # start with line 2 and go to the end\n(lots of lines)\n$ ls \nnew_test.csv test.csv training.csv\n$ rm new_test.csv\nrm: remove regular file 'new_test.csv'? y # you may not see this\n$ ls\ntest.csv training.csv\n\n\n\nNotes and variations\n\nYou can copy a bunch of files to a directory if the target of the copy is a directory. You can use wildcards if you want.\n\n\n$ cp file1 file2 file3 ... filen directory \n$ cp *.csv directory # copy all .csv files into the specified directory\n\n\nThe mv command will work on directories to rename them.\n\n\n$ ls -F\ndata/ model.py notes/\n$ mv data old_data\n$ ls -F\nmodel.py old_data/ notes/\n\n\nThe cp command doesn’t work on directories unless you use the -r or --recursive flag, in which case it copies the entire directory tree.\nYou should assume that these operations are irrevocable and destructive. There is no trash can in UNIX So for example if you rename file1 ontop of another file2 , you delete the existing file2. You can prevent this (and get warnings) with the -i flag.\n\n\n$ rm -i model.py\nrm: remove regular file `model.py`? n # cancel the operation\n$  cp model.py model2.py \n$  mv model.py model2.py # this will overwrite model2.py \n$  ls -failed\ndata/ model2.py notes/\n\n\nThe -f flag means “force” and will override any warnings. So cp -f will do a copy over an existing file without a warning. In particular, rm -f will remove a directory and its contents even if the directory is nonempty. Use with extreme caution!\nThe shell wildcards are * (which matches anything) and ? which matches one character.\nThe ls -R command lists the contents of all subdirectories as well as the directory itself. The tree command (which isn’t always available) gives you a nicer picture.\n\n\n$ tree \n.\n├── data\n│   ├── test.csv\n│   └── training.csv\n├── model.py\n└── notes\n    ├── algorithm_notes.txt\n    └── to_do.txt\n\n\n\nExercise\nYou receive the following note from your boss together with this attachment.\n\nHi, one of our analysts just quit and he sent me the attached zip file of his work so far\non one of our projects.  Can you get it organized?\n\nUnzip the attachment. Using the command line, organize the data into appropriate directories and standardize the file names in a reasonable way.\nA few notes:\nTo unzip the attachment on the command line, use the unzip command.\n\n$ unzip joe.zip\n\nTo create a zip file you use the zip command. The -r option means to descend into directories as well.\n\n$ zip -r zipfile.zip ...files and directories to zip...\n\nTo run a python program from the command line, use the python command:\n\n$ python program.py \n...program runs",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#redirection-pipes-and-filters",
    "href": "chapters/10-Shell/UnixCommandLine.html#redirection-pipes-and-filters",
    "title": "The UNIX command line",
    "section": "Redirection, Pipes, and Filters",
    "text": "Redirection, Pipes, and Filters\n\nStandard input and standard output\nWhen a UNIX command runs, it typically has three I/O pathways associated to it:\n\nan input stream called the standard input.\nan output stream called the standard output.\nan output stream called the standard error output.\n\nPrograms which read from standard input and write to standard output are called filters.\nSome key commands for this section:\n\ncat combines the files given as arguments and outputs them to standard output chained together. Without any files, reads from standard input and outputs to standard output.\nwc counts words, characters, and lines from the file on the command line, or from standard input, and outputs to standard output. wc -c, wc -l, and wc -w give the individual numbers.\ncut extracts a field from the file on the command line (or from standard input) and outputs to standard output.\necho sends its command line to standard output.\nsort sorts files or standard input, outputs to standard output.\ngrep looks for matching patterns in files or standard input, outputs matching lines to standard output.\nuniq finds unique lines in a sorted file or standard input.\n\n\n\nRedirection\nOne of the most powerful features of the shell is its ability to redirect standard input, standard output, and standard error to other files, and thereby construct pipelines.\n\nRedirection of output\n\n$ ls &gt; files.txt # the &gt; sign sends standard output to the given file.\n$ cat files.txt # cat types the file to standard output\ndata\nfiles.txt\nmodel2.py \nnotes\n$ ls -F # notice that files.txt has been created\ndata/ files.txt model2.py notes/\n\nOrdinarily, redirecting output using &gt; overwrites the target. But if you use &gt;&gt; you can append to the end of a file.\n\n\nPipes\nA pipe between commands is written with |. A pipe means the output from the first command should be sent as input to the second command.\nFirst, let’s look at the wc command.\n\n$ wc files.txt\n4 4 31 files.txt # lines words characters in files.txt\n$ wc -l files.txt # just the lines please\n4\n\nNow we put wc into a pipeline with ls to count the number of files in our directory.\n\n$ ls | wc -l  # the output of ls (one file per line) goes to wc -l which counts lines \n4\n\nHere we combine the training and test files and count the number of characters.\n\n$ ls data/*\ntest.csv training.csv\n$ cat data/* | wc -l \n151\n\n\n\n\nThe standard input\nCommands like wc and cat either use files specified as arguments or, if there aren’t any, they read from standard input.\n\n$ wc \nHere, wc is reading this stuff (which comes from the terminal, i.e. standard input)\nand is counting words, lines and so on.\nI use CTRL-D to send an end of file to tell wc that I'm done.\n^D \n3 37 86\n\nYou can redirect standard input using &lt;.\n\n$ wc &lt; files.txt\n4 4 31\n\nThe output is the line/word/character counts, but there’s no file name because the data comes from standard input via the ‘&lt;’ operator.\nCheck-in: Explain what these commands do and why.\n\n$ echo \"Hello There\"\n$ echo \"Hello There\" &gt; hello.txt\n$ echo \"Hello There\" | wc \n\nTwo useful commands are sort and cut.\nThe cut command extracts fields from a delimited file. You can specify the field separator and the fields you want. The default delimiter for cut is the TAB character.\nWARNING: cut (and sort) are not sophisticated about quoted fields that contain commas, unlike, say, pandas or the tidyverse. So you may not always get what you are expecting if you have quoted fields that contain commas.\n\n$ cut -f4 -d, data/training.csv | head\nRegion\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\nAnvers\n$ cut -f1-4 -d, data/test.csv | tail -3\nPAL0910,66,Chinstrap penguin (Pygoscelis antarctica),Anvers\nPAL0910,67,Chinstrap penguin (Pygoscelis antarctica),Anvers\nPAL0910,68,Chinstrap penguin (Pygoscelis antarctica),Anvers\n$ ls -l  | cut  -f1 -d' ' # here we use space as a delimiter.\n$ cut -c1-10 data/training.csv | head -2 # first 10 characters.\nstudyName,\nPAL0708,1,\n\nThe sort command sorts (not surprisingly). You can specify the file on the command line or use sort as a filter. Ordinarily it sorts on the entire line.\n\n$ sort data/titanic_train.csv &gt; data/titanic_train_sorted.csv\n$ ls data\ntest.csv  titanic_test.csv  titanic_train.csv  titanic_train_sorted.csv  training.csv\n$ head -3 data/titanic_train_sorted.csv\n100,0,2,\"Kantor, Mr. Sinai\",male,34,1,0,244367,26,,S\n101,0,3,\"Petranec, Miss. Matilda\",female,28,0,0,349245,7.8958,,S\n10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C\n\nYou can specify fields (sort key) with -f, numerical sort with -n, reverse with -r, case folding with -f, and a field separator with -t. The quoted names throw things off here!\n\n$ sort -k4 -t, data/titanic_train.csv | head -3 # field four, sep=,\n846,0,3,\"Abbing, Mr. Anthony\",male,42,0,0,C.A. 5547,7.55,,S\n747,0,3,\"Abbott, Mr. Rossmore Edward\",male,16,1,1,C.A. 2673,20.25,,S\n280,1,3,\"Abbott, Mrs. Stanton (Rosa Hunt)\",female,35,1,1,C.A. 2673,20.25,,S\n$ sort -k4 -r -t, data/titanic_train.csv | head -2\n423,0,3,\"Zimmerman, Mr. Leo\",male,29,0,0,315082,7.875,,S\n241,0,3,\"Zabour, Miss. Thamine\",female,,1,0,2665,14.4542,,C\n\nSorting is normally done “alphabetically” in which case the order might not be what you expect for numbers. The -n flag forces numeric values to be used.\n\n$ sort  data/titanic_train.csv | cut -f1 -d, | head -5 # alphabetical\n100\n101\n10\n102\n103\n$ sort -n data/titanic_train.csv | cut -f1 -d, | head -5 # numerical\nPassengerId\n1\n2\n3\n4\n\n\nSearching\nThe grep command searches for matches in its input and outputs any that it finds. There are several variants of grep and there are many, many options to the command.\nThe basics:\n\n$ grep 'William' data/titanic_train.csv | head -5  \n5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S\n13,0,3,\"Saundercock, Mr. William Henry\",male,20,0,0,A/5. 2151,8.05,,S\n18,1,2,\"Williams, Mr. Charles Eugene\",male,,0,0,244373,13,,S\n24,1,1,\"Sloper, Mr. William Thompson\",male,28,0,0,113788,35.5,A6,S\n32,1,1,\"Spencer, Mrs. William Augustus (Marie Eugenie)\",female,,1,0,PC 17569,146.5208,B78,C\n$ grep '^8' data/titanic_train.csv | head -5\n8,0,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S\n80,1,3,\"Dowdell, Miss. Elizabeth\",female,30,0,0,364516,12.475,,S\n81,0,3,\"Waelens, Mr. Achille\",male,22,0,0,345767,9,,S\n82,1,3,\"Sheerlinck, Mr. Jan Baptist\",male,29,0,0,345779,9.5,,S\n83,1,3,\"McDermott, Miss. Brigdet Delia\",female,,0,0,330932,7.7875,,Q\n$ grep '\\bWilliam\\b' data/titanic_train.csv | tail -5\n803,1,1,\"Carter, Master. William Thornton II\",male,11,1,2,113760,120,B96 B98,S\n811,0,3,\"Alexander, Mr. William\",male,26,0,0,3474,7.8875,,S\n865,0,2,\"Gill, Mr. John William\",male,24,0,0,233866,13,,S\n881,1,2,\"Shelley, Mrs. William (Imanita Parrish Hall)\",female,25,0,1,230433,26,,S\n886,0,3,\"Rice, Mrs. William (Margaret Norton)\",female,39,0,5,382652,29.125,,Q\n$ grep '\\bWilliam\\b' data/titanic_train.csv | wc -l\n\nYou can do a lot of useful stuff by combining grep with other tools.\n\n$ grep female data/titanic_train.csv &gt; data/females_train.csv\n$ head data/females_train.csv\n2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n9,1,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S\n10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C\n\nUNIX tools aren’t as powerful as the csv tools in, for example, pandas, but you can still be clever. Suppose we want to get at the names in the titanic file. They have embedded commas but are set off with quotations\n\n$ cut -f2 -d\\\" data/titanic_train.csv\nPassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\nBraund, Mr. Owen Harris\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nHeikkinen, Miss. Laina\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | head -2\nSurvived\nmale\nfemale\n\nThe uniq command can be used to see the different elements in the field.\n\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | sort | uniq \n\nfemale\nmale\nSurvived\n$ cut -d\\\" -f3 data/titanic_train.csv | cut -f2 -d, | sort | uniq -c\n 53 \n 282 female\n 556 male\n 1 Survived\n\n\n\n\nExercise\n\nUse UNIX tools to determine:\n\nhow many of each type of penguin there are in the penguins_training.csv and penguins_test.csv files.\nhow many males and females there are in each file.\n\nCombine the training and test files for the penguins into a single file (penguins.csv). Then make a file male_penguins.csv containing just the males.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#variables-and-loops",
    "href": "chapters/10-Shell/UnixCommandLine.html#variables-and-loops",
    "title": "The UNIX command line",
    "section": "Variables and Loops",
    "text": "Variables and Loops\n\nVariables\nYou use names for variables (like x), but to refer to the value of a variable you use $x$.\n\n$ x=\"hello\" # no spaces!\n$ echo $x\nhello\n\nThe various UNIX shells are programming languages and they have the full set of capabilities: variables, logical statements, loops….\nThe syntax for loops is different for zsh and bash unfortunately.\n\n$ for x in *.csv # bash\n&gt; do\n&gt; echo $x\n&gt; done\n\n\n$ for x in *.csv # zsh\ncmdor cursh cmdand cursh then else&gt; echo $x\n\nYou can use loops to (for example) rename a bunch of files.\n\n$ mkdir bkup\n$ for x in *.csv \ncmdor cursh cmdand cursh then else&gt; cp $x bkup/$x\n\n\n$ mkdir bkup\n$ for x in *.csv\n&gt; do\n&gt; cp $x bkup/$x\n&gt; done",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#scripts",
    "href": "chapters/10-Shell/UnixCommandLine.html#scripts",
    "title": "The UNIX command line",
    "section": "Scripts",
    "text": "Scripts\nA shell script is a file containing a sequence of shell commands. When a shell starts, it executes a startup script stored in .zshrc or .bashrc. This is where you can put commands to customize your shell.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#the-environment",
    "href": "chapters/10-Shell/UnixCommandLine.html#the-environment",
    "title": "The UNIX command line",
    "section": "The environment",
    "text": "The environment\nEvery shell has an environment which is a bunch of variables that are used by programs. Elements of the environment are called environment variables. Sometimes you have to set an environment variable.\nSome common and important shell environment variables are:\n\n$ echo $HOME # home directory\n$ echo $PATH # search path for commands\n$ echo $USER # your user id\n$ echo $PS1 # the shell prompt\n$ env # print the entire environment",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/10-Shell/UnixCommandLine.html#other-topics",
    "href": "chapters/10-Shell/UnixCommandLine.html#other-topics",
    "title": "The UNIX command line",
    "section": "Other topics",
    "text": "Other topics\n\nUsing wget to get information from the web.\nUsing ssh to make a remote connection.\nUsing rsync to copy files across computers.\nUsing tar or gzip to compress and uncompress archives of files.",
    "crumbs": [
      "Contents",
      "The UNIX command line"
    ]
  },
  {
    "objectID": "chapters/13-Plotting/Plotting.html",
    "href": "chapters/13-Plotting/Plotting.html",
    "title": "Plotting (in Python)",
    "section": "",
    "text": "The main tool for plotting in R is ggplot, which we have talked about a little and which will be covered in detail in other courses.\nThe purpose of this lesson is to talk about tools for plotting in Python. Here the situation is more diverse, and there are a number of different plotting packages with different capabilities. The most notable ones are:\nWe’ll discuss matplotlib, bokeh, and seaborn and you can explore the others on your own to see what you like best.\nWe’ll work with the penguins dataset.\nimport matplotlib.pyplot as plt  # this gives a \"matlab\"-like interface to matplotlib\nimport pandas as pd\nimport numpy as np\n\npenguins = pd.read_csv(\"data/penguins-raw.csv\")\npenguins = penguins.drop(\"Comments\", axis=1)\npenguins.dropna()\n\nx = np.linspace(-5, 5)\ny = x**2\nThe matplotlib package is organized around figures and axes. Essentially, a set of axes is a single graph, and a figure is a collection of axes organized into a single picture. To work with matplotlib one first creates a figure and then adds axes to it.\nfig = plt.figure(figsize=(3, 4))\naxes = fig.add_subplot(\n    1, 1, 1\n)  # here we are saying the figure will have 1 row, 1 column, and this is plot number 1.\naxes.plot(x, y)  # plot y vs x\nYou can plot multiple things on on set of axes. We also add a grid.\naxes.plot(x, 1 - 2 * y)\naxes.grid(True)\nfig\nIf we want a 2x2 array of plots, we could proceed like this.\nfig = plt.figure(figsize=(4, 3))\naxes1 = fig.add_subplot(2, 2, 1)\naxes2 = fig.add_subplot(2, 2, 2)\naxes3 = fig.add_subplot(2, 2, 3)\naxes4 = fig.add_subplot(2, 2, 4)\naxes1.plot(x, y)\naxes2.plot(x, 2 * y + 1)\naxes3.plot(x, -y)\naxes4.plot(x, -y + 2)\nThere are lots of types of plots, as always.\nfig = plt.figure(figsize=(6, 8))\naxes1 = fig.add_subplot(2, 2, 1)\naxes2 = fig.add_subplot(2, 2, 2)\naxes3 = fig.add_subplot(2, 2, 3)\naxes4 = fig.add_subplot(2, 2, 4)\naxes1.plot(x, y)\naxes2.scatter(penguins[\"Body Mass (g)\"], penguins[\"Flipper Length (mm)\"], s=0.1)\naxes3.plot(x, -y, color=\"green\", linestyle=\"dashed\")\naxes4.plot(x, -y + 2, color=\"blue\", linestyle=\"--\", linewidth=3)\nYou need titles (for the figure and the individual plots) and axis labels.\nfig.set_size_inches(12, 12)\nfig.suptitle(\"Demonstration Plot\")\naxes1.set_title(\"A Parabola\")\naxes1.set_xlabel(\"x\")\naxes1.set_ylabel(\"y\")\naxes1.grid(True)\naxes2.set_title(\"A scatter plot\")\naxes3.set_title(\"A green\\n upside-down parabola\")\naxes4.set_title(\"A blue parabola\")\nfig\nLet’s look at a fully developed scatter plot.\nfig = plt.figure(figsize=(10, 10))\n# fig.suptitle(\"Flipper Length vs Body Mass\")\naxes = fig.add_subplot(1, 1, 1)\naxes.grid(True)\naxes.set_xlabel(\"Body Mass (g)\")\naxes.set_ylabel(\"Flipper Length (mm)\")\naxes.set_title(\"Flipper Length vs Body Mass\")\n# axes.set_xlim(0,5500)\n# axes.set_ylim(0,300)\n\nMales = penguins[penguins[\"Sex\"] == \"MALE\"]\nFemales = penguins[penguins[\"Sex\"] == \"FEMALE\"]\nmale_plot = axes.scatter(\n    x=Males[\"Body Mass (g)\"], y=Males[\"Flipper Length (mm)\"], c=\"blue\", label=\"Male\"\n)\nfemale_plot = axes.scatter(\n    x=Females[\"Body Mass (g)\"],\n    y=Females[\"Flipper Length (mm)\"],\n    c=\"red\",\n    label=\"Female\",\n)\naxes.legend([\"Male\", \"Female\"])\nFinally we can generate a multiple plot.\nfig = plt.figure(figsize=(10, 30))\nMales = penguins[penguins[\"Sex\"] == \"MALE\"]\nFemales = penguins[penguins[\"Sex\"] == \"FEMALE\"]\nfor i, x in enumerate(\n    [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"]\n):\n    axes = fig.add_subplot(3, 1, i + 1)\n    axes.grid(True)\n    axes.set_title(f\"{x} vs Body Mass\")\n    male_plot = axes.scatter(\n        x=Males[\"Body Mass (g)\"], y=Males[x], c=\"blue\", label=\"Male\"\n    )\n    female_plot = axes.scatter(\n        x=Females[\"Body Mass (g)\"], y=Females[x], c=\"red\", label=\"Female\"\n    )\n    axes.legend([\"Male\", \"Female\"])\nMatplotlib also offers a histogram command.\nfig = plt.figure(figsize=(5, 5))\naxes = fig.add_subplot(1, 1, 1)\naxes.grid(True)\naxes.set_title(\"Distribution of Body Mass (Male and Female)\")\naxes.hist(\n    Males[\"Body Mass (g)\"],\n    color=\"forestgreen\",\n    bins=50,\n    density=True,\n    label=\"Male\",\n    alpha=0.5,\n)\naxes.hist(\n    Females[\"Body Mass (g)\"],\n    color=\"orange\",\n    bins=50,\n    density=True,\n    label=\"Female\",\n    alpha=0.5,\n)\naxes.legend([\"Male\", \"Female\"])\nfig\nThere are millions of others…..",
    "crumbs": [
      "Contents",
      "Plotting (in Python)"
    ]
  },
  {
    "objectID": "chapters/13-Plotting/Plotting.html#seaborn",
    "href": "chapters/13-Plotting/Plotting.html#seaborn",
    "title": "Plotting (in Python)",
    "section": "Seaborn",
    "text": "Seaborn\nSeaborn is based on matplotlib but the graphics are of higher quality (IMHO) and many of the plots published in scientific journals in biology are recognizably seaborn.\nSeaborn is also better at handling data sources than matplotlib and has built in statistical capabilities (box plots, density curves, fitted lines…)\nUltimately to make seaborn really work you need to know matplotlib well.\nSee the seaborn documentation\n\nimport seaborn as sns\n\nsns.set_theme()\n\nWe can declare a data source for our plots.\nA scatter plot is called a relplot for “relationship plot”.\n\nsns.relplot(data=penguins, x=\"Body Mass (g)\", y=\"Flipper Length (mm)\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\n\nsns.relplot(\n    data=penguins, col=\"Sex\", hue=\"Species\", x=\"Body Mass (g)\", y=\"Flipper Length (mm)\"\n)\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\n\nax = sns.relplot(\n    data=penguins, hue=\"Species\", x=\"Body Mass (g)\", y=\"Flipper Length (mm)\"\n)\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\nSeaborn has some built-in statistical stuff, like ggplot does.\n\nsns.lmplot(data=penguins, x=\"Body Mass (g)\", y=\"Flipper Length (mm)\", hue=\"Species\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\nHistograms are displots.\n\n# displot is a facetgrid object with multiple axes within it; you need to\n# get at those to mess with titles, etc.\nax = sns.displot(data=penguins, x=\"Body Mass (g)\", hue=\"Species\")\nax.axes[0, 0].set_title(\"Distribution of Body Mass\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\nText(0.5, 1.0, 'Distribution of Body Mass')\n\n\n\n\n\n\n\n\n\nHere are some examples of what you can do with seaborn. Let’s clean up the species names and the sex field first.\n\npenguins[\"SpeciesS\"] = penguins[\"Species\"].apply(lambda x: x.split(\" \")[0])\npenguins[\"Sex\"] = penguins[\"Sex\"].apply(\n    lambda x: x if type(x) != str else x[0] + x[1:].lower()\n)\n\nYou can split the histograms by species.\n\nax = sns.displot(data=penguins, x=\"Body Mass (g)\", col=\"SpeciesS\")\nax.set_titles(\"{col_name}\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\n\n\n\n\n\n\n\nYou can split the histograms by species and sex, and add density curves if you want.\n\nax = sns.displot(data=penguins, x=\"Body Mass (g)\", col=\"SpeciesS\", row=\"Sex\", kde=True)\nax.set_titles(\"{col_name}|{row_name}\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\n\n\n\n\n\n\n\nYou can add colors if you want.\n\nax = sns.displot(data=penguins, x=\"Body Mass (g)\", row=\"Sex\", kde=True, hue=\"SpeciesS\")\nax.set_titles(\"{row_name}\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\n\n\n\n\n\n\n\nAmong the other types of plots you can get are:\nBar Plots\n\nax = sns.catplot(data=penguins, x=\"SpeciesS\", kind=\"count\", hue=\"Sex\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\nBox Plots\n\nax = sns.boxplot(data=penguins, x=\"Body Mass (g)\", y=\"SpeciesS\")\nlabel = ax.set_ylabel(\"Species\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\nViolin Plots\n\nax = sns.violinplot(data=penguins, x=\"Body Mass (g)\", y=\"SpeciesS\")\nlabel = ax.set_ylabel(\"Species\")\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n/home/jet08013/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning:\n\nis_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n\n\n\n\n\n\n\n\n\nThere are many other things you can do. See the seaborn plot gallery.",
    "crumbs": [
      "Contents",
      "Plotting (in Python)"
    ]
  },
  {
    "objectID": "chapters/13-Plotting/Plotting.html#bokeh",
    "href": "chapters/13-Plotting/Plotting.html#bokeh",
    "title": "Plotting (in Python)",
    "section": "Bokeh",
    "text": "Bokeh\nBokeh is an open source plotting package that is not derived from matplotlib. It has an underlying javascript engine that provides interactivity.\n\nimport bokeh\nfrom bokeh.plotting import figure, output_file, output_notebook, show\nfrom bokeh.models import ColumnDataSource\n\noutput_notebook()\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\nWe setup a ColumnDataSource from our penguins dataframe.\n\npenguins_source = ColumnDataSource(penguins)\n\nWe plot by creating a figure and adding things to it.\n\nF = figure()\nF.scatter(x=\"Body Mass (g)\", y=\"Culmen Length (mm)\", source=penguins_source)\nshow(F)\n\n\n  \n\n\n\n\n\nOne of the nice featues of Bokeh is that we can add interactive tools to it.\n\nx = \"Body Mass (g)\"\ny = \"Culmen Length (mm)\"\ntooltips = [\n    (\"Mass\", \"@{Body Mass (g)}\"),\n    (\"Length\", \"@{Culmen Length (mm)}\"),\n    (\"Sex\", \"@Sex\"),\n]\nF = figure(x_axis_label=x, y_axis_label=y, title=f\"{y} vs {x}\", tooltips=tooltips)\nF.scatter(x=x, y=y, source=penguins_source)\nshow(F)\n\n\n  \n\n\n\n\n\nTo color something, we create a color mapper function.\n\nfrom bokeh.transform import factor_cmap\n\ncolor_mapper = factor_cmap(\n    \"SpeciesS\",\n    palette=[\"red\", \"green\", \"blue\"],\n    factors=[\"Adelie\", \"Gentoo\", \"Chinstrap\"],\n)\nF = figure(x_axis_label=x, y_axis_label=y, title=f\"{y} vs {x}\", tooltips=tooltips)\nF.scatter(\n    x=x,\n    y=y,\n    size=7,\n    fill_color=factor_cmap(\n        \"SpeciesS\",\n        palette=[\"red\", \"green\", \"blue\"],\n        factors=[\"Adelie\", \"Gentoo\", \"Chinstrap\"],\n    ),\n    source=penguins_source,\n)\nshow(F)",
    "crumbs": [
      "Contents",
      "Plotting (in Python)"
    ]
  },
  {
    "objectID": "chapters/99-Resources/regexps.html",
    "href": "chapters/99-Resources/regexps.html",
    "title": "Python regexps",
    "section": "",
    "text": "# Regular Expressions\nimport re\nfrom collections import Counter\ntext = \"\"\"\nLong ago, I travelled to the far west, seeking my fortune. I found\nfrosty mountains, arid deserts, lush oases, and a huge ocean.\nAt times, I was gripped by despair, and at other times filled with Joy.\n\n- Anonymous, 1865\n\"\"\""
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#guide",
    "href": "chapters/99-Resources/regexps.html#guide",
    "title": "Python regexps",
    "section": "Guide",
    "text": "Guide\n\nLetters, Numbers match themselves\n‘.’ matches one of anything\n‘+’ means one or more of the preceeding\n’*’ means 0 or more of the preceding\n[] groups things ([A-Z]+ matches a sequence of one or more capital letters);\n‘\\w’ matches “word” characters\n‘\\W’ matches non-word characters\n‘\\b’ matches boundaries (end or start of string)\n‘{5}’’ matches 5 times\n‘\\s’ matches whitespace\n‘\\S’ matches non-whitespace\n\n\nif re.search(r\"travel\", text):\n    print(\"Yes\")\n\nif re.match(r\"travel\", text):\n    print(\"Yes\")\n\n# m = re.search(r\"travel\",text)\n# print(m,m.start(), m.end(),m.span(),m.string)\n\nm = re.search(r\"I (\\w+) to \", text)\nprint(m[0], m[1])\n\nYes\nI travelled to  travelled\n\n\n\nastrings = re.findall(r\"a\\w+\", text)\nprint(astrings)\n\nawords = re.findall(r\"\\ba\\w+\\b\", text)\nprint(awords)\n\n['ago', 'avelled', 'ar', 'ains', 'arid', 'ases', 'and', 'an', 'as', 'air', 'and', 'at']\n['ago', 'arid', 'and', 'and', 'at']\n\n\n\nre.findall(r\"\\w+\", text)\n\nre.findall(r\"\\w+\", text.lower())\n\n['long',\n 'ago',\n 'i',\n 'travelled',\n 'to',\n 'the',\n 'far',\n 'west',\n 'seeking',\n 'my',\n 'fortune',\n 'i',\n 'found',\n 'frosty',\n 'mountains',\n 'arid',\n 'deserts',\n 'lush',\n 'oases',\n 'and',\n 'a',\n 'huge',\n 'ocean',\n 'at',\n 'times',\n 'i',\n 'was',\n 'gripped',\n 'by',\n 'despair',\n 'and',\n 'at',\n 'other',\n 'times',\n 'filled',\n 'with',\n 'joy',\n 'anonymous',\n '1865']"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#match-objects",
    "href": "chapters/99-Resources/regexps.html#match-objects",
    "title": "Python regexps",
    "section": "Match Objects",
    "text": "Match Objects\n\n%%\nfinditer\nmatch objects\nx a match object: x[0] returns the match; x.span() returns (start, end) of the match\n\n\nfor x in re.finditer(r\"\\w+\", text):\n    print(x[0])\n\nLong\nago\nI\ntravelled\nto\nthe\nfar\nwest\nseeking\nmy\nfortune\nI\nfound\nfrosty\nmountains\narid\ndeserts\nlush\noases\nand\na\nhuge\nocean\nAt\ntimes\nI\nwas\ngripped\nby\ndespair\nand\nat\nother\ntimes\nfilled\nwith\nJoy\nAnonymous\n1865"
  },
  {
    "objectID": "chapters/99-Resources/regexps.html#counter",
    "href": "chapters/99-Resources/regexps.html#counter",
    "title": "Python regexps",
    "section": "Counter",
    "text": "Counter\nCounter creates a dictionary that counts the number of occurrences of elements of a list.\n\nwords = re.findall(r\"\\b\\w\\w+\\b\", text.lower())\ncounts = Counter(words)\nsorted_words = dict(sorted(counts.items(), key=lambda x: x[0], reverse=True))\nprint(sorted_words)\n\n{'with': 1, 'west': 1, 'was': 1, 'travelled': 1, 'to': 1, 'times': 2, 'the': 1, 'seeking': 1, 'other': 1, 'ocean': 1, 'oases': 1, 'my': 1, 'mountains': 1, 'lush': 1, 'long': 1, 'joy': 1, 'huge': 1, 'gripped': 1, 'frosty': 1, 'found': 1, 'fortune': 1, 'filled': 1, 'far': 1, 'despair': 1, 'deserts': 1, 'by': 1, 'at': 2, 'arid': 1, 'anonymous': 1, 'and': 2, 'ago': 1, '1865': 1}"
  },
  {
    "objectID": "chapters/999-Problems/HW1.html",
    "href": "chapters/999-Problems/HW1.html",
    "title": "Homework One",
    "section": "",
    "text": "This assignment is due Sunday, September 10th by midnight. Please submit it using HuskyCT. Follow the instructions below.\n\nCreate a project directory named Homework_One, and inside it create a subdirectory called python.\nIn the python directory, create a jupyter notebook named Homework_One.ipynb.\nUsing a markdown cell, add text at the beginning of your notebook that yields text following this template:\nHeader: First Homework Assignment for Grad 5100\nText: Submitted by [your name] on [the date]\nTopic: Some features of the python language.\n\n(Hint: you can get the word python formatted this way by using backticks: `python`) 3. Using a code cell, create the following variables:\n\nfirst_name = # your first name (a string)\nlast_name = # your last name (a string)\nyear = # current year, an integer\nstates = # a list of strings containing the names of the New England states (look them up)\n\nWorking in code cells, complete the following\n\nfirst_name_345 = first_name[] # fill in the [] to extract the third, fourth, and fifth letters of your first name (note this could be an empty string, or shorter than three letters)\nprint() # complete the print statement to show your answer\n\n\nlast_name_last = last_name[] # fill in the [] to extract the last letter of your last name. Do not assume you know how many letters are in your last name. \nprint() # complete the print statement to show your answer\n\n\nyear_5 = # compute the year multipled by 5\nprint() # print the answer\n\nThe sorted command takes a list and returns it sorted.\n\nstates_sorted = sorted(states) # sort your list of states\nmid = states+_sorted[][] # complete the []'s to find the last letter of the third New England state in alphabetical order. \nprint() # print the answer\n\n\nExport your jupyter notebook as a pdffile and submit it using HuskyCT.\nGo back to your project directory and create a subdirectory called R. In that directory, start Rstudio.\nCreate an RMD file called Homework_One.rmd and repeat the steps above, but working in R and Rstudio. Notice that you’ll have to make some small modifications to the syntax:\n\nchange “Python” to “R”\nreplace “=” by “&lt;-”\nin R, you use sort not sorted\n\nExport your RMD file as a pdf file and submit it using HuskyCT.",
    "crumbs": [
      "Problems",
      "Homework One"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW1.html#first-homework-assignment",
    "href": "chapters/999-Problems/HW1.html#first-homework-assignment",
    "title": "Homework One",
    "section": "",
    "text": "This assignment is due Sunday, September 10th by midnight. Please submit it using HuskyCT. Follow the instructions below.\n\nCreate a project directory named Homework_One, and inside it create a subdirectory called python.\nIn the python directory, create a jupyter notebook named Homework_One.ipynb.\nUsing a markdown cell, add text at the beginning of your notebook that yields text following this template:\nHeader: First Homework Assignment for Grad 5100\nText: Submitted by [your name] on [the date]\nTopic: Some features of the python language.\n\n(Hint: you can get the word python formatted this way by using backticks: `python`) 3. Using a code cell, create the following variables:\n\nfirst_name = # your first name (a string)\nlast_name = # your last name (a string)\nyear = # current year, an integer\nstates = # a list of strings containing the names of the New England states (look them up)\n\nWorking in code cells, complete the following\n\nfirst_name_345 = first_name[] # fill in the [] to extract the third, fourth, and fifth letters of your first name (note this could be an empty string, or shorter than three letters)\nprint() # complete the print statement to show your answer\n\n\nlast_name_last = last_name[] # fill in the [] to extract the last letter of your last name. Do not assume you know how many letters are in your last name. \nprint() # complete the print statement to show your answer\n\n\nyear_5 = # compute the year multipled by 5\nprint() # print the answer\n\nThe sorted command takes a list and returns it sorted.\n\nstates_sorted = sorted(states) # sort your list of states\nmid = states+_sorted[][] # complete the []'s to find the last letter of the third New England state in alphabetical order. \nprint() # print the answer\n\n\nExport your jupyter notebook as a pdffile and submit it using HuskyCT.\nGo back to your project directory and create a subdirectory called R. In that directory, start Rstudio.\nCreate an RMD file called Homework_One.rmd and repeat the steps above, but working in R and Rstudio. Notice that you’ll have to make some small modifications to the syntax:\n\nchange “Python” to “R”\nreplace “=” by “&lt;-”\nin R, you use sort not sorted\n\nExport your RMD file as a pdf file and submit it using HuskyCT.",
    "crumbs": [
      "Problems",
      "Homework One"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html",
    "href": "chapters/999-Problems/HW2-Poisson.html",
    "title": "HW2 - Comments on Poisson",
    "section": "",
    "text": "The Poisson distribution measures the probability of \\(k\\) events occurring in a given time interval, assuming:\n\nthe interarrival times are independent of one another\nthe mean number of arrivals in any interval is a constant \\(\\lambda\\).\n\n\npdata &lt;- tibble(\n    x = seq(0, 20),\n)\nplts &lt;- list()\ni &lt;- 1\n\nfor (n in seq(1, 10, 2)) {\n    cname &lt;- paste0(\"y\", n)\n    pdata &lt;- pdata |&gt; mutate({{ cname }} := dpois(`x`, n))\n}\n\np1 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y1)) +\n    ggtitle(\"mean=1\")\np3 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y3)) +\n    ggtitle(\"mean=3\")\np5 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y5)) +\n    ggtitle(\"mean=5\")\np7 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y7)) +\n    ggtitle(\"mean=7\")\np9 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y9)) +\n    ggtitle(\"mean=9\")\ngrid.arrange(p1, p3, p5, p7, p9)",
    "crumbs": [
      "Problems",
      "HW2 - Comments on Poisson"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html#the-poisson-distribution",
    "href": "chapters/999-Problems/HW2-Poisson.html#the-poisson-distribution",
    "title": "HW2 - Comments on Poisson",
    "section": "",
    "text": "The Poisson distribution measures the probability of \\(k\\) events occurring in a given time interval, assuming:\n\nthe interarrival times are independent of one another\nthe mean number of arrivals in any interval is a constant \\(\\lambda\\).\n\n\npdata &lt;- tibble(\n    x = seq(0, 20),\n)\nplts &lt;- list()\ni &lt;- 1\n\nfor (n in seq(1, 10, 2)) {\n    cname &lt;- paste0(\"y\", n)\n    pdata &lt;- pdata |&gt; mutate({{ cname }} := dpois(`x`, n))\n}\n\np1 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y1)) +\n    ggtitle(\"mean=1\")\np3 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y3)) +\n    ggtitle(\"mean=3\")\np5 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y5)) +\n    ggtitle(\"mean=5\")\np7 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y7)) +\n    ggtitle(\"mean=7\")\np9 &lt;- ggplot(data = pdata, aes(x = x)) +\n    geom_col(aes(y = y9)) +\n    ggtitle(\"mean=9\")\ngrid.arrange(p1, p3, p5, p7, p9)",
    "crumbs": [
      "Problems",
      "HW2 - Comments on Poisson"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html#the-exponential-distribution",
    "href": "chapters/999-Problems/HW2-Poisson.html#the-exponential-distribution",
    "title": "HW2 - Comments on Poisson",
    "section": "The Exponential Distribution",
    "text": "The Exponential Distribution\nThe exponential distribution is a continuous probability distribution given by an exponential function with a fixed rate \\(\\lambda\\).\n\nx &lt;- seq(0, 3, .01)\ny &lt;- dexp(x, 1)\nggplot() +\n    geom_line(aes(x = x, y = y)) +\n    ggtitle(\"Exponential Distribution with parameter 1\")",
    "crumbs": [
      "Problems",
      "HW2 - Comments on Poisson"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2-Poisson.html#poisson-process",
    "href": "chapters/999-Problems/HW2-Poisson.html#poisson-process",
    "title": "HW2 - Comments on Poisson",
    "section": "Poisson Process",
    "text": "Poisson Process\nIn a “Poisson Process”, events occur randomly in time. The interval between two consecutive events is chosen (independently) from an exponential distribution.\n\nt &lt;- rexp(100, 1)\narrivals &lt;- cumsum(t)\nggplot() +\n    geom_col(aes(x = arrivals, y = 1), width = .015, color = \"black\") +\n    ggtitle(\"Arrival Times in a Poisson Process\")\n\n\n\n\n\n\n\n\n\nsum(arrivals &lt; 25)\n\n[1] 18\n\nsum(arrivals &lt; 50)\n\n[1] 41\n\nsum(arrivals &gt; 25 & arrivals &lt; 50)\n\n[1] 23",
    "crumbs": [
      "Problems",
      "HW2 - Comments on Poisson"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW2.html",
    "href": "chapters/999-Problems/HW2.html",
    "title": "Homework Two",
    "section": "",
    "text": "This homework is due Sunday, September 24th at midnight. Please submit it using HuskyCT.\nThere are two files you need to submit (one for R, one for python). For the R part of the homework (problems 1-3), you submit a QMD file with the following YAML material at the top. For the Python part (problem 4-5) submit an ipynb file.\n\n---\ntitle: \"Homework Two - R\"\nauthor: [your name]\nformat: html\n---\n\n\nProblem 1\nLet X be a binomial random variable with n=50 and p=.7.\n\nDraw 1000 samples from X. How many of your sampled values are less than 30?\nBased on the probability distribution, how many sampled values would you expect to see that are less than 30?\n\nPlot a histogram of your sampled values.\n\nYour answer should be in the form of an r code block in your qmd file.\n\nXsamples &lt;- #\nless_than_30_observed &lt;- #\nless_than_30_predicted &lt;- #\n# code to plot histogram of Xsamples\n\n\n\nProblem 2\nThe poisson distribution is a discrete probability distribution that arises in queuing theory (and many other places). For example, imagine that customers arrive at a server at a rate so that, in a typical one hour period, 20 customers come. But the intervals between customers are random and independent of one another. Then in a randomly chosen hour, the probability of k customers arriving is dpois(k,20).\n\nSample this distribution 1000 times (hint: use rpois). What is the largest number of people who arrive in an one of these random hours? What is the smallest?\nSuppose you want to design your system so that it can handle the number of arriving customers 95% of the time. How many people should you design for? (Hint: use qpois).\nWhat’s the chance that between 18 and 22 people arrive in a given hour? (Hint: use ppois).\nPlot the Poisson distribution probabilities. (Hint: use dpois).\n\n\n  poisson_samples &lt;- #\n  max_arrivals &lt;- #\n  min_arrivals &lt;- #\n  threshold_95 &lt;-#\n  # code to plot the distribution\n\n\n\nProblem 3\nWrite an R function that takes a string as input, removes all characters that are not numbers, letters, or spaces, makes all the letters lower case, converts all the spaces to ’_’, and returns the result.\nHints:\n\nthe gsub function replaces things in a string.\nthe tolower function makes things lower case\nthe builtin variable letters (resp LETTERS) is a vector of all lower (resp upper) case letters.\n\n\n\nProblem 4\nDo problem 3 in Python.\nHints:\n\nthe python string method replace() replaces thngs in a string. So if x is a string, x.replace(\"a\",\"b\") replaces all a’s by b.\nthe python string method lower() makes a string lower case. So if x is a string, x.lower() is x in lower case.\n\n\n\nProblem 5\nIf \\(x_0=1\\) and \\(n\\) is a positive real number, the iteration \\[\nx_{k+1} = x_{k}/2+n/(2x_k)\n\\]\nconverges to the square root of \\(n\\). Write a Python function that runs this iteration until the difference between \\(x_{k+1}\\) and \\(x_{k}\\) is less than a tolerance.\n\ndef sq(n):\n    x=1\n    tol = 1\n    while(tol&gt;1e-6):\n        xnew = # fill this in\n        tol = np.abs(xnew - x)\n        x = xnew\n    return x\n\nNow improve the function above so that:\n\none can optionally provide a threshold to replace 1e-6\nif the code runs for more than max_iter iterations of the while loop, it quits while printing “Failed to converge”. max_iter is by default 1000 but can be modified when the function is called.",
    "crumbs": [
      "Problems",
      "Homework Two"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW4Assignment.html",
    "href": "chapters/999-Problems/HW4Assignment.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please submit your solution to this problem on Husky CT by Monday, October 30th at 8:00 AM.\nThis zip file contains the first few chapters of “The Hitchiker’s Guide to the Galaxy” by Douglas Adams in text format in a file called hhg.txt.\n\nWhat shell command will tell you if the word “adorable” occurs in this file? (does it?)\nWhat shell command will tell you how many lines are in the file? (how many are there?)\n\nNext, using whatever tools you prefer, create 26 text files called hhgX.txt where X runs from A to Z. Each file should contain all of the words from hhg.txt that begin with the corresponding letter, one word per line, in alphabetical order, in lower case. Each word should occur only once in hhgX.txt regardless of how many times it occurs in the original text.\nNext, answer the following questions:\n\nWhat shell command would combine all of the hhgX.txt files into a single file called hhgwords.txt?\nWhat shell commands would carry out the following:\n\ncreate a directory called orig\nmove the original files hhg.zip and hhg.txt into this directory.\n\n\nCreate a file that contains your answers to a,b,c,d called shell_answers.sh. This file should contain only four lines.\nCreate a single zip file called hhg-exploded.zip which, when uncompressed, yields:\n\na directory called first_last where first and last are your first and last names. Inside that directory, there should be:\na file report.txt that explains your method for creating the hhgX.txt files (briefly)\nthe file shell_answers.sh\na subdirectory whose name is hhg-exploded, and whose contents are the 26 files described above.\na subdirectory called bkup which contains the original text file hhg.txt as well as the original zip file hhg.zip.\n\nTo illustrate (although I’ve only put the ABC files in hhg-exploded) your zip file should unpack to this:\njeremy_teitelbaum\n├── bkup\n│   ├── hhg.txt\n│   └── hhg.zip\n├── hhg-exploded\n│   ├── hhgA.txt\n│   ├── hhgB.txt\n│   ├── hhgC.txt\n│   \n├── report.txt\n└── shell_answers.sh",
    "crumbs": [
      "Problems",
      "Homework 4"
    ]
  },
  {
    "objectID": "chapters/999-Problems/HW4Assignment.html#homework-4",
    "href": "chapters/999-Problems/HW4Assignment.html#homework-4",
    "title": "Homework 4",
    "section": "",
    "text": "Please submit your solution to this problem on Husky CT by Monday, October 30th at 8:00 AM.\nThis zip file contains the first few chapters of “The Hitchiker’s Guide to the Galaxy” by Douglas Adams in text format in a file called hhg.txt.\n\nWhat shell command will tell you if the word “adorable” occurs in this file? (does it?)\nWhat shell command will tell you how many lines are in the file? (how many are there?)\n\nNext, using whatever tools you prefer, create 26 text files called hhgX.txt where X runs from A to Z. Each file should contain all of the words from hhg.txt that begin with the corresponding letter, one word per line, in alphabetical order, in lower case. Each word should occur only once in hhgX.txt regardless of how many times it occurs in the original text.\nNext, answer the following questions:\n\nWhat shell command would combine all of the hhgX.txt files into a single file called hhgwords.txt?\nWhat shell commands would carry out the following:\n\ncreate a directory called orig\nmove the original files hhg.zip and hhg.txt into this directory.\n\n\nCreate a file that contains your answers to a,b,c,d called shell_answers.sh. This file should contain only four lines.\nCreate a single zip file called hhg-exploded.zip which, when uncompressed, yields:\n\na directory called first_last where first and last are your first and last names. Inside that directory, there should be:\na file report.txt that explains your method for creating the hhgX.txt files (briefly)\nthe file shell_answers.sh\na subdirectory whose name is hhg-exploded, and whose contents are the 26 files described above.\na subdirectory called bkup which contains the original text file hhg.txt as well as the original zip file hhg.zip.\n\nTo illustrate (although I’ve only put the ABC files in hhg-exploded) your zip file should unpack to this:\njeremy_teitelbaum\n├── bkup\n│   ├── hhg.txt\n│   └── hhg.zip\n├── hhg-exploded\n│   ├── hhgA.txt\n│   ├── hhgB.txt\n│   ├── hhgC.txt\n│   \n├── report.txt\n└── shell_answers.sh",
    "crumbs": [
      "Problems",
      "Homework 4"
    ]
  }
]