---
title: "Probability"
subtitle: "Fundamentals of Data Science"
author: "Jeremy Teitelbaum"
format: revealjs
title-block-style: plain
---

# Populations and Samples

## Probability Theory

Probability theory is based on:

- An underlying collection $S$ of all possible outcomes  (a *population* or *sample space*) of an experiment. 
- A rule $P$ that assigns a number between zero and one to each subset of the sample space satisfying certain rules. 

## Sample Space


For example:

- For a flip of a single coin, the possible outcomes are Heads and Tails and the sample
space has two elements. For multiple flips, the outcomes are sequences of Heads and Tails.

- For a measurement of temperature, we might model the possible outcomes, or the sample space,   as all real numbers, recognizing that only some of them are actually possible results of the experiment.


## Simple Events

The elements of the sample space or population are the *outcomes* or *simple events* or *sample points*. 

- For a flip of a coin, the possible outcomes are Heads or Tails.  For multiple flips,
the possible outcomes are particular sequences of Heads or Tails.

- For a measurement of temperature, a simple event would be a particular number obtained
at a particular time. 

## Events

Subsets of the population make up events or outcomes.

- Among the population made up of sequences of 10 coin flips, the subset consisting of
sequences containing at least 3 heads is an event. 

- Among the measurements of temperature, a measurement lying between say 22 and 25 degrees celsius would be an event. 

## Probability Measure

The last element of probability theory is the function P that assigns a number between 0 and 1 to every event such that

- $P(\emptyset)=0$
- $P(S)=1$. 
- If $A\cap B=\emptyset$ then $P(A\cup B)=P(A)+P(B)$.  This is also required to hold for *infinite* collections of disjoint sets but we won't worry much about the foundations of probability. 

## Random Variables

A *random variable* is a rule that assigns a number to an event. 

- We can assign the value 1 to heads and 0 to tails.  This is a *bernoulli* random variable.
- Our sample space can be sets of 10 coin flips.  The number of heads is a random variable. 
- The measurement of temperature yields a number.  
- If we pick a person at random, we can assign the value 1 if they wear glasses and 0 if not.

## Discrete vs Continuous Random Variables

A discrete random variables takes "separate" values depending on the event.
A continuous random variable takes values in a range.

- Bernoulli random variable is discrete (0/1)
- Number of heads in 10 flips is discrete (takes values 0,...,10)
- Temperature is continuous (in principle can get any reading)
- Mass of a penguin is continuous
- Species of penguin is discrete


## Events and Random Variables

Specifying a value, or a range of values, for a random variable defines an event.

## Bernoulli example

- Sample space is $\{H,T\}$
- $P(H)=p$
- $X$ is the random variable with $X(H)=1$ and $X(T)=0$

Then:

- $X=1$ is the same as the event $H$
- $P(X=1)$=p

## Continuous example

- Sample space is the possible temperatures at a particular point in space and time.
- Random variable $T$ is a measure of temperature.
- $P(21<T<22)$ is the probability that the temperature is between 21 and 22 degrees.

## Probability density functions

In the continuous case, probability is measured by a probability density function $P(x)$. The classic example is the normal (bell-shaped) curve.


## Area gives probability

```{r echo=FALSE}
library(tidyverse)
temperature<-seq(21,23,.001)
density<-dnorm(temperature,22,.2)
p<-pnorm(22.3,22,.2)-pnorm(21.7,22,.2)
ggplot()+
    geom_line(aes(x=temperature,y=density))+
    geom_ribbon(aes(x=temperature,ymin=0,ymax=if_else(temperature>=21.7 & temperature<=22.3,density,0)),fill='gray')
```

If $P(x)$ is the density function, then:

> the probability that $x$ lies between $a$ and $b$ is the area under density function between $a$ and $b$.

The shaded area gives probability `r format(p,digits=2,nsmall=2)` for temp between 21.7 and 22.3.





<!--
some things to talk about:
fisher exact test  (likelihood of results at random)
datatypes and types of random variables (ints are discrete/continuous?)
relationship between *density function* and *histogram*
empirical distribution
-->


