---
title: "Essential Linear Algebra"
subtitle: "Fundamentals of Data Science"
author: "Jeremy Teitelbaum"
format: revealjs
title-block-style: plain
---
```{python visible=False}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Arrow

def make_plot(xmin,ymin,xmax,ymax):
    fig, ax = plt.subplots()
    ax.set_xlim(xmin,xmax)
    ax.set_ylim(ymin,ymax)
    ax.set_xticks(np.arange(xmin,xmax,1))
    ax.set_yticks(np.arange(ymin,ymax,1))
    ax.set_aspect('equal')
    ax.grid(visible=True)
    return fig, ax

def draw_arrow(x0,y0,x1,y1,axes,color='blue',alpha=1):
    axes.add_patch(Arrow(x0,y0,x1-x0,y1-y0,width=.3,color=color,alpha=alpha))
    return axes

```
## Vectors and Scalars

$\mathbf{R}^{n}$ is the set of vectors (ordered tuples) of real numbers of length $n$.
A *scalar* is a real number.

- Vectors are *added* componentwise.
- A vector can be multiplied by a scalar.


## Addition

```{python}

fig, ax = make_plot(0,0,12,12)
ax.set_title('Vector Addition')
ax = draw_arrow(0,0,3,5,ax)
ax = draw_arrow(0,0,1,4,ax)
ax = draw_arrow(1,4,4,9,ax)
ax = draw_arrow(3,5,4,9,ax)
plt.show()
```

## Scalar Multiplication

```{python}
fig,ax = make_plot(0,0,12,12)
ax.set_title("Scalar Multiplication")
ax = draw_arrow(0,0,3,5, ax)
ax = draw_arrow(0,0,6,10,ax,color='red',alpha=.5)
```

## Geometric Interpretation in 2 and 3 dimensions

## Feature Space 

- examples including word2vec and embeddings
- maybe polynomial regression?
- images as vectors
- one-hot encoding of categorical vectors

## Linear Dependence and Linear Independence; basis; scores

- dependent, or almost dependent features, don't add new information
- linear combinations of features yield new features (scores)
- different bases give different points of view on the same data
(for example rescaling data to standard z-scores)

## Subspaces, hyperplanes, and dimension



## Linear Maps and Matrices

## Rank and invertibility

## Matrix multiplication

## Linear Systems

## Separating hyperplanes, convex sets

## Distances and the euclidean norm

## The dot product, orthogonality, cauchy-schwartz

## orthogonal projection, minimum distance to a hyperspace

## Transpose of a matrix, covariance matrix, principal directions



